{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653143f4",
   "metadata": {},
   "source": [
    "# LSTM, GRU, LSTM+GRU 모델에 여러 변수 적용해보기 (변수선택)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2b6e4",
   "metadata": {},
   "source": [
    "# 시계열 알고리즘 epochs 100 두고 8개 조합 다 돌려보고, 각자 성능 가장 좋은 변수채택 (NEURON 사용 (클라우드슈퍼컴)) (맨 아랫줄 빼고 다 소용 X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c4cf6",
   "metadata": {},
   "source": [
    "1. 15일치 종가 + 선택된변수 전체 15일치\n",
    "\n",
    "2. 15일치 종가 + 선택된변수 하나씩 15일치\n",
    "\n",
    "3. 15일치 종가 + 선택된변수 두개이상(2~7개) 조합 15일치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad80f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "from pykrx import bond\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54502bbe",
   "metadata": {},
   "source": [
    "1. 15일치 종가 + 선택된변수 전체 15일치 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91afc721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 20s 51ms/step - loss: 0.0078 - val_loss: 7.9998e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 6s 37ms/step - loss: 0.0010 - val_loss: 6.5751e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 6s 39ms/step - loss: 6.7338e-04 - val_loss: 3.8098e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 6.5717e-04 - val_loss: 4.5043e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 6.2089e-04 - val_loss: 5.7921e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 5.7241e-04 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 6.2652e-04 - val_loss: 3.7105e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 4.7826e-04 - val_loss: 4.7737e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 5.0433e-04 - val_loss: 3.5488e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 6.3361e-04 - val_loss: 9.4101e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 23s 63ms/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.0018 - val_loss: 8.3480e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.0014 - val_loss: 6.5531e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.0013 - val_loss: 9.3430e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 7.9284e-04 - val_loss: 4.2173e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 7.3955e-04 - val_loss: 5.2434e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 6.5463e-04 - val_loss: 6.9884e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 13s 36ms/step - loss: 0.0207 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0011 - val_loss: 7.7484e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 9.9984e-04 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.9706e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1415.627774</td>\n",
       "      <td>0.958043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1642.695904</td>\n",
       "      <td>0.943504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1757.901639</td>\n",
       "      <td>0.935301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "2   lstmgru  1415.627774  0.958043\n",
       "1       gru  1642.695904  0.943504\n",
       "0      lstm  1757.901639  0.935301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,8)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,8), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,8), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "\n",
    "comparison1.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a3a60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1415.627774</td>\n",
       "      <td>0.958043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1642.695904</td>\n",
       "      <td>0.943504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1757.901639</td>\n",
       "      <td>0.935301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "2   lstmgru  1415.627774  0.958043\n",
       "1       gru  1642.695904  0.943504\n",
       "0      lstm  1757.901639  0.935301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [1757.901639, 1642.695904, 1415.627774]\n",
    "\n",
    "r2_li = [0.935301, 0.943504, 0.958043]\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2': r2_li}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "\n",
    "comparison1.sort_values(['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e79f1e",
   "metadata": {},
   "source": [
    "2. 15일치 종가 + 15일치 WMA 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c09b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 23s 58ms/step - loss: 0.0090 - val_loss: 7.6764e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 6s 37ms/step - loss: 0.0012 - val_loss: 8.7523e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 8.9837e-04 - val_loss: 7.0420e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 7.4660e-04 - val_loss: 6.9941e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 6.0523e-04 - val_loss: 3.6951e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 7s 43ms/step - loss: 5.4652e-04 - val_loss: 6.3628e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 4.7571e-04 - val_loss: 5.6482e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 5.2002e-04 - val_loss: 3.1983e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 6.0824e-04 - val_loss: 3.0849e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 5.2562e-04 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 25s 69ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 9s 55ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 8s 51ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 9s 55ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 8s 51ms/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.0015 - val_loss: 8.6543e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 9s 51ms/step - loss: 9.3145e-04 - val_loss: 5.8245e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 36ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 5s 28ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 5s 27ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 7.6211e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 5s 27ms/step - loss: 0.0013 - val_loss: 8.9465e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 6.3340e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1292.377611</td>\n",
       "      <td>0.965031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1347.721478</td>\n",
       "      <td>0.961972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1700.238859</td>\n",
       "      <td>0.939476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "2   lstmgru  1292.377611  0.965031\n",
       "0      lstm  1347.721478  0.961972\n",
       "1       gru  1700.238859  0.939476"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :2]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :2]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :2]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison2 = pd.DataFrame(data)\n",
    "\n",
    "comparison2.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b5a6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1292.377611</td>\n",
       "      <td>0.965031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1347.721478</td>\n",
       "      <td>0.961972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1700.238859</td>\n",
       "      <td>0.939476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "2   lstmgru  1292.377611  0.965031\n",
       "0      lstm  1347.721478  0.961972\n",
       "1       gru  1700.238859  0.939476"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [1347.721478, 1700.238859, 1292.377611]\n",
    "\n",
    "r2_li = [0.961972, 0.939476, 0.965031]\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2': r2_li}\n",
    "\n",
    "comparison2 = pd.DataFrame(data)\n",
    "\n",
    "comparison2.sort_values(['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f04aa8",
   "metadata": {},
   "source": [
    "3. 15일치 종가 + 15일치 MA5 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecb6230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 22ms/step - loss: 0.0124 - val_loss: 9.9594e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 6.6990e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.4492e-04 - val_loss: 5.4449e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8883e-04 - val_loss: 4.3617e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6701e-04 - val_loss: 3.7126e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 6.0372e-04 - val_loss: 3.8847e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.9903e-04 - val_loss: 8.8467e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7356e-04 - val_loss: 6.8968e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.4054e-04 - val_loss: 3.3578e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 28ms/step - loss: 0.0100 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 9.6324e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 8.5579e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 7.2652e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 6s 16ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 9.1154e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.4474e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 8.6155e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.2468e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 7.0080e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.5399e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.0497e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>981.260116</td>\n",
       "      <td>0.979841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1443.388452</td>\n",
       "      <td>0.956381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1922.163277</td>\n",
       "      <td>0.922645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   981.260116  0.979841\n",
       "2   lstmgru  1443.388452  0.956381\n",
       "0      lstm  1922.163277  0.922645"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison3 = pd.DataFrame(data)\n",
    "\n",
    "comparison3.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "971805b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>981.260116</td>\n",
       "      <td>0.979841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1443.388452</td>\n",
       "      <td>0.956381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1922.163277</td>\n",
       "      <td>0.922645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   981.260116  0.979841\n",
       "2   lstmgru  1443.388452  0.956381\n",
       "0      lstm  1922.163277  0.922645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [1922.163277, 981.260116, 1443.388452]\n",
    "\n",
    "r2_li = [0.922645, 0.979841, 0.956381]\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2': r2_li}\n",
    "\n",
    "comparison3 = pd.DataFrame(data)\n",
    "\n",
    "comparison3.sort_values(['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee3f54",
   "metadata": {},
   "source": [
    "4. 15일치 종가 + 15일치 PER 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ce1b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0074 - val_loss: 7.8768e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 6.2476e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 5.4773e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.6783e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.0745e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.9486e-04 - val_loss: 6.6288e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 7.2354e-04 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 5.4419e-04 - val_loss: 4.5564e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 7.1368e-04 - val_loss: 3.8844e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.2959e-04 - val_loss: 3.2360e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 30ms/step - loss: 0.0077 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 5s 31ms/step - loss: 0.0015 - val_loss: 8.5397e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0011 - val_loss: 6.4584e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 6s 15ms/step - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 9.9719e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 9.7524e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>963.301316</td>\n",
       "      <td>0.980572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1360.884338</td>\n",
       "      <td>0.961225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1672.307125</td>\n",
       "      <td>0.941449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   963.301316  0.980572\n",
       "2   lstmgru  1360.884338  0.961225\n",
       "0      lstm  1672.307125  0.941449"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,3]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,3]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,3]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison4 = pd.DataFrame(data)\n",
    "\n",
    "comparison4.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5119ff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>963.301316</td>\n",
       "      <td>0.980572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1360.884338</td>\n",
       "      <td>0.961225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1672.307125</td>\n",
       "      <td>0.941449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   963.301316  0.980572\n",
       "2   lstmgru  1360.884338  0.961225\n",
       "0      lstm  1672.307125  0.941449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [1672.307125, 963.301316, 1360.884338]\n",
    "\n",
    "r2_li = [0.941449, 0.980572, 0.961225]\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2': r2_li}\n",
    "\n",
    "comparison4 = pd.DataFrame(data)\n",
    "\n",
    "comparison4.sort_values(['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20605536",
   "metadata": {},
   "source": [
    "5. 15일치 종가 + 15일치 foreign_보유수량 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fa423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 20ms/step - loss: 0.0084 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0015 - val_loss: 9.2806e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0013 - val_loss: 5.8855e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 9.6357e-04 - val_loss: 5.5017e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.0016e-04 - val_loss: 7.2788e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.9417e-04 - val_loss: 5.4274e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.3606e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4863e-04 - val_loss: 7.7236e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5894e-04 - val_loss: 3.4743e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.6520e-04 - val_loss: 3.1832e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 27ms/step - loss: 0.0094 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 6s 13ms/step - loss: 0.0257 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>955.410841</td>\n",
       "      <td>0.980889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1838.754578</td>\n",
       "      <td>0.929213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>2212.965432</td>\n",
       "      <td>0.897469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   955.410841  0.980889\n",
       "0      lstm  1838.754578  0.929213\n",
       "2   lstmgru  2212.965432  0.897469"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,4]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,4]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,4]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2':r2_li}\n",
    "\n",
    "comparison5 = pd.DataFrame(data)\n",
    "\n",
    "comparison5.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679e98fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>955.410841</td>\n",
       "      <td>0.980889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1838.754578</td>\n",
       "      <td>0.929213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>2212.965432</td>\n",
       "      <td>0.897469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   955.410841  0.980889\n",
       "0      lstm  1838.754578  0.929213\n",
       "2   lstmgru  2212.965432  0.897469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [1838.754578, 955.410841, 2212.965432]\n",
    "\n",
    "r2_li = [0.929213, 0.980889, 0.897469]\n",
    "\n",
    "data = {'algorithm':algo_li, \n",
    "        'rmse': rmse_li, \n",
    "        'r2': r2_li}\n",
    "\n",
    "comparison5 = pd.DataFrame(data)\n",
    "\n",
    "comparison5.sort_values(['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d3b6b",
   "metadata": {},
   "source": [
    "6. 15일치 종가 + 15일치 RSI 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed19f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 20ms/step - loss: 0.0119 - val_loss: 6.2447e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 8.7807e-04 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.2758e-04 - val_loss: 9.3887e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.2965e-04 - val_loss: 7.2381e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.7080e-04 - val_loss: 4.5897e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.3408e-04 - val_loss: 3.6162e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.7228e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.4212e-04 - val_loss: 9.0144e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3923e-04 - val_loss: 5.2380e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0954e-04 - val_loss: 8.0033e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 28ms/step - loss: 0.0091 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 8.3372e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 7.3602e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0013 - val_loss: 6.2021e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0010 - val_loss: 5.7349e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 9.0789e-04 - val_loss: 5.4536e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 7.8548e-04 - val_loss: 4.6893e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 7.4706e-04 - val_loss: 4.2911e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 14ms/step - loss: 0.0104 - val_loss: 7.6388e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 7.3823e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 6.8756e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 8.8900e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 7.6591e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.8775e-04 - val_loss: 5.8081e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 5.9338e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.6025e-04 - val_loss: 5.3199e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.0680e-04 - val_loss: 5.1194e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.7731e-04 - val_loss: 7.4069e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1109.281361</td>\n",
       "      <td>0.974237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1457.398074</td>\n",
       "      <td>0.955531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1514.937648</td>\n",
       "      <td>0.951950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "2   lstmgru  1109.281361  0.974237\n",
       "0      lstm  1457.398074  0.955531\n",
       "1       gru  1514.937648  0.951950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,5]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,5]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,5]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison6 = pd.DataFrame(data)\n",
    "\n",
    "comparison6.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac586887",
   "metadata": {},
   "source": [
    "7. 15일치 종가 + 15일치 MOM 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa30769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 21ms/step - loss: 0.0116 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.0884e-04 - val_loss: 6.2754e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.1816e-04 - val_loss: 6.6208e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.2093e-04 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.0508e-04 - val_loss: 6.9522e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.5691e-04 - val_loss: 4.2820e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3673e-04 - val_loss: 4.5200e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8294e-04 - val_loss: 5.2221e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1477e-04 - val_loss: 3.7786e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 28ms/step - loss: 0.0088 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 7.5797e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.7964e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 6.8213e-04 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 6s 14ms/step - loss: 0.0110 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 6.9012e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0012 - val_loss: 7.3187e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 7.1761e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.1357e-04 - val_loss: 9.6627e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>1040.936192</td>\n",
       "      <td>0.977314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1664.600133</td>\n",
       "      <td>0.941987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1766.920144</td>\n",
       "      <td>0.934636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru  1040.936192  0.977314\n",
       "0      lstm  1664.600133  0.941987\n",
       "2   lstmgru  1766.920144  0.934636"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,6]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,6]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,6]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison7 = pd.DataFrame(data)\n",
    "\n",
    "comparison7.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a31b05",
   "metadata": {},
   "source": [
    "8. 15일치 종가 + 15일치 MA20 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91764693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 23ms/step - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 8.7775e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0011 - val_loss: 9.5857e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 6.7638e-04 - val_loss: 4.0213e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 5.6860e-04 - val_loss: 3.8089e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.5522e-04 - val_loss: 4.9274e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.9682e-04 - val_loss: 4.2413e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 4.6712e-04 - val_loss: 5.8886e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.3075e-04 - val_loss: 3.1758e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.8856e-04 - val_loss: 3.3754e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 17s 51ms/step - loss: 0.0093 - val_loss: 0.0146\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 6s 36ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 6s 36ms/step - loss: 0.0028 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 5s 33ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 5s 29ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0018 - val_loss: 9.2958e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 8.0832e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0015 - val_loss: 6.3218e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 7.3275e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0264 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0016 - val_loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>983.835265</td>\n",
       "      <td>0.979735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>1449.563573</td>\n",
       "      <td>0.956007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2656.804512</td>\n",
       "      <td>0.852217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2\n",
       "1       gru   983.835265  0.979735\n",
       "2   lstmgru  1449.563573  0.956007\n",
       "0      lstm  2656.804512  0.852217"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,2)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,2), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison8 = pd.DataFrame(data)\n",
    "\n",
    "comparison8.sort_values(['r2'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82313b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison1['rmse_mean'] = comparison1['rmse'].mean()\n",
    "comparison2['rmse_mean'] = comparison2['rmse'].mean()\n",
    "comparison3['rmse_mean'] = comparison3['rmse'].mean()\n",
    "comparison4['rmse_mean'] = comparison4['rmse'].mean()\n",
    "comparison5['rmse_mean'] = comparison5['rmse'].mean()\n",
    "comparison6['rmse_mean'] = comparison6['rmse'].mean()\n",
    "comparison7['rmse_mean'] = comparison7['rmse'].mean()\n",
    "comparison8['rmse_mean'] = comparison8['rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec3a19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison1, marker='o', label='comparison1')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison2, marker='o', label='comparison2')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison3, marker='o', label='comparison3')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison4, marker='o', label='comparison4')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison5, marker='o', label='comparison5')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison6, marker='o', label='comparison6')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison7, marker='o', label='comparison7')\n",
    "sns.lineplot(x='algorithm', y='r2', data=comparison8, marker='o', label='comparison8')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), borderaxespad=-3)\n",
    "\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('R2')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30c1f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison1, marker='o', label='comparison1')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison2, marker='o', label='comparison2')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison3, marker='o', label='comparison3')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison4, marker='o', label='comparison4')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison5, marker='o', label='comparison5')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison6, marker='o', label='comparison6')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison7, marker='o', label='comparison7')\n",
    "sns.lineplot(x='algorithm', y='rmse_mean', data=comparison8, marker='o', label='comparison8')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), borderaxespad=-3)\n",
    "\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('R2')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a89eff",
   "metadata": {},
   "source": [
    "# LSTM, GRU, RMSE 기준 15일치 종가 + 15일치 PER 채택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db801533",
   "metadata": {},
   "source": [
    "3. 15일치 종가 + 선택된변수 두개이상(2~7개) 조합 15일치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fb66d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [1, 5],\n",
       " [1, 6],\n",
       " [1, 7],\n",
       " [2, 3],\n",
       " [2, 4],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [2, 7],\n",
       " [3, 4],\n",
       " [3, 5],\n",
       " [3, 6],\n",
       " [3, 7],\n",
       " [4, 5],\n",
       " [4, 6],\n",
       " [4, 7],\n",
       " [5, 6],\n",
       " [5, 7],\n",
       " [6, 7],\n",
       " [1, 2, 3],\n",
       " [1, 2, 4],\n",
       " [1, 2, 5],\n",
       " [1, 2, 6],\n",
       " [1, 2, 7],\n",
       " [1, 3, 4],\n",
       " [1, 3, 5],\n",
       " [1, 3, 6],\n",
       " [1, 3, 7],\n",
       " [1, 4, 5],\n",
       " [1, 4, 6],\n",
       " [1, 4, 7],\n",
       " [1, 5, 6],\n",
       " [1, 5, 7],\n",
       " [1, 6, 7],\n",
       " [2, 3, 4],\n",
       " [2, 3, 5],\n",
       " [2, 3, 6],\n",
       " [2, 3, 7],\n",
       " [2, 4, 5],\n",
       " [2, 4, 6],\n",
       " [2, 4, 7],\n",
       " [2, 5, 6],\n",
       " [2, 5, 7],\n",
       " [2, 6, 7],\n",
       " [3, 4, 5],\n",
       " [3, 4, 6],\n",
       " [3, 4, 7],\n",
       " [3, 5, 6],\n",
       " [3, 5, 7],\n",
       " [3, 6, 7],\n",
       " [4, 5, 6],\n",
       " [4, 5, 7],\n",
       " [4, 6, 7],\n",
       " [5, 6, 7],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 5],\n",
       " [1, 2, 3, 6],\n",
       " [1, 2, 3, 7],\n",
       " [1, 2, 4, 5],\n",
       " [1, 2, 4, 6],\n",
       " [1, 2, 4, 7],\n",
       " [1, 2, 5, 6],\n",
       " [1, 2, 5, 7],\n",
       " [1, 2, 6, 7],\n",
       " [1, 3, 4, 5],\n",
       " [1, 3, 4, 6],\n",
       " [1, 3, 4, 7],\n",
       " [1, 3, 5, 6],\n",
       " [1, 3, 5, 7],\n",
       " [1, 3, 6, 7],\n",
       " [1, 4, 5, 6],\n",
       " [1, 4, 5, 7],\n",
       " [1, 4, 6, 7],\n",
       " [1, 5, 6, 7],\n",
       " [2, 3, 4, 5],\n",
       " [2, 3, 4, 6],\n",
       " [2, 3, 4, 7],\n",
       " [2, 3, 5, 6],\n",
       " [2, 3, 5, 7],\n",
       " [2, 3, 6, 7],\n",
       " [2, 4, 5, 6],\n",
       " [2, 4, 5, 7],\n",
       " [2, 4, 6, 7],\n",
       " [2, 5, 6, 7],\n",
       " [3, 4, 5, 6],\n",
       " [3, 4, 5, 7],\n",
       " [3, 4, 6, 7],\n",
       " [3, 5, 6, 7],\n",
       " [4, 5, 6, 7],\n",
       " [1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 6],\n",
       " [1, 2, 3, 4, 7],\n",
       " [1, 2, 3, 5, 6],\n",
       " [1, 2, 3, 5, 7],\n",
       " [1, 2, 3, 6, 7],\n",
       " [1, 2, 4, 5, 6],\n",
       " [1, 2, 4, 5, 7],\n",
       " [1, 2, 4, 6, 7],\n",
       " [1, 2, 5, 6, 7],\n",
       " [1, 3, 4, 5, 6],\n",
       " [1, 3, 4, 5, 7],\n",
       " [1, 3, 4, 6, 7],\n",
       " [1, 3, 5, 6, 7],\n",
       " [1, 4, 5, 6, 7],\n",
       " [2, 3, 4, 5, 6],\n",
       " [2, 3, 4, 5, 7],\n",
       " [2, 3, 4, 6, 7],\n",
       " [2, 3, 5, 6, 7],\n",
       " [2, 4, 5, 6, 7],\n",
       " [3, 4, 5, 6, 7],\n",
       " [1, 2, 3, 4, 5, 6],\n",
       " [1, 2, 3, 4, 5, 7],\n",
       " [1, 2, 3, 4, 6, 7],\n",
       " [1, 2, 3, 5, 6, 7],\n",
       " [1, 2, 4, 5, 6, 7],\n",
       " [1, 3, 4, 5, 6, 7],\n",
       " [2, 3, 4, 5, 6, 7]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "for r in range(2, 7):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22603dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [2],\n",
       " [3],\n",
       " [4],\n",
       " [5],\n",
       " [6],\n",
       " [7],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [1, 5],\n",
       " [1, 6],\n",
       " [1, 7],\n",
       " [2, 3],\n",
       " [2, 4],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [2, 7],\n",
       " [3, 4],\n",
       " [3, 5],\n",
       " [3, 6],\n",
       " [3, 7],\n",
       " [4, 5],\n",
       " [4, 6],\n",
       " [4, 7],\n",
       " [5, 6],\n",
       " [5, 7],\n",
       " [6, 7],\n",
       " [1, 2, 3],\n",
       " [1, 2, 4],\n",
       " [1, 2, 5],\n",
       " [1, 2, 6],\n",
       " [1, 2, 7],\n",
       " [1, 3, 4],\n",
       " [1, 3, 5],\n",
       " [1, 3, 6],\n",
       " [1, 3, 7],\n",
       " [1, 4, 5],\n",
       " [1, 4, 6],\n",
       " [1, 4, 7],\n",
       " [1, 5, 6],\n",
       " [1, 5, 7],\n",
       " [1, 6, 7],\n",
       " [2, 3, 4],\n",
       " [2, 3, 5],\n",
       " [2, 3, 6],\n",
       " [2, 3, 7],\n",
       " [2, 4, 5],\n",
       " [2, 4, 6],\n",
       " [2, 4, 7],\n",
       " [2, 5, 6],\n",
       " [2, 5, 7],\n",
       " [2, 6, 7],\n",
       " [3, 4, 5],\n",
       " [3, 4, 6],\n",
       " [3, 4, 7],\n",
       " [3, 5, 6],\n",
       " [3, 5, 7],\n",
       " [3, 6, 7],\n",
       " [4, 5, 6],\n",
       " [4, 5, 7],\n",
       " [4, 6, 7],\n",
       " [5, 6, 7],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 5],\n",
       " [1, 2, 3, 6],\n",
       " [1, 2, 3, 7],\n",
       " [1, 2, 4, 5],\n",
       " [1, 2, 4, 6],\n",
       " [1, 2, 4, 7],\n",
       " [1, 2, 5, 6],\n",
       " [1, 2, 5, 7],\n",
       " [1, 2, 6, 7],\n",
       " [1, 3, 4, 5],\n",
       " [1, 3, 4, 6],\n",
       " [1, 3, 4, 7],\n",
       " [1, 3, 5, 6],\n",
       " [1, 3, 5, 7],\n",
       " [1, 3, 6, 7],\n",
       " [1, 4, 5, 6],\n",
       " [1, 4, 5, 7],\n",
       " [1, 4, 6, 7],\n",
       " [1, 5, 6, 7],\n",
       " [2, 3, 4, 5],\n",
       " [2, 3, 4, 6],\n",
       " [2, 3, 4, 7],\n",
       " [2, 3, 5, 6],\n",
       " [2, 3, 5, 7],\n",
       " [2, 3, 6, 7],\n",
       " [2, 4, 5, 6],\n",
       " [2, 4, 5, 7],\n",
       " [2, 4, 6, 7],\n",
       " [2, 5, 6, 7],\n",
       " [3, 4, 5, 6],\n",
       " [3, 4, 5, 7],\n",
       " [3, 4, 6, 7],\n",
       " [3, 5, 6, 7],\n",
       " [4, 5, 6, 7],\n",
       " [1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 6],\n",
       " [1, 2, 3, 4, 7],\n",
       " [1, 2, 3, 5, 6],\n",
       " [1, 2, 3, 5, 7],\n",
       " [1, 2, 3, 6, 7],\n",
       " [1, 2, 4, 5, 6],\n",
       " [1, 2, 4, 5, 7],\n",
       " [1, 2, 4, 6, 7],\n",
       " [1, 2, 5, 6, 7],\n",
       " [1, 3, 4, 5, 6],\n",
       " [1, 3, 4, 5, 7],\n",
       " [1, 3, 4, 6, 7],\n",
       " [1, 3, 5, 6, 7],\n",
       " [1, 4, 5, 6, 7],\n",
       " [2, 3, 4, 5, 6],\n",
       " [2, 3, 4, 5, 7],\n",
       " [2, 3, 4, 6, 7],\n",
       " [2, 3, 5, 6, 7],\n",
       " [2, 4, 5, 6, 7],\n",
       " [3, 4, 5, 6, 7],\n",
       " [1, 2, 3, 4, 5, 6],\n",
       " [1, 2, 3, 4, 5, 7],\n",
       " [1, 2, 3, 4, 6, 7],\n",
       " [1, 2, 3, 5, 6, 7],\n",
       " [1, 2, 4, 5, 6, 7],\n",
       " [1, 3, 4, 5, 6, 7],\n",
       " [2, 3, 4, 5, 6, 7]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "for r in range(1, 7):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae9c50a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 7.5056e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.4554e-04 - val_loss: 6.9112e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.6338e-04 - val_loss: 4.9314e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.3980e-04 - val_loss: 8.3944e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9694e-04 - val_loss: 3.9041e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4102e-04 - val_loss: 3.3467e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2461e-04 - val_loss: 6.2110e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2378e-04 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4430e-04 - val_loss: 3.3203e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0080 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 5.6171e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8526e-04 - val_loss: 5.6307e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 16ms/step - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 9.3142e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 8.3435e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 23ms/step - loss: 0.0148 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 7.7258e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 6.3773e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.8980e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.9432e-04 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.1031e-04 - val_loss: 5.9919e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.9352e-04 - val_loss: 3.8161e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.4070e-04 - val_loss: 6.6695e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.2932e-04 - val_loss: 5.1887e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.0595e-04 - val_loss: 4.2110e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 27ms/step - loss: 0.0096 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 8.4444e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 14ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 9.6914e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 8.1754e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0012 - val_loss: 8.0538e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.2392e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0204 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0013 - val_loss: 8.6090e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.6194e-04 - val_loss: 4.9185e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.4468e-04 - val_loss: 8.2702e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.9266e-04 - val_loss: 0.0022\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.6902e-04 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.3954e-04 - val_loss: 5.3393e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1082e-04 - val_loss: 3.7504e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.8230e-04 - val_loss: 9.1480e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0125 - val_loss: 0.0041\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.8892e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 7.4615e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 7.4423e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 6.8665e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0218 - val_loss: 0.0034\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 9.6353e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.1007e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 20ms/step - loss: 0.0122 - val_loss: 7.1483e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.9713e-04 - val_loss: 8.3869e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.0620e-04 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.1940e-04 - val_loss: 7.8681e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.6018e-04 - val_loss: 8.5665e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.8509e-04 - val_loss: 3.7951e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4747e-04 - val_loss: 8.3920e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.6448e-04 - val_loss: 4.6020e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.8265e-04 - val_loss: 3.7981e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.8647e-04 - val_loss: 5.4323e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0149 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 9.2008e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 9.6332e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 7.5435e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 6.5970e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.7616e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 5.4824e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0114 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.6089e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.0761e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.1532e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.5474e-04 - val_loss: 6.3059e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.7550e-04 - val_loss: 6.6772e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.3977e-04 - val_loss: 5.5761e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.3243e-04 - val_loss: 5.6798e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.7598e-04 - val_loss: 5.9778e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 20ms/step - loss: 0.0187 - val_loss: 8.7180e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 9.0627e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.4951e-04 - val_loss: 5.8544e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 4.9495e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.8126e-04 - val_loss: 9.5518e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.0916e-04 - val_loss: 5.8135e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6723e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1218e-04 - val_loss: 7.2719e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.5040e-04 - val_loss: 3.8867e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0106e-04 - val_loss: 3.8898e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 30ms/step - loss: 0.0089 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 5s 29ms/step - loss: 0.0012 - val_loss: 5.6898e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.6583e-04 - val_loss: 8.5278e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.9333e-04 - val_loss: 5.0608e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0138 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 9.5854e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 7.8749e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 8.2464e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 6.3814e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 7.1289e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.3843e-04 - val_loss: 6.2064e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0062 - val_loss: 9.5729e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.0013 - val_loss: 6.3041e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.8337e-04 - val_loss: 5.4573e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.1693e-04 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 6.3134e-04 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.7225e-04 - val_loss: 3.6951e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.8052e-04 - val_loss: 3.2047e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 5.6602e-04 - val_loss: 3.1182e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 5.2535e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 4.2700e-04 - val_loss: 3.4549e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 26ms/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 9.2261e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 6.2264e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.2755e-04 - val_loss: 9.6972e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.8479e-04 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0104 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 8.6869e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 9.4580e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 7.6956e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.9094e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0132 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 6.1242e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.9323e-04 - val_loss: 6.4179e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.6439e-04 - val_loss: 8.9306e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7727e-04 - val_loss: 3.9851e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0528e-04 - val_loss: 3.4819e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.0466e-04 - val_loss: 3.5171e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.5074e-04 - val_loss: 3.2089e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0101 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0216 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0095 - val_loss: 8.4292e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 8.5233e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 5.5193e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 6.7522e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.7564e-04 - val_loss: 5.2643e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.3405e-04 - val_loss: 3.8529e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5331e-04 - val_loss: 4.3560e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.3607e-04 - val_loss: 8.9148e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.3908e-04 - val_loss: 3.4872e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.8202e-04 - val_loss: 5.4502e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0108 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0018 - val_loss: 8.6213e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 9.5656e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0073 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.6001e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0090 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 6.1438e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8072e-04 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 7.6247e-04 - val_loss: 5.3247e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2261e-04 - val_loss: 8.2119e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.4310e-04 - val_loss: 8.4765e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.8711e-04 - val_loss: 4.1838e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.7682e-04 - val_loss: 6.3612e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.4664e-04 - val_loss: 3.2391e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.8845e-04 - val_loss: 3.3252e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 7.5525e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 8.0172e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.2015e-04 - val_loss: 8.7244e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 9.0714e-04 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0095 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.7226e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.9825e-04 - val_loss: 6.6327e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.8417e-04 - val_loss: 5.6736e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.9371e-04 - val_loss: 6.1540e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 7.7189e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.6658e-04 - val_loss: 5.1327e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 7.5836e-04 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 7.2318e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5490e-04 - val_loss: 7.3983e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.1586e-04 - val_loss: 4.2764e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.9446e-04 - val_loss: 7.5830e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.6385e-04 - val_loss: 3.8064e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2477e-04 - val_loss: 3.7635e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2101e-04 - val_loss: 4.0868e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.9016e-04 - val_loss: 3.7489e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.2425e-04 - val_loss: 4.6795e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0102 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 7.9471e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 6.0746e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 6.8419e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.9865e-04 - val_loss: 7.2078e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0135 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 8.8580e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 6.7353e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.7839e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 7.0756e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.8771e-04 - val_loss: 3.7151e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.9994e-04 - val_loss: 9.8606e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0179e-04 - val_loss: 3.0952e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2157e-04 - val_loss: 3.1379e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.7453e-04 - val_loss: 3.4400e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 4.7855e-04 - val_loss: 5.7755e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 4.7977e-04 - val_loss: 5.0488e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0119 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0024 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 8.7094e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0015 - val_loss: 8.2977e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0308 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.0010 - val_loss: 8.1294e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.9506e-04 - val_loss: 9.2198e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.7595e-04 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.5422e-04 - val_loss: 4.3097e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.3599e-04 - val_loss: 3.8459e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.0993e-04 - val_loss: 3.4934e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.4857e-04 - val_loss: 6.3327e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.4335e-04 - val_loss: 3.7093e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0119 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 8.4540e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 7.3672e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 7.2800e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.9395e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.9742e-04 - val_loss: 4.2427e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.0668e-04 - val_loss: 7.1493e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.8519e-04 - val_loss: 4.3538e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.7121e-04 - val_loss: 3.2642e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.3087e-04 - val_loss: 3.3345e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.4921e-04 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.1372e-04 - val_loss: 4.9307e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.1434e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.4759e-04 - val_loss: 4.3289e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0109 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 9.3081e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0020 - val_loss: 8.5925e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0015 - val_loss: 7.8365e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0018 - val_loss: 8.8445e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0011 - val_loss: 7.4319e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 7.0613e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0135 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 9.8878e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.6489e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.9164e-04 - val_loss: 8.0164e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.8004e-04 - val_loss: 7.4769e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.2927e-04 - val_loss: 9.3922e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.2015e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.1829e-04 - val_loss: 8.8898e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0140 - val_loss: 8.2867e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 6.9548e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.1105e-04 - val_loss: 6.5824e-04\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 19ms/step - loss: 6.9655e-04 - val_loss: 5.2607e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.5012e-04 - val_loss: 6.8761e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.4490e-04 - val_loss: 4.4382e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.0631e-04 - val_loss: 5.2613e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.1851e-04 - val_loss: 4.3122e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2266e-04 - val_loss: 5.4713e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.6950e-04 - val_loss: 3.3982e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 5.5209e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0119 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 8.3519e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.6340e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.4283e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.2498e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.7718e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 9.3150e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.9127e-04 - val_loss: 4.2725e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.1861e-04 - val_loss: 5.6969e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.9330e-04 - val_loss: 4.6750e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.4189e-04 - val_loss: 3.6703e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5580e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.5207e-04 - val_loss: 3.0756e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1657e-04 - val_loss: 4.3154e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0142 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0018 - val_loss: 9.4769e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0015 - val_loss: 9.6269e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 6.7293e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 9.5980e-04 - val_loss: 6.4719e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0011 - val_loss: 6.8901e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0095 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 8.9834e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0105 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 8.8455e-04 - val_loss: 8.4118e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.9628e-04 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.9667e-04 - val_loss: 8.2241e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6312e-04 - val_loss: 7.3756e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.5656e-04 - val_loss: 3.5581e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.5924e-04 - val_loss: 8.1882e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.0954e-04 - val_loss: 3.8251e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.5701e-04 - val_loss: 4.8470e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.7914e-04 - val_loss: 4.3600e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0109 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 8.9981e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0016 - val_loss: 7.9852e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 6.0153e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.7577e-04 - val_loss: 6.5529e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.9736e-04 - val_loss: 8.5183e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.5064e-04 - val_loss: 8.2890e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0247 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 8.7331e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 9.6759e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 9.2069e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 9.3629e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 5.9181e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.4391e-04 - val_loss: 9.3536e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0127 - val_loss: 6.6252e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.9468e-04 - val_loss: 8.2562e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.4800e-04 - val_loss: 5.1397e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.4705e-04 - val_loss: 4.1453e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.2477e-04 - val_loss: 4.6443e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4514e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6065e-04 - val_loss: 6.0821e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4187e-04 - val_loss: 9.6927e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3431e-04 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.0914e-04 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.8899e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0059 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 7.7041e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 9.9839e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.9822e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 6.0705e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.6799e-04 - val_loss: 5.4982e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.9063e-04 - val_loss: 7.8327e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.0453e-04 - val_loss: 4.8527e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0070 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.2776e-04 - val_loss: 5.4972e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 6.1524e-04 - val_loss: 6.1821e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0628e-04 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3737e-04 - val_loss: 6.1511e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1008e-04 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.5847e-04 - val_loss: 3.3087e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.6285e-04 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 9.7438e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 6.5884e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0084 - val_loss: 7.4251e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.5205e-04 - val_loss: 9.7277e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.0553e-04 - val_loss: 6.2606e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.2630e-04 - val_loss: 6.3184e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.9215e-04 - val_loss: 4.0684e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.3639e-04 - val_loss: 3.6370e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 7.3411e-04 - val_loss: 4.0670e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 4.7027e-04 - val_loss: 4.0552e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.1349e-04 - val_loss: 7.0946e-04\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 19ms/step - loss: 5.0836e-04 - val_loss: 4.8190e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0148 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 9.7161e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 7.5716e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 7.8981e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.6442e-04 - val_loss: 4.8702e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.8915e-04 - val_loss: 0.0020\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0310 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 9.6926e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.5568e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 9.0187e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 6.8566e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.3631e-04 - val_loss: 8.5048e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.1572e-04 - val_loss: 6.4967e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0073 - val_loss: 6.3398e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0010 - val_loss: 7.8626e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 5.4543e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.3347e-04 - val_loss: 4.8756e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.4303e-04 - val_loss: 9.1351e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0397e-04 - val_loss: 7.6449e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.9456e-04 - val_loss: 4.2499e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 4.8269e-04 - val_loss: 7.8632e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.8366e-04 - val_loss: 5.3617e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.4783e-04 - val_loss: 3.5853e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0092 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 8.9604e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 6.2762e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 6.5262e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.2040e-04 - val_loss: 8.4921e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.6284e-04 - val_loss: 7.3184e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0127 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.4135e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 9.1170e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 7.1414e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 8.0892e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.8500e-04 - val_loss: 9.1285e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.6749e-04 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0059 - val_loss: 6.1833e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.7769e-04 - val_loss: 5.4200e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 5.4460e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.0413e-04 - val_loss: 4.2098e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.6691e-04 - val_loss: 3.7856e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.5518e-04 - val_loss: 5.0640e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.4527e-04 - val_loss: 4.2955e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4015e-04 - val_loss: 4.3544e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.5070e-04 - val_loss: 3.5379e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1122e-04 - val_loss: 3.5821e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 8.2806e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 8.0519e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 5.8753e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.7205e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.5706e-04 - val_loss: 5.5470e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 8.2552e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 8.1852e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.4911e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 6.5529e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 5.8751e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 6.0665e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 6.0452e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.1817e-04 - val_loss: 9.0324e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0053 - val_loss: 9.5006e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 7.1621e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.0291e-04 - val_loss: 4.9905e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.0886e-04 - val_loss: 8.0299e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.9573e-04 - val_loss: 4.6216e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0176e-04 - val_loss: 3.3919e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.9214e-04 - val_loss: 3.7209e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6073e-04 - val_loss: 4.9674e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.0032e-04 - val_loss: 3.1946e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0091 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 15ms/step - loss: 0.0134 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0052 - val_loss: 8.1046e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.7232e-04 - val_loss: 4.7210e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9689e-04 - val_loss: 6.5250e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.4274e-04 - val_loss: 4.0918e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.8543e-04 - val_loss: 3.2645e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3579e-04 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.8815e-04 - val_loss: 7.4967e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.9285e-04 - val_loss: 7.5332e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.8860e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 33ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 8.1111e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 7.5358e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 9.7312e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.5445e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 8.2705e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0032 - val_loss: 6.7999e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0449e-04 - val_loss: 4.6313e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.0282e-04 - val_loss: 3.8342e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.6172e-04 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.3667e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.2467e-04 - val_loss: 8.7459e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3180e-04 - val_loss: 3.5100e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.4461e-04 - val_loss: 8.1098e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.5921e-04 - val_loss: 3.3694e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.5121e-04 - val_loss: 4.2068e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0095 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0090\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 6.9598e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.0294e-04 - val_loss: 5.8324e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.1210e-04 - val_loss: 6.2987e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0105 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 7.7252e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.3115e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.8241e-04 - val_loss: 8.4007e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.0039e-04 - val_loss: 7.3332e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.3074e-04 - val_loss: 6.7608e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.2698e-04 - val_loss: 5.5617e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.8987e-04 - val_loss: 7.0327e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 6.5777e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2936e-04 - val_loss: 5.0029e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.5797e-04 - val_loss: 4.6759e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8931e-04 - val_loss: 4.8424e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.3114e-04 - val_loss: 4.4093e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.6897e-04 - val_loss: 6.3899e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.5270e-04 - val_loss: 6.9372e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.5049e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.4908e-04 - val_loss: 7.8878e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0128 - val_loss: 0.0064\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 5.3544e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.4370e-04 - val_loss: 5.4451e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.5497e-04 - val_loss: 5.6672e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0102 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 8.8693e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.5324e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 7.3427e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.8492e-04 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 4.6038e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.9641e-04 - val_loss: 5.5841e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.9925e-04 - val_loss: 3.3810e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0318e-04 - val_loss: 8.6577e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.0106e-04 - val_loss: 3.1384e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.2957e-04 - val_loss: 3.1995e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.8057e-04 - val_loss: 7.3045e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0017 - val_loss: 8.4013e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 6.3739e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 8.3039e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 4.8909e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0115 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 9.5965e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.7685e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 6.9883e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0094 - val_loss: 9.2103e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 9.3466e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 6.1929e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.4831e-04 - val_loss: 6.6987e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.0249e-04 - val_loss: 7.3322e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.1298e-04 - val_loss: 4.0102e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.3982e-04 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.2619e-04 - val_loss: 4.5248e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1659e-04 - val_loss: 3.6665e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1850e-04 - val_loss: 3.0456e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0160 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 9.8820e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 9.0808e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0190 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 8.7325e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0089 - val_loss: 7.1734e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 8.0392e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.0674e-04 - val_loss: 6.4110e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.7986e-04 - val_loss: 5.1527e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0162e-04 - val_loss: 3.8128e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3292e-04 - val_loss: 4.3045e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.2195e-04 - val_loss: 3.6857e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.0492e-04 - val_loss: 3.2826e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.7141e-04 - val_loss: 3.8193e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.0077e-04 - val_loss: 8.1491e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 8.0218e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0011 - val_loss: 8.5331e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0125 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 7.8655e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.6687e-04 - val_loss: 8.7106e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.2236e-04 - val_loss: 7.7767e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.6315e-04 - val_loss: 8.9029e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.9586e-04 - val_loss: 6.0219e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.7872e-04 - val_loss: 6.0934e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.7406e-04 - val_loss: 6.2468e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0055 - val_loss: 7.9100e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 8.8488e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 9.2758e-04 - val_loss: 9.5652e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.0552e-04 - val_loss: 9.7729e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.4728e-04 - val_loss: 7.6228e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1152e-04 - val_loss: 4.1156e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6907e-04 - val_loss: 7.4672e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.3067e-04 - val_loss: 3.5124e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3849e-04 - val_loss: 5.3290e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3156e-04 - val_loss: 3.8096e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 9.0848e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 6.8535e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.9053e-04 - val_loss: 5.8258e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 15ms/step - loss: 0.0147 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.8747e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 8.7176e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.6680e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.9637e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 7.4791e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.1775e-04 - val_loss: 6.5590e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0115 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 7.2310e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 8.9774e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.7086e-04 - val_loss: 4.6322e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.5112e-04 - val_loss: 3.7513e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.0165e-04 - val_loss: 3.9339e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.2430e-04 - val_loss: 4.2979e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7147e-04 - val_loss: 3.2285e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 4.3907e-04 - val_loss: 3.3706e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3229e-04 - val_loss: 3.1535e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0079 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.6299e-04 - val_loss: 5.2720e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.4245e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.2842e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0063 - val_loss: 8.4679e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.3668e-04 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.8907e-04 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.0406e-04 - val_loss: 4.7236e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.7661e-04 - val_loss: 4.7650e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1610e-04 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.7226e-04 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.6878e-04 - val_loss: 3.7887e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7879e-04 - val_loss: 6.9496e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.9688e-04 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0136 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0019 - val_loss: 9.7564e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.6664e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2464e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0155 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.0891e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.6173e-04 - val_loss: 8.1851e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.3737e-04 - val_loss: 6.5273e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0136 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 7.1288e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.5422e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.3854e-04 - val_loss: 7.8792e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.3770e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.7398e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.2578e-04 - val_loss: 5.7439e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.4001e-04 - val_loss: 3.9896e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.8742e-04 - val_loss: 8.0119e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.3633e-04 - val_loss: 4.8958e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0100 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0022 - val_loss: 0.0071\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 5s 28ms/step - loss: 0.0016 - val_loss: 6.7488e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0011 - val_loss: 7.5823e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.1590e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.6534e-04 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0130 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 8.6116e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 8.5972e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 7.4582e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.3557e-04 - val_loss: 8.2025e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0085 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 6.3171e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 6.6193e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 6.9117e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4546e-04 - val_loss: 6.4511e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0753e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.2678e-04 - val_loss: 3.2460e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.6671e-04 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9439e-04 - val_loss: 3.0931e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0119 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0018 - val_loss: 9.6008e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 9.2238e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 9.7267e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.1710e-04 - val_loss: 4.6927e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0687e-04 - val_loss: 8.7314e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5399e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5285e-04 - val_loss: 3.4748e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.7575e-04 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.8794e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6269e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6814e-04 - val_loss: 3.5217e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3692e-04 - val_loss: 3.3542e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0105 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0016 - val_loss: 8.7336e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 7.7969e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 8.5901e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 5.5836e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 5.0530e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.4962e-04 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.4542e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.1117e-04 - val_loss: 6.0760e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.0902e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.5521e-04 - val_loss: 6.5875e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0150 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 8.3083e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.6332e-04 - val_loss: 6.2385e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5075e-04 - val_loss: 4.0220e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.2240e-04 - val_loss: 4.9171e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.7173e-04 - val_loss: 6.8734e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.3560e-04 - val_loss: 3.8450e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0857e-04 - val_loss: 7.8327e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2821e-04 - val_loss: 5.1044e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7238e-04 - val_loss: 4.0707e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0123 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 8.8171e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 8.0991e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 7.8404e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0010 - val_loss: 5.8463e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 7.8732e-04 - val_loss: 6.5876e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 18ms/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 9.3512e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 9.2465e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 7.6422e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 6.9524e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.0166e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.9185e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 8.6167e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.5269e-04 - val_loss: 5.3378e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0095 - val_loss: 9.4952e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.5512e-04 - val_loss: 4.9493e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 7.6938e-04 - val_loss: 4.6520e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 6.2155e-04 - val_loss: 6.5845e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 5s 28ms/step - loss: 6.6994e-04 - val_loss: 9.2582e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 5.5678e-04 - val_loss: 4.4674e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 6.3479e-04 - val_loss: 8.1082e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 6.4810e-04 - val_loss: 9.8727e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.5419e-04 - val_loss: 3.7130e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 33ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 5s 30ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 5s 32ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 5s 28ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 8.2014e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 5s 29ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 6s 34ms/step - loss: 0.0016 - val_loss: 6.3066e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 5s 30ms/step - loss: 0.0010 - val_loss: 5.9204e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 5s 28ms/step - loss: 9.7655e-04 - val_loss: 5.5921e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0129 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 9.2206e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 7.3975e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 8.5776e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.0228e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.8104e-04 - val_loss: 7.6042e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0097 - val_loss: 9.9477e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 6.5589e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 8.1364e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.0856e-04 - val_loss: 6.0254e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.7085e-04 - val_loss: 4.3633e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5243e-04 - val_loss: 3.8041e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5045e-04 - val_loss: 3.6902e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5081e-04 - val_loss: 4.0883e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.3010e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2331e-04 - val_loss: 3.4326e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0096 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0211 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0064 - val_loss: 5.5192e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.4862e-04 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.7275e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.8986e-04 - val_loss: 3.7378e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.6342e-04 - val_loss: 4.9769e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.2537e-04 - val_loss: 3.7441e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8588e-04 - val_loss: 9.9051e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 5.1015e-04 - val_loss: 3.2487e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.1977e-04 - val_loss: 5.1961e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 4.7822e-04 - val_loss: 3.5788e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0084 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0018 - val_loss: 9.9388e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 8.7350e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.4175e-04 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.3395e-04 - val_loss: 5.1185e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0159 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 9.8109e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.1439e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.6763e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.3394e-04 - val_loss: 7.3315e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 5.0696e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.7365e-04 - val_loss: 4.8039e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.8872e-04 - val_loss: 5.8283e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2393e-04 - val_loss: 7.7940e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.3480e-04 - val_loss: 5.4575e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.2615e-04 - val_loss: 3.9014e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0289e-04 - val_loss: 6.8339e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.9625e-04 - val_loss: 8.2159e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6526e-04 - val_loss: 4.2237e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 25ms/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0022 - val_loss: 9.5030e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 8.0416e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0010 - val_loss: 9.2679e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 7.7799e-04 - val_loss: 5.5942e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0140 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 9.4275e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 9.5014e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 8.7360e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.4187e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 9.1964e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.5988e-04 - val_loss: 3.8948e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6506e-04 - val_loss: 5.3525e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1596e-04 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9727e-04 - val_loss: 3.5394e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.6900e-04 - val_loss: 3.0958e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.3046e-04 - val_loss: 7.9094e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 4.9620e-04 - val_loss: 0.0022\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 8.6420e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0015 - val_loss: 9.7501e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0015 - val_loss: 7.7938e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 15ms/step - loss: 0.0115 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0088 - val_loss: 8.7102e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.7982e-04 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.7869e-04 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.8929e-04 - val_loss: 7.7378e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.4458e-04 - val_loss: 6.0341e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 6.1957e-04 - val_loss: 5.7946e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3444e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.5256e-04 - val_loss: 9.9194e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4786e-04 - val_loss: 4.0259e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.7084e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 28ms/step - loss: 0.0093 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 7.0372e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 8.5180e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 5.6803e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8283e-04 - val_loss: 6.5545e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.6348e-04 - val_loss: 8.9960e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 7.2490e-04 - val_loss: 9.1057e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0119 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 8.5320e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.3698e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 6.6302e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.6873e-04 - val_loss: 9.8186e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.9107e-04 - val_loss: 6.7699e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.0028e-04 - val_loss: 5.7949e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.6355e-04 - val_loss: 8.0852e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2759e-04 - val_loss: 4.6422e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8805e-04 - val_loss: 8.1801e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 6.8005e-04 - val_loss: 4.9499e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2988e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.8037e-04 - val_loss: 5.8729e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1422e-04 - val_loss: 9.3753e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.4863e-04 - val_loss: 3.6765e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0741e-04 - val_loss: 4.1739e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.4596e-04 - val_loss: 5.7912e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 8.6168e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 7.8628e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 6.5484e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.1796e-04 - val_loss: 0.0021\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0266 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.2588e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.3184e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0017 - val_loss: 7.3803e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 8.3113e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.4315e-04 - val_loss: 5.4607e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.1179e-04 - val_loss: 5.0053e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.3525e-04 - val_loss: 4.7319e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0451e-04 - val_loss: 3.3559e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.9924e-04 - val_loss: 9.2741e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.5501e-04 - val_loss: 4.8521e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.1011e-04 - val_loss: 3.1550e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 9.2592e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 7.2535e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 8.8704e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 6.9924e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0211 - val_loss: 8.0316e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.1709e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.2102e-04 - val_loss: 5.4383e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.4810e-04 - val_loss: 4.7836e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.9565e-04 - val_loss: 4.5344e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.8955e-04 - val_loss: 5.5284e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.2797e-04 - val_loss: 5.5462e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.6708e-04 - val_loss: 3.2772e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 4.6132e-04 - val_loss: 5.5897e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.2854e-04 - val_loss: 3.1800e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 30ms/step - loss: 0.0091 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0018 - val_loss: 8.5282e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0014 - val_loss: 8.6967e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2594e-04 - val_loss: 4.8772e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8199e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9668e-04 - val_loss: 8.2665e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.3722e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 6.8513e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 7.0368e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.3132e-04 - val_loss: 9.9349e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.8379e-04 - val_loss: 7.6976e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.6140e-04 - val_loss: 5.4615e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.3833e-04 - val_loss: 5.9990e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 7.0544e-04 - val_loss: 7.8780e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.1218e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.4924e-04 - val_loss: 5.4659e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.7355e-04 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.9354e-04 - val_loss: 4.2390e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3732e-04 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9256e-04 - val_loss: 3.6684e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3513e-04 - val_loss: 4.1564e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1258e-04 - val_loss: 4.6709e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.0614e-04 - val_loss: 3.4634e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0107 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 5s 29ms/step - loss: 0.0011 - val_loss: 8.0378e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0012 - val_loss: 6.6027e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 9.7782e-04 - val_loss: 5.7243e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0010 - val_loss: 7.4656e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0118 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 7.3527e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 6.1991e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.6366e-04 - val_loss: 5.3074e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.1938e-04 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 6.2804e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.3611e-04 - val_loss: 5.8378e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5464e-04 - val_loss: 6.0827e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.1449e-04 - val_loss: 6.0602e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.4221e-04 - val_loss: 5.3617e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.6378e-04 - val_loss: 4.2377e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6996e-04 - val_loss: 3.8371e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9073e-04 - val_loss: 5.5302e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0646e-04 - val_loss: 4.6585e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0096 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 8.9410e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 6.0383e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0127 - val_loss: 0.0034\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 9.8961e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 8.1395e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 9.1917e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 6.9019e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.2022e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0054 - val_loss: 6.0075e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.9117e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.4778e-04 - val_loss: 4.2699e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.4278e-04 - val_loss: 4.8557e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.3668e-04 - val_loss: 3.3688e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0354e-04 - val_loss: 3.3844e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8484e-04 - val_loss: 3.5627e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.7522e-04 - val_loss: 4.4493e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8483e-04 - val_loss: 5.7321e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0117 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 8.4522e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 7.9504e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 7.4525e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 6.3497e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 8.7630e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.8242e-04 - val_loss: 8.3404e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.4322e-04 - val_loss: 4.9712e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0199 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.9475e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.1469e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.8325e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.6117e-04 - val_loss: 7.9330e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0119 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 7.2632e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 4.6443e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.8777e-04 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.4504e-04 - val_loss: 8.5673e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.2312e-04 - val_loss: 5.1695e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.5557e-04 - val_loss: 7.8260e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.1458e-04 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7198e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.7842e-04 - val_loss: 4.0568e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0120 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0025 - val_loss: 0.0078\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0017 - val_loss: 8.3280e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 7.4144e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 5.8815e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8777e-04 - val_loss: 6.6807e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0179 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 9.0512e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 8.3715e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.0247e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.8343e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0097 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.6588e-04 - val_loss: 5.8823e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.4227e-04 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5778e-04 - val_loss: 3.7760e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8684e-04 - val_loss: 3.7933e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6068e-04 - val_loss: 3.5307e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2711e-04 - val_loss: 3.4365e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0361e-04 - val_loss: 4.6724e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0016 - val_loss: 9.5433e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0013 - val_loss: 6.4389e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 8.5373e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0066 - val_loss: 8.3769e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.5111e-04 - val_loss: 5.0983e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.0343e-04 - val_loss: 4.4060e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.1657e-04 - val_loss: 3.8233e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5088e-04 - val_loss: 3.5848e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.6626e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.2685e-04 - val_loss: 3.3520e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8087e-04 - val_loss: 8.4008e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3008e-04 - val_loss: 3.1915e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.5784e-04 - val_loss: 3.2220e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0120 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 9.7303e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 7.4349e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.3200e-04 - val_loss: 5.7793e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 6.0436e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.9972e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.4974e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 7.7857e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.6849e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.1840e-04 - val_loss: 8.0433e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.0516e-04 - val_loss: 6.1471e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0101 - val_loss: 7.1509e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5085e-04 - val_loss: 6.1141e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.8483e-04 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6350e-04 - val_loss: 5.6428e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.3472e-04 - val_loss: 5.1796e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.8900e-04 - val_loss: 5.6155e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.8138e-04 - val_loss: 5.7837e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.1915e-04 - val_loss: 4.2380e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2499e-04 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4032e-04 - val_loss: 5.7086e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0112 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0016 - val_loss: 9.2969e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0013 - val_loss: 6.4205e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 7.5690e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0176 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.0187e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.4637e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.1022e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.3206e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.7644e-04 - val_loss: 6.5971e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0053 - val_loss: 9.1622e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 5.4221e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.4788e-04 - val_loss: 4.7876e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.1859e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.3549e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8526e-04 - val_loss: 3.7093e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.8663e-04 - val_loss: 3.4632e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0136e-04 - val_loss: 5.0570e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.0133e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8300e-04 - val_loss: 4.5780e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0083 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 9.9054e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 9.1863e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 8.5176e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 9.4611e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 8.2121e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 7.6637e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.9019e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 9.2607e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.3573e-04 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 8.6723e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.6007e-04 - val_loss: 6.0543e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.2719e-04 - val_loss: 7.0123e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0154 - val_loss: 6.7178e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.4023e-04 - val_loss: 5.3722e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.0133e-04 - val_loss: 4.1093e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0881e-04 - val_loss: 9.0357e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0424e-04 - val_loss: 6.1432e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.8221e-04 - val_loss: 5.3286e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1842e-04 - val_loss: 7.1769e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8676e-04 - val_loss: 5.5292e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6142e-04 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9895e-04 - val_loss: 5.4169e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0124 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0117\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 7.9362e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 6.5053e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 9.9522e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.7443e-04 - val_loss: 4.9279e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.5713e-04 - val_loss: 7.3880e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0122 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.6533e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.8371e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9336e-04 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 9.4052e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.7173e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.2980e-04 - val_loss: 8.3671e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0066 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.4693e-04 - val_loss: 6.8906e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.3086e-04 - val_loss: 5.5147e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7908e-04 - val_loss: 6.8903e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.9332e-04 - val_loss: 6.6196e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.2715e-04 - val_loss: 4.6570e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.1779e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0755e-04 - val_loss: 5.6500e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2970e-04 - val_loss: 3.4217e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.1209e-04 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0115 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.1393e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.7550e-04 - val_loss: 0.0022\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0266 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.1839e-04 - val_loss: 9.0686e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.9405e-04 - val_loss: 0.0029\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.9933e-04 - val_loss: 4.4161e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6724e-04 - val_loss: 6.2657e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3924e-04 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6036e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.8929e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0635e-04 - val_loss: 6.1942e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.1057e-04 - val_loss: 8.2163e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0097 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 9.9577e-04 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.4130e-04 - val_loss: 0.0019\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 15ms/step - loss: 0.0170 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 8.8597e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 5.6886e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 20ms/step - loss: 0.0085 - val_loss: 9.0155e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.8895e-04 - val_loss: 8.2728e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.6595e-04 - val_loss: 4.6328e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3031e-04 - val_loss: 6.2639e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.0514e-04 - val_loss: 8.1520e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9395e-04 - val_loss: 5.4372e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8771e-04 - val_loss: 3.5052e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5652e-04 - val_loss: 3.6648e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0189e-04 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4915e-04 - val_loss: 7.2371e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 29ms/step - loss: 0.0095 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 9.7758e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 7.9691e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 7.3373e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 9.6759e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 7.3823e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.8999e-04 - val_loss: 5.2090e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0138 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 6.6530e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 7.2098e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.5077e-04 - val_loss: 5.2061e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.6009e-04 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 7.8288e-04 - val_loss: 5.3302e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0069 - val_loss: 8.2003e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 6.6359e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.7701e-04 - val_loss: 6.7757e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.4838e-04 - val_loss: 4.4811e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.2455e-04 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.1281e-04 - val_loss: 5.3948e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7397e-04 - val_loss: 3.9338e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2553e-04 - val_loss: 5.1607e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8686e-04 - val_loss: 3.6967e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9145e-04 - val_loss: 5.8520e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0029 - val_loss: 0.0080\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 8.8512e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0073 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 8.7133e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0163 - val_loss: 6.8701e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 5.1714e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.1670e-04 - val_loss: 4.6704e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.0429e-04 - val_loss: 5.7854e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8220e-04 - val_loss: 4.0577e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0560e-04 - val_loss: 8.1529e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.8490e-04 - val_loss: 5.2154e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1222e-04 - val_loss: 4.7083e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 4.5427e-04 - val_loss: 6.7321e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0893e-04 - val_loss: 5.5610e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0105 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 9.3401e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 8.5917e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 7.0542e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 7.7009e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.5271e-04 - val_loss: 8.0349e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.8232e-04 - val_loss: 8.1494e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0153 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.2939e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.5706e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.7773e-04 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4343e-04 - val_loss: 6.3227e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.5136e-04 - val_loss: 7.1649e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.4895e-04 - val_loss: 6.7404e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0102 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.9126e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.7985e-04 - val_loss: 7.6940e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8989e-04 - val_loss: 8.7534e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.4784e-04 - val_loss: 4.5124e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.9848e-04 - val_loss: 4.8079e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 5.3160e-04 - val_loss: 3.9218e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0257e-04 - val_loss: 8.4912e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.9051e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.4049e-04 - val_loss: 4.5078e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 8.9832e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 8.5285e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0226 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 8.7803e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.4831e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.7953e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0095 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 6.2162e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 6.6247e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 4.8214e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.6408e-04 - val_loss: 6.2451e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.0347e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.8571e-04 - val_loss: 3.7482e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.5336e-04 - val_loss: 3.6488e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.2247e-04 - val_loss: 3.2260e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 7.7537e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.5601e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0129 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 9.9353e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0048 - val_loss: 6.6948e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.2760e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.7367e-04 - val_loss: 4.0168e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9062e-04 - val_loss: 4.6049e-04\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 20ms/step - loss: 5.8223e-04 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.9427e-04 - val_loss: 8.9208e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.7049e-04 - val_loss: 3.4607e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7717e-04 - val_loss: 4.6258e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.8627e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2989e-04 - val_loss: 4.5657e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0104 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 7.1791e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.9345e-04 - val_loss: 6.8577e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.0288e-04 - val_loss: 7.6336e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.0252e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.5319e-04 - val_loss: 4.9844e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0117 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.3886e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 8.3977e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9676e-04 - val_loss: 5.9174e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 6.1651e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.0344e-04 - val_loss: 6.4436e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.1585e-04 - val_loss: 6.0596e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0136 - val_loss: 8.0038e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.0605e-04 - val_loss: 5.4777e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.1013e-04 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5442e-04 - val_loss: 4.9730e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3669e-04 - val_loss: 8.2426e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8697e-04 - val_loss: 8.2751e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2478e-04 - val_loss: 4.2083e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7483e-04 - val_loss: 3.7292e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8135e-04 - val_loss: 3.7863e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 29ms/step - loss: 0.0104 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 8.6796e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.9449e-04 - val_loss: 0.0019\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 7.6530e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 7.1410e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.6606e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.7586e-04 - val_loss: 9.8160e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6302e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0122 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.3197e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.1136e-04 - val_loss: 6.3635e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5567e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.3766e-04 - val_loss: 4.8655e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0416e-04 - val_loss: 3.4205e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6265e-04 - val_loss: 4.4017e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0112 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0031 - val_loss: 0.0076\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 9.7995e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0166 - val_loss: 0.0105\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0024 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 9.2634e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 9.4668e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 9.0412e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 9.8858e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 8.8437e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.9356e-04 - val_loss: 7.9065e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.1829e-04 - val_loss: 5.4317e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.6374e-04 - val_loss: 3.8146e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.0354e-04 - val_loss: 3.4032e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.4629e-04 - val_loss: 4.4731e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1955e-04 - val_loss: 3.4217e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1193e-04 - val_loss: 9.7155e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7704e-04 - val_loss: 9.6887e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0133 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 7.9185e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 8.4695e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 6.9251e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 5.3541e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 5.0213e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.3867e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.7506e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.9723e-04 - val_loss: 8.5353e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.7238e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.5433e-04 - val_loss: 6.2534e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0066 - val_loss: 6.6367e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8267e-04 - val_loss: 6.4881e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.4029e-04 - val_loss: 3.7261e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.8286e-04 - val_loss: 4.2188e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2077e-04 - val_loss: 3.8401e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.0050e-04 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 5.9811e-04 - val_loss: 3.7733e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 5.7157e-04 - val_loss: 8.7750e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.4342e-04 - val_loss: 3.9749e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.2207e-04 - val_loss: 6.5650e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 34ms/step - loss: 0.0087 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 6.8349e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 7.1563e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2627e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 9.2902e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0116 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.3820e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.2318e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 6.2658e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 7.0152e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.7322e-04 - val_loss: 9.1923e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6550e-04 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4463e-04 - val_loss: 7.5802e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0044 - val_loss: 7.3032e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.5264e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5153e-04 - val_loss: 5.1994e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.6422e-04 - val_loss: 4.0398e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0523e-04 - val_loss: 5.5178e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5024e-04 - val_loss: 3.6733e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6390e-04 - val_loss: 6.1832e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3109e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5029e-04 - val_loss: 3.7807e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0823e-04 - val_loss: 3.4498e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0084 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0017 - val_loss: 9.0464e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 9.6156e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 9.2370e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0018 - val_loss: 6.1174e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.2290e-04 - val_loss: 4.8974e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 7.0460e-04 - val_loss: 7.4919e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0175 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 8.0008e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 6.9475e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 6.8389e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 7.4480e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 6.8427e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.1371e-04 - val_loss: 5.8848e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0048 - val_loss: 6.0482e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.0944e-04 - val_loss: 6.8700e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 3.7596e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7841e-04 - val_loss: 3.9806e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6903e-04 - val_loss: 3.6977e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2799e-04 - val_loss: 3.4568e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5910e-04 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2825e-04 - val_loss: 3.2624e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9330e-04 - val_loss: 6.9721e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4084e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 8.1264e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 6.5792e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.7214e-04 - val_loss: 5.9029e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 7.9040e-04 - val_loss: 6.6272e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.3657e-04 - val_loss: 9.7518e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0160 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 8.9635e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.9069e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.5943e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.9339e-04 - val_loss: 9.8532e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.1883e-04 - val_loss: 7.3238e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 8.2466e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.7826e-04 - val_loss: 4.7497e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.9070e-04 - val_loss: 4.6155e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.6980e-04 - val_loss: 5.6147e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.7060e-04 - val_loss: 6.1270e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8344e-04 - val_loss: 3.9277e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.9835e-04 - val_loss: 4.5286e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6617e-04 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8482e-04 - val_loss: 5.9379e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 6.4969e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 8.0337e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 7.2291e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.1463e-04 - val_loss: 6.1562e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 4.2808e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0195 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 9.4420e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.0313e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 6.9837e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 7.3770e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.1559e-04 - val_loss: 6.7408e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 5.9040e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.9850e-04 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 7.6646e-04 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.7690e-04 - val_loss: 3.6570e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.2291e-04 - val_loss: 4.2429e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.0998e-04 - val_loss: 6.5868e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.4247e-04 - val_loss: 4.6890e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.0590e-04 - val_loss: 5.2947e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 8.2392e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 9.0919e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 8.4188e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 8.1715e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 9s 22ms/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 6.9470e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9923e-04 - val_loss: 3.9700e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.3684e-04 - val_loss: 5.4836e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.3422e-04 - val_loss: 5.2202e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.6536e-04 - val_loss: 3.5979e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.9730e-04 - val_loss: 5.4277e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.8202e-04 - val_loss: 3.3322e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.7784e-04 - val_loss: 4.3859e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.5932e-04 - val_loss: 4.8265e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0089 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.9078e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 8.4015e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.4744e-04 - val_loss: 5.3358e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.4427e-04 - val_loss: 7.0079e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0167 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 7.8418e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 7.4122e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.2018e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4142e-04 - val_loss: 6.6582e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.3027e-04 - val_loss: 6.8216e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.8309e-04 - val_loss: 8.5900e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.1870e-04 - val_loss: 5.9673e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0111 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.4547e-04 - val_loss: 8.4754e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.7142e-04 - val_loss: 8.2589e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.2533e-04 - val_loss: 4.5132e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.7660e-04 - val_loss: 6.3293e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.6141e-04 - val_loss: 9.0558e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2917e-04 - val_loss: 4.5723e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7101e-04 - val_loss: 5.7042e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3718e-04 - val_loss: 5.2294e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.9608e-04 - val_loss: 4.4307e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 8.8632e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 7.8915e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9543e-04 - val_loss: 7.0146e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 7.4913e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0092 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.0031e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.8234e-04 - val_loss: 5.5512e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.7650e-04 - val_loss: 5.9853e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.0940e-04 - val_loss: 5.2030e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.4937e-04 - val_loss: 5.4537e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0026 - val_loss: 7.6270e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 9.9264e-04 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5385e-04 - val_loss: 4.6685e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 7.7450e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2791e-04 - val_loss: 3.9450e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.4302e-04 - val_loss: 5.4347e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0772e-04 - val_loss: 6.5256e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.7460e-04 - val_loss: 3.7549e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.1047e-04 - val_loss: 9.6897e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8661e-04 - val_loss: 4.3264e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0119 - val_loss: 0.0051\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0012 - val_loss: 6.9750e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0010 - val_loss: 6.1643e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.5788e-04 - val_loss: 0.0014\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0157 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 8.4607e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 8.7280e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 7.5763e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0072 - val_loss: 7.1760e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 8.9194e-04 - val_loss: 5.0113e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9238e-04 - val_loss: 4.0433e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.1384e-04 - val_loss: 4.7125e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9820e-04 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3200e-04 - val_loss: 5.2379e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.6394e-04 - val_loss: 3.6278e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 6.6843e-04 - val_loss: 3.7646e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9445e-04 - val_loss: 3.4291e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6634e-04 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0134 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 7.0954e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.1339e-04 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 6.9127e-04 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0118 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.7436e-04 - val_loss: 6.7940e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.5441e-04 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.1376e-04 - val_loss: 9.1560e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.6042e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.4451e-04 - val_loss: 0.0022\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.9848e-04 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 6.9718e-04 - val_loss: 7.0034e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.7035e-04 - val_loss: 5.4061e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6604e-04 - val_loss: 3.9944e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.7917e-04 - val_loss: 3.4915e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1810e-04 - val_loss: 4.8877e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4340e-04 - val_loss: 3.2712e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5006e-04 - val_loss: 9.4361e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0099 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0016 - val_loss: 8.6110e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 6.8782e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 7.2636e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 9.2968e-04 - val_loss: 7.1498e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0350 - val_loss: 0.0037\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 9.5393e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.3275e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 6.0222e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.2476e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0094 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8954e-04 - val_loss: 6.5987e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.7418e-04 - val_loss: 7.5811e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.4502e-04 - val_loss: 7.5530e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.0186e-04 - val_loss: 4.4780e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5268e-04 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3888e-04 - val_loss: 5.9342e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1113e-04 - val_loss: 5.2400e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6520e-04 - val_loss: 5.0422e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0120 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 9.9306e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.6143e-04 - val_loss: 6.2274e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.0140e-04 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 16ms/step - loss: 0.0143 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 8.8477e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0138 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.6768e-04 - val_loss: 5.1047e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8175e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.9453e-04 - val_loss: 3.9356e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.2245e-04 - val_loss: 3.5696e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4144e-04 - val_loss: 4.1386e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 5.4326e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 6.4206e-04 - val_loss: 3.5818e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 4.3319e-04 - val_loss: 6.6133e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.6022e-04 - val_loss: 7.1922e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 12s 30ms/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0016 - val_loss: 8.0594e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.0579e-04 - val_loss: 5.6014e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 7.1966e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 5s 29ms/step - loss: 9.0543e-04 - val_loss: 7.5614e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 6s 16ms/step - loss: 0.0111 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 14ms/step - loss: 0.0011 - val_loss: 8.3757e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.0010 - val_loss: 6.6895e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 9.3172e-04 - val_loss: 8.3865e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 8.2056e-04 - val_loss: 8.6041e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.0850e-04 - val_loss: 6.5353e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.7954e-04 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 8.2912e-04 - val_loss: 5.2341e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0075 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.2989e-04 - val_loss: 0.0010\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.7914e-04 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.8893e-04 - val_loss: 7.9746e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0876e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.5450e-04 - val_loss: 3.2200e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.2697e-04 - val_loss: 8.1995e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.2967e-04 - val_loss: 5.9830e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1450e-04 - val_loss: 9.2651e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.7580e-04 - val_loss: 4.3002e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0080 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 9.6333e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 4.7050e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.3191e-04 - val_loss: 5.7184e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.3681e-04 - val_loss: 7.1474e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0302 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 7.0121e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0068 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0012 - val_loss: 8.7175e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.6442e-04 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.4596e-04 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.3031e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.1835e-04 - val_loss: 6.3827e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.5918e-04 - val_loss: 6.0455e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.6464e-04 - val_loss: 4.9173e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.9097e-04 - val_loss: 6.0847e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.5052e-04 - val_loss: 4.8040e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0090 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0017 - val_loss: 9.1726e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 7.6116e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.8411e-04 - val_loss: 4.8581e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.4774e-04 - val_loss: 4.5446e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0085 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 9.1037e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.8769e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.7838e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.2159e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.4488e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 7.6252e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 6.7661e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.3714e-04 - val_loss: 5.0415e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 9.3226e-04 - val_loss: 8.7561e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.9601e-04 - val_loss: 4.1036e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.1704e-04 - val_loss: 6.6516e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0379e-04 - val_loss: 4.0109e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.7254e-04 - val_loss: 3.8117e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0784e-04 - val_loss: 0.0011\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0099 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 8.2355e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 7.7544e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.8033e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.9942e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 9.0465e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 8.8538e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.7418e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0055 - val_loss: 6.5825e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 4.2651e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.7169e-04 - val_loss: 3.8210e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.2838e-04 - val_loss: 3.8148e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.9928e-04 - val_loss: 3.4721e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9497e-04 - val_loss: 4.3504e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5266e-04 - val_loss: 3.3152e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3290e-04 - val_loss: 3.8371e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9928e-04 - val_loss: 4.0707e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6921e-04 - val_loss: 4.8501e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.4502e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 8.5044e-04 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.3323e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0188 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 9.6464e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 9.9986e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.4440e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 8.2095e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.0981e-04 - val_loss: 8.3028e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.5869e-04 - val_loss: 9.3748e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.3488e-04 - val_loss: 6.2157e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0107 - val_loss: 8.8027e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 8.0341e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.2193e-04 - val_loss: 8.1339e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3061e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3103e-04 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8168e-04 - val_loss: 8.2710e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5363e-04 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.0318e-04 - val_loss: 4.4496e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2439e-04 - val_loss: 3.5403e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9857e-04 - val_loss: 5.8121e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0123 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0015 - val_loss: 8.2306e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.6403e-04 - val_loss: 6.9436e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 9.0855e-04 - val_loss: 6.6142e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 6.5811e-04 - val_loss: 9.1000e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0111 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 7.4940e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 7.8582e-04\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 8.1245e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 21ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.2368e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5736e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1085e-04 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.6984e-04 - val_loss: 5.8591e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3918e-04 - val_loss: 4.1740e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9858e-04 - val_loss: 3.8893e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4061e-04 - val_loss: 7.6102e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5331e-04 - val_loss: 3.7527e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1698e-04 - val_loss: 7.0426e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0078 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 8.5787e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0014 - val_loss: 9.0591e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.7842e-04 - val_loss: 8.4773e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 8.4931e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 8.0834e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 7.4787e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 8.8552e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0082 - val_loss: 6.9575e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.1432e-04 - val_loss: 8.9666e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9952e-04 - val_loss: 4.0490e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2001e-04 - val_loss: 4.5189e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0295e-04 - val_loss: 6.8861e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8341e-04 - val_loss: 5.9204e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7894e-04 - val_loss: 6.5522e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7712e-04 - val_loss: 4.5129e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9640e-04 - val_loss: 5.2558e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.5654e-04 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0096 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 7.2116e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 6.7386e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0010 - val_loss: 8.5603e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 9.0356e-04 - val_loss: 7.2472e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.1113e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.1408e-04 - val_loss: 8.5631e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0222 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.9917e-04 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.4789e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 5.2540e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.8784e-04 - val_loss: 5.1216e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.6316e-04 - val_loss: 7.0520e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 6.5615e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.3695e-04 - val_loss: 5.5360e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.6731e-04 - val_loss: 3.7733e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.3845e-04 - val_loss: 6.8171e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.0693e-04 - val_loss: 3.7581e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.1223e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7705e-04 - val_loss: 7.0218e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5926e-04 - val_loss: 4.5310e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3071e-04 - val_loss: 7.5634e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0089 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 7.1089e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 7.1962e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0334 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.6403e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 7.3919e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 7.4258e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0124 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 6.3423e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.5320e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.6836e-04 - val_loss: 5.6637e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.1020e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 6.7397e-04 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 7.7278e-04 - val_loss: 8.0379e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 6.0276e-04 - val_loss: 4.9572e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 6.7029e-04 - val_loss: 7.8571e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.5726e-04 - val_loss: 3.8058e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 7.6398e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0150 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 8.2360e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.2589e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 9.1882e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.7326e-04 - val_loss: 0.0029\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0115 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 5.1345e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.1629e-04 - val_loss: 4.5770e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3597e-04 - val_loss: 7.2861e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6084e-04 - val_loss: 3.7526e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9568e-04 - val_loss: 5.2643e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6063e-04 - val_loss: 3.9445e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5929e-04 - val_loss: 3.6857e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.7036e-04 - val_loss: 3.8603e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3913e-04 - val_loss: 3.2815e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 27ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 9.6794e-04 - val_loss: 6.2585e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.9880e-04 - val_loss: 6.2343e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 9.4409e-04 - val_loss: 0.0028\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0232 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 9.4901e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 6.0241e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.9700e-04 - val_loss: 7.3213e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 6.7407e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.5288e-04 - val_loss: 5.8086e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.0691e-04 - val_loss: 6.3671e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.9238e-04 - val_loss: 7.0001e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0159 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 5.7492e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 8.3179e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.3245e-04 - val_loss: 5.5064e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2221e-04 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5466e-04 - val_loss: 6.3625e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4290e-04 - val_loss: 3.8171e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1837e-04 - val_loss: 3.6863e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2056e-04 - val_loss: 7.2880e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3767e-04 - val_loss: 7.6246e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0102 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 7.1982e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.9276e-04 - val_loss: 7.7503e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.8546e-04 - val_loss: 8.0538e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0499 - val_loss: 0.0093\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0032 - val_loss: 0.0084\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.8741e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0133 - val_loss: 6.2737e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.4009e-04 - val_loss: 4.6221e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.2558e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.2944e-04 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8549e-04 - val_loss: 5.8375e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7671e-04 - val_loss: 4.1127e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.1915e-04 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.6398e-04 - val_loss: 3.7348e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4243e-04 - val_loss: 3.6728e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0132 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0013 - val_loss: 7.1943e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 6.8143e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0135 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 6.9485e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 9.2478e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9999e-04 - val_loss: 8.3076e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.0837e-04 - val_loss: 6.8253e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4545e-04 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 9.2491e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8960e-04 - val_loss: 7.1269e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8759e-04 - val_loss: 4.0544e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8313e-04 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8022e-04 - val_loss: 4.3934e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9514e-04 - val_loss: 4.9578e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.0221e-04 - val_loss: 3.9767e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.1053e-04 - val_loss: 4.0173e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.6096e-04 - val_loss: 3.3886e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 30ms/step - loss: 0.0100 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0027 - val_loss: 0.0145\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0020 - val_loss: 8.7813e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 9.1606e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 6.6533e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 9.5499e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0176 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 9.1853e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 9.9488e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 6.3787e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 6.5809e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 9.0300e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0098 - val_loss: 7.1507e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 6.8244e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.0153e-04 - val_loss: 5.4416e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1950e-04 - val_loss: 6.9678e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5983e-04 - val_loss: 3.6922e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9397e-04 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9325e-04 - val_loss: 3.6860e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8267e-04 - val_loss: 3.8531e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1033e-04 - val_loss: 9.3220e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1286e-04 - val_loss: 9.9618e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 9.9015e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 8.1613e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.8593e-04 - val_loss: 6.8937e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.0865e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 7.5882e-04 - val_loss: 7.1728e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0126 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 9.9128e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.5181e-04 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.0756e-04 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.5938e-04 - val_loss: 7.1498e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.2929e-04 - val_loss: 8.7171e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.8578e-04 - val_loss: 8.7688e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.0086e-04 - val_loss: 0.0030\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.3515e-04 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.7070e-04 - val_loss: 7.3572e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.4345e-04 - val_loss: 3.8572e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.3223e-04 - val_loss: 6.6798e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.9628e-04 - val_loss: 4.0819e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.5183e-04 - val_loss: 5.3900e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1254e-04 - val_loss: 6.3284e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.6812e-04 - val_loss: 4.6536e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0124 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.7322e-04 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0206 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.1022e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.8105e-04 - val_loss: 6.9465e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.1236e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 9.0140e-04 - val_loss: 7.4508e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.7770e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.7841e-04 - val_loss: 5.5420e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0096 - val_loss: 7.5260e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.4527e-04 - val_loss: 4.7244e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1072e-04 - val_loss: 4.1972e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.8385e-04 - val_loss: 6.5271e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.6808e-04 - val_loss: 3.4470e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.1444e-04 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0665e-04 - val_loss: 4.1471e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.5798e-04 - val_loss: 3.4468e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.8870e-04 - val_loss: 9.1921e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3388e-04 - val_loss: 0.0013\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0021 - val_loss: 9.8561e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0021 - val_loss: 7.8965e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8261e-04 - val_loss: 4.5640e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.0586e-04 - val_loss: 9.5776e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.7824e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 5.8226e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 5.7205e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.3723e-04 - val_loss: 4.9374e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.5135e-04 - val_loss: 4.8267e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.6230e-04 - val_loss: 6.0693e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.4498e-04 - val_loss: 7.8694e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0046 - val_loss: 9.3377e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 5.5863e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.9532e-04 - val_loss: 5.0729e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.0377e-04 - val_loss: 5.4853e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5138e-04 - val_loss: 5.3648e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7187e-04 - val_loss: 3.9161e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1701e-04 - val_loss: 4.0290e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4594e-04 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0734e-04 - val_loss: 3.6949e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2331e-04 - val_loss: 7.9614e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0106 - val_loss: 0.0042\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 9.9050e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 9.3849e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0016 - val_loss: 8.4403e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0012 - val_loss: 5.5419e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0258 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0015 - val_loss: 9.2922e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 9.9703e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 8.0649e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 7.9201e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.9980e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 6.0081e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0042 - val_loss: 9.8102e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 4.6857e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.7591e-04 - val_loss: 4.2991e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.1034e-04 - val_loss: 4.2133e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.6269e-04 - val_loss: 3.6517e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6159e-04 - val_loss: 7.2724e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.0899e-04 - val_loss: 3.8004e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.9529e-04 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.3890e-04 - val_loss: 3.1010e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 15ms/step - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 8.4524e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 21ms/step - loss: 0.0108 - val_loss: 9.8703e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 4.5559e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.1403e-04 - val_loss: 4.9280e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.2808e-04 - val_loss: 8.8578e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.7320e-04 - val_loss: 3.4673e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.7964e-04 - val_loss: 5.4148e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.3332e-04 - val_loss: 5.7134e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.9881e-04 - val_loss: 4.3480e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2717e-04 - val_loss: 4.9602e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 30ms/step - loss: 0.0080 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0017 - val_loss: 8.4262e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 6.9517e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 8.5616e-04 - val_loss: 5.3905e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 8.1638e-04 - val_loss: 5.8147e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 8.5823e-04 - val_loss: 7.8237e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 14ms/step - loss: 0.0231 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 9.3107e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.8697e-04 - val_loss: 8.1104e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.2528e-04 - val_loss: 9.1520e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4147e-04 - val_loss: 7.2401e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6802e-04 - val_loss: 6.3785e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0080 - val_loss: 7.9832e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 4.5205e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.2691e-04 - val_loss: 4.0205e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7982e-04 - val_loss: 3.8728e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7584e-04 - val_loss: 6.1765e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9630e-04 - val_loss: 3.5271e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2732e-04 - val_loss: 5.0010e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0530e-04 - val_loss: 9.4086e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1249e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2540e-04 - val_loss: 3.8165e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 8.6733e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0011 - val_loss: 9.4128e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 7.7441e-04 - val_loss: 7.7758e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0132 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 9.0203e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 8.3948e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0010 - val_loss: 8.4678e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.3455e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 7.8444e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.0900e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.2834e-04 - val_loss: 6.2893e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0092 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 7.7150e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 5.1430e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.8116e-04 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.1564e-04 - val_loss: 5.4163e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5897e-04 - val_loss: 7.5739e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.0723e-04 - val_loss: 5.9040e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6164e-04 - val_loss: 5.6980e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7869e-04 - val_loss: 6.6544e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1124e-04 - val_loss: 3.8118e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 9.4592e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 7.5531e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0199 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 7.3815e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 6.9313e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 9.3408e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 4.2051e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9824e-04 - val_loss: 9.3739e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.4545e-04 - val_loss: 3.3908e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.0497e-04 - val_loss: 9.0507e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7519e-04 - val_loss: 4.3677e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.9782e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.5853e-04 - val_loss: 4.9182e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.2945e-04 - val_loss: 3.2683e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 8.5404e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 7.8133e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 8.2746e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 6.8619e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8578e-04 - val_loss: 5.4252e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.4930e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 5.1193e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.0791e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9951e-04 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.0531e-04 - val_loss: 0.0028\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0125 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.0575e-04 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.8862e-04 - val_loss: 5.5170e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.8533e-04 - val_loss: 4.7294e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.8854e-04 - val_loss: 3.5787e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.1839e-04 - val_loss: 9.3864e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 4.6444e-04 - val_loss: 4.1991e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.8416e-04 - val_loss: 3.8418e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.5581e-04 - val_loss: 3.9806e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0014 - val_loss: 8.3071e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.5650e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.9655e-04 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.9558e-04 - val_loss: 5.4853e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0161 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.1072e-04 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.0503e-04 - val_loss: 7.3413e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6948e-04 - val_loss: 6.2640e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 8.6952e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.8484e-04 - val_loss: 4.8681e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.3245e-04 - val_loss: 7.2905e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5256e-04 - val_loss: 4.2043e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9458e-04 - val_loss: 7.4316e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6240e-04 - val_loss: 3.9511e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9955e-04 - val_loss: 3.7747e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0364e-04 - val_loss: 4.1773e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.9518e-04 - val_loss: 4.3354e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 29ms/step - loss: 0.0132 - val_loss: 0.0038\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0019 - val_loss: 9.4696e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 9.6132e-04 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 9.2580e-04 - val_loss: 6.9381e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 8.6336e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 8.8170e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 9.3314e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0037 - val_loss: 7.0178e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 6.8339e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.3962e-04 - val_loss: 6.6439e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.6085e-04 - val_loss: 4.1829e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1356e-04 - val_loss: 0.0038\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.3123e-04 - val_loss: 4.1227e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.9103e-04 - val_loss: 4.8651e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5090e-04 - val_loss: 4.2568e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6837e-04 - val_loss: 3.6153e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.8378e-04 - val_loss: 5.3043e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0015 - val_loss: 9.4746e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.4895e-04 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 6.0059e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.2219e-04 - val_loss: 6.6109e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0084 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 9.4126e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.1313e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9642e-04 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4772e-04 - val_loss: 8.3728e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.3621e-04 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6447e-04 - val_loss: 6.4738e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.3782e-04 - val_loss: 8.6286e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0086 - val_loss: 5.2122e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8649e-04 - val_loss: 7.1619e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.9768e-04 - val_loss: 4.0551e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0232e-04 - val_loss: 9.7165e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.0673e-04 - val_loss: 5.6801e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7217e-04 - val_loss: 7.8178e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.3123e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.9529e-04 - val_loss: 6.8542e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.0193e-04 - val_loss: 5.4559e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.3489e-04 - val_loss: 8.8619e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 13s 36ms/step - loss: 0.0112 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0019 - val_loss: 9.2775e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0014 - val_loss: 6.5341e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 9.8142e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.3305e-04 - val_loss: 5.4903e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.7954e-04 - val_loss: 6.4726e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0219 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 6.9262e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 7.8738e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.3690e-04 - val_loss: 7.6920e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 6.1808e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.4264e-04 - val_loss: 7.5689e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0107 - val_loss: 7.6533e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 8.1825e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.6663e-04 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0386e-04 - val_loss: 6.0213e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7512e-04 - val_loss: 3.8053e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0615e-04 - val_loss: 6.9539e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0151e-04 - val_loss: 8.6121e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0013e-04 - val_loss: 4.5619e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6678e-04 - val_loss: 3.2305e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1386e-04 - val_loss: 3.3027e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0103 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 8.0725e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 5.8301e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 8.9727e-04 - val_loss: 6.5739e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.5168e-04 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.0706e-04 - val_loss: 5.2794e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0150 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 8.7131e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 8.0270e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.8657e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.0813e-04 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0010 - val_loss: 6.4859e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0061 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.1699e-04 - val_loss: 7.7505e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 9.4358e-04 - val_loss: 3.9303e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.4775e-04 - val_loss: 4.1463e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6590e-04 - val_loss: 4.5942e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.1314e-04 - val_loss: 3.4826e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.3691e-04 - val_loss: 7.2619e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.6816e-04 - val_loss: 3.4355e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5143e-04 - val_loss: 4.1936e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0101 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 8.4231e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 7.3767e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0116 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 8.6075e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.8349e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 8.8761e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 7.3344e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 6.8037e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 6.9971e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 23ms/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 4.3128e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.9943e-04 - val_loss: 4.6359e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.3210e-04 - val_loss: 4.5479e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.2550e-04 - val_loss: 4.7556e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.6789e-04 - val_loss: 4.5289e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.7126e-04 - val_loss: 6.7031e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.7747e-04 - val_loss: 8.1576e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.1673e-04 - val_loss: 4.0237e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.4367e-04 - val_loss: 4.4464e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0079 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0024 - val_loss: 8.9580e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0012 - val_loss: 9.4691e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0011 - val_loss: 6.4862e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8432e-04 - val_loss: 6.5686e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0184 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.5203e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6900e-04 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.8372e-04 - val_loss: 6.6790e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6367e-04 - val_loss: 8.1744e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.8118e-04 - val_loss: 6.2892e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.5390e-04 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 7s 21ms/step - loss: 0.0066 - val_loss: 6.9233e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 7.5673e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5677e-04 - val_loss: 7.4828e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1270e-04 - val_loss: 6.0742e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5122e-04 - val_loss: 6.6718e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.3008e-04 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2908e-04 - val_loss: 3.3792e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.9454e-04 - val_loss: 3.9463e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 4.6562e-04 - val_loss: 3.9421e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.3222e-04 - val_loss: 3.7787e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0105 - val_loss: 0.0152\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0037 - val_loss: 0.0083\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 8.3356e-04 - val_loss: 9.1674e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 7.1524e-04 - val_loss: 6.5035e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 7.7829e-04 - val_loss: 5.6442e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0086 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 8.6879e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.9782e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 5.8345e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9045e-04 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9529e-04 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.3688e-04 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.3766e-04 - val_loss: 5.2705e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0068 - val_loss: 6.1062e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.4162e-04 - val_loss: 7.7674e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9793e-04 - val_loss: 6.0982e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9072e-04 - val_loss: 4.7974e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1670e-04 - val_loss: 6.5768e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4239e-04 - val_loss: 3.7227e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0437e-04 - val_loss: 3.6205e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0117e-04 - val_loss: 3.5886e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4158e-04 - val_loss: 5.1380e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6599e-04 - val_loss: 3.3902e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 28ms/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0018 - val_loss: 9.6475e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 7.9101e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 9.8188e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 9.3026e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.4478e-04 - val_loss: 7.7851e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.7572e-04 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0099 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 9.9307e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 7.5956e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.5643e-04 - val_loss: 7.8927e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.6406e-04 - val_loss: 9.2676e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0010 - val_loss: 9.1438e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.9855e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.9323e-04 - val_loss: 5.3355e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 4.2658e-04\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 19ms/step - loss: 8.7762e-04 - val_loss: 4.6064e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.8949e-04 - val_loss: 3.6358e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 5.8637e-04 - val_loss: 4.4237e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.1928e-04 - val_loss: 6.7161e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.6371e-04 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.5800e-04 - val_loss: 7.3678e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1896e-04 - val_loss: 4.8375e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1668e-04 - val_loss: 6.1170e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0106 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.5121e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.8652e-04 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0419 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 9.4287e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 7.1110e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 6.9284e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.1739e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 22ms/step - loss: 0.0108 - val_loss: 9.9049e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 6.5110e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.6736e-04 - val_loss: 5.2269e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.5897e-04 - val_loss: 4.4104e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.2622e-04 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.0359e-04 - val_loss: 4.7119e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.1880e-04 - val_loss: 6.2401e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.5576e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.8991e-04 - val_loss: 3.5198e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 5.3971e-04 - val_loss: 3.4825e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0092 - val_loss: 0.0022\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0021 - val_loss: 9.7190e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 27ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 9.4938e-04 - val_loss: 5.0982e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 8.9825e-04 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0084 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 8.6864e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.4566e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.1094e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 7.5390e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.9078e-04 - val_loss: 5.8841e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.4893e-04 - val_loss: 7.0536e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.7309e-04 - val_loss: 5.4872e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0088 - val_loss: 7.8161e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.0886e-04 - val_loss: 4.8198e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8346e-04 - val_loss: 4.8962e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.6727e-04 - val_loss: 4.2439e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3557e-04 - val_loss: 3.6435e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2084e-04 - val_loss: 3.7380e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.7186e-04 - val_loss: 4.2160e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.2651e-04 - val_loss: 3.4528e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1760e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 4.7589e-04 - val_loss: 5.0056e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0094 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 6.6060e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 8.7208e-04 - val_loss: 8.4155e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 8.9607e-04 - val_loss: 7.2504e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0109 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 9.7233e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.5962e-04 - val_loss: 7.3712e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.1273e-04 - val_loss: 5.1656e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 8.2787e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.8076e-04 - val_loss: 7.4935e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.4222e-04 - val_loss: 7.2774e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0115 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 6.8518e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.6412e-04 - val_loss: 5.3191e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 7.1511e-04 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.4405e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6488e-04 - val_loss: 4.0223e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.5948e-04 - val_loss: 5.1989e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.6631e-04 - val_loss: 5.2484e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6530e-04 - val_loss: 9.5500e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0340e-04 - val_loss: 6.2896e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0098 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 9.9373e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 6.2280e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.5845e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 9.9947e-04 - val_loss: 4.7222e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 7.5657e-04 - val_loss: 0.0023\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0272 - val_loss: 0.0058\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.8309e-04 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.7083e-04 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.2301e-04 - val_loss: 7.0107e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.5914e-04 - val_loss: 0.0030\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0089 - val_loss: 9.9206e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 4.5976e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.5647e-04 - val_loss: 6.4266e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.9794e-04 - val_loss: 3.5127e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.1401e-04 - val_loss: 4.5005e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 5.0879e-04 - val_loss: 5.0704e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7281e-04 - val_loss: 5.7953e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2630e-04 - val_loss: 3.4276e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.2502e-04 - val_loss: 3.6144e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7507e-04 - val_loss: 6.3520e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0017 - val_loss: 8.6386e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 5s 30ms/step - loss: 0.0014 - val_loss: 6.7296e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0014 - val_loss: 5.4870e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 27ms/step - loss: 7.6214e-04 - val_loss: 5.1903e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 7.3974e-04 - val_loss: 6.6934e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 6.4776e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 7.7261e-04 - val_loss: 3.8090e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.1735e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 9.3743e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.8704e-04 - val_loss: 6.2662e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.6946e-04 - val_loss: 5.3445e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.2927e-04 - val_loss: 7.0421e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.5031e-04 - val_loss: 6.2742e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.8947e-04 - val_loss: 7.5556e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0060 - val_loss: 8.0039e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.3857e-04 - val_loss: 4.3399e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 6.4326e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.4531e-04 - val_loss: 0.0045\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.8268e-04 - val_loss: 3.5172e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.0838e-04 - val_loss: 4.8441e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.4182e-04 - val_loss: 5.0347e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.5916e-04 - val_loss: 4.0105e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.5835e-04 - val_loss: 3.3980e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.1461e-04 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0134 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0016 - val_loss: 9.2809e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 5s 27ms/step - loss: 0.0013 - val_loss: 8.2476e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0015 - val_loss: 6.4981e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0012 - val_loss: 6.8360e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0165 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 9.7726e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.4016e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.3346e-04 - val_loss: 7.5401e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.7895e-04 - val_loss: 6.4737e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.6977e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.8658e-04 - val_loss: 0.0010\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0095 - val_loss: 6.3564e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.0784e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 9.3024e-04 - val_loss: 4.6743e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8381e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8771e-04 - val_loss: 8.2121e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.7500e-04 - val_loss: 5.0991e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8563e-04 - val_loss: 4.3514e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7422e-04 - val_loss: 4.3164e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1780e-04 - val_loss: 3.5408e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6771e-04 - val_loss: 5.2737e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0106 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 9.1561e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.0016 - val_loss: 6.8853e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 9.7093e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0011 - val_loss: 6.3780e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.4151e-04 - val_loss: 7.9978e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 9.2195e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 7.3953e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.8501e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.4165e-04 - val_loss: 9.6047e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 9.0063e-04 - val_loss: 6.5702e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 8.2787e-04 - val_loss: 5.9415e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0075 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0015 - val_loss: 6.3334e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 9.2905e-04 - val_loss: 9.5404e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 8.1981e-04 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 7.1549e-04 - val_loss: 4.3028e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.7830e-04 - val_loss: 8.8798e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.2262e-04 - val_loss: 3.6995e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.4559e-04 - val_loss: 3.5658e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6644e-04 - val_loss: 6.8983e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.3652e-04 - val_loss: 0.0012\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0097 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.3747e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 8.8692e-04 - val_loss: 9.9520e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0105 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 7.7420e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.1336e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 7.2374e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 6.7605e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.1354e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 7.2184e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.5101e-04 - val_loss: 9.7092e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 7.2570e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.5836e-04 - val_loss: 3.8479e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.5646e-04 - val_loss: 4.0720e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.6461e-04 - val_loss: 8.0811e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 6.1533e-04 - val_loss: 3.5607e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.0999e-04 - val_loss: 4.0952e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.3443e-04 - val_loss: 4.8358e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 5.0393e-04 - val_loss: 4.0318e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0106 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0018 - val_loss: 8.3901e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.9516e-04 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 9.3864e-04 - val_loss: 8.0502e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 9.2708e-04 - val_loss: 8.1294e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0090 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 9.5754e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.7440e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.3865e-04 - val_loss: 7.1532e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.6393e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.5551e-04 - val_loss: 6.1905e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.3853e-04 - val_loss: 5.4798e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 7.1347e-04 - val_loss: 5.8880e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 6.7325e-04 - val_loss: 6.6548e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0087 - val_loss: 0.0023\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 5.0413e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8841e-04 - val_loss: 6.2353e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.0363e-04 - val_loss: 7.7001e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.2581e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.8702e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.7883e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 7.1354e-04 - val_loss: 4.0980e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 5.3531e-04 - val_loss: 6.8096e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6709e-04 - val_loss: 3.7045e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 27ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 9.3007e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0016 - val_loss: 6.6032e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.2197e-04 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 9.0751e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 8.5156e-04 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 6.4789e-04 - val_loss: 7.0007e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.1973e-04 - val_loss: 5.8546e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 9.5341e-04 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.8517e-04 - val_loss: 6.9535e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 7.3669e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 7.7300e-04 - val_loss: 0.0016\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0099 - val_loss: 5.9985e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 5.6028e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.0821e-04 - val_loss: 4.2657e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 8.5419e-04 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 6.9779e-04 - val_loss: 8.4386e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.8033e-04 - val_loss: 3.6118e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.3202e-04 - val_loss: 3.9954e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 6.4982e-04 - val_loss: 3.3013e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 5.1819e-04 - val_loss: 7.4908e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.0384e-04 - val_loss: 4.0302e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 26ms/step - loss: 0.0089 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0019 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0017 - val_loss: 8.9763e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0012 - val_loss: 7.9160e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 5.6608e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0011 - val_loss: 5.9486e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 8.2015e-04 - val_loss: 6.2448e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 13ms/step - loss: 0.0278 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.6476e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.2706e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 9.6455e-04 - val_loss: 5.7008e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.3630e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 8.2991e-04 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 7.8993e-04 - val_loss: 0.0038\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 21ms/step - loss: 0.0046 - val_loss: 6.1562e-04\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8658e-04 - val_loss: 6.5200e-04\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 8.8822e-04 - val_loss: 7.8351e-04\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1362e-04 - val_loss: 4.0786e-04\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 6.1934e-04 - val_loss: 3.8975e-04\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 6.8266e-04 - val_loss: 5.1108e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.7881e-04 - val_loss: 7.1262e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 5.6921e-04 - val_loss: 8.9204e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 7.2786e-04 - val_loss: 5.2504e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 5.4757e-04 - val_loss: 5.3722e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 28ms/step - loss: 0.0098 - val_loss: 0.0017\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0011 - val_loss: 7.1549e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 7.5197e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 7.0677e-04 - val_loss: 4.7132e-04\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 5s 14ms/step - loss: 0.0274 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 7.1601e-04\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0010 - val_loss: 6.5574e-04\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.7377e-04 - val_loss: 6.4196e-04\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 9.9958e-04 - val_loss: 6.1858e-04\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 8.7361e-04 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "li = []\n",
    "\n",
    "for r in range(2, 7):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "\n",
    "\n",
    "combili = []\n",
    "        \n",
    "for kk in li :\n",
    "    \n",
    "    kk.append(0)\n",
    "#     print(kk)\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(GRU(32,return_sequences=True,input_shape=(15,len(kk))))\n",
    "    model.add(GRU(32,return_sequences=True))\n",
    "    model.add(GRU(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "    train_predict.shape, test_predict.shape\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "    gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    gru_r2 = r2_score(y_test,test_predict)\n",
    "    \n",
    "\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(32,return_sequences=True,input_shape=(15,len(kk)), activation='tanh'))\n",
    "    model.add(LSTM(32,return_sequences=True))\n",
    "    model.add(GRU(32,return_sequences=True))\n",
    "    model.add(GRU(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "    lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(16, return_sequences=True,input_shape=(15,len(kk)), activation='tanh'))\n",
    "    model.add(LSTM(16, return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=5,verbose=1)\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "    lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    lstm_r2 = r2_score(y_test,test_predict)\n",
    "    algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "    rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "    r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "    def listToString(str_list):\n",
    "        result = \"\"\n",
    "        for s in str_list:\n",
    "            result += s + \" \"\n",
    "        return result.strip()\n",
    "\n",
    "\n",
    "    col_li = list(df.iloc[:,kk].columns)\n",
    "    result = listToString(col_li)\n",
    "    \n",
    "    \n",
    "    data = {'data' : result,\n",
    "        'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "            'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "            'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "    comparison = pd.DataFrame(data)\n",
    "\n",
    "    comparison = comparison.sort_values(['r2'], ascending=False)\n",
    "    \n",
    "    combili.append(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9672cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(combili, axis=0)\n",
    "merged_df.to_csv('./gogo.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "edb14b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\n",
       "WMA foreign_보유수량 RSI MOM MA20 종가        0.970595\n",
       "WMA PER MA20 종가                         0.970562\n",
       "WMA PER foreign_보유수량 RSI MA20 종가        0.969845\n",
       "WMA MOM 종가                              0.969667\n",
       "PER RSI MOM 종가                          0.969155\n",
       "                                          ...   \n",
       "MA5 PER foreign_보유수량 RSI 종가             0.906769\n",
       "WMA PER MOM MA20 종가                     0.906201\n",
       "WMA PER foreign_보유수량 RSI MOM MA20 종가    0.903069\n",
       "MA5 foreign_보유수량 RSI MOM MA20 종가        0.882629\n",
       "foreign_보유수량 RSI MA20 종가                0.845648\n",
       "Name: r2, Length: 119, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = merged_df.groupby(merged_df['data'])['r2'].mean().sort_values(ascending=False)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1d2706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li=[]\n",
    "for r in range(1, 3):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18496e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=[]\n",
    "for r in range(3, 4):\n",
    "    \n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6aadc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=[]\n",
    "for r in range(4, 5):\n",
    "    \n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a09e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=[]\n",
    "for r in range(5, 8):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8d347",
   "metadata": {},
   "source": [
    "# 최종 : 종가 WMA foreign_보유수량 RSI MOM MA20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2a9170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "\n",
    "for r in range(1, 3):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c3aaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "\n",
    "for r in range(3, 4):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd60b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "\n",
    "for r in range(4, 5):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450a5d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "li = []\n",
    "\n",
    "for r in range(5, 8):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc6ed1",
   "metadata": {},
   "source": [
    "# 시계열 알고리즘 epochs 1000 두고 8개 조합 다 돌려보고, 각자 성능 가장 좋은 변수채택 (NEURON 사용 (클라우드슈퍼컴)) (1,3 / 3,4 / 4,5 / 5,8 슬라이싱) (EarlyStopping 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "li = []\n",
    "\n",
    "for r in range(1, 8):\n",
    "    # 1부터 7까지의 수 중에서 r개를 뽑는 조합 생성\n",
    "    for combination in combinations(range(1, 8), r):\n",
    "        a = list(combination)\n",
    "        li.append(a)\n",
    "\n",
    "\n",
    "combili = []\n",
    "        \n",
    "for kk in li :\n",
    "    \n",
    "    kk.append(0)\n",
    "#     print(kk)\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(GRU(32,return_sequences=True,input_shape=(15,len(kk))))\n",
    "    model.add(GRU(32,return_sequences=True))\n",
    "    model.add(GRU(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    stop = keras.callbacks.EarlyStopping(patienc=30, restore_best_weights=True)\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "    train_predict.shape, test_predict.shape\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "    gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    gru_r2 = r2_score(y_test,test_predict)\n",
    "    \n",
    "\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(32,return_sequences=True,input_shape=(15,len(kk)), activation='tanh'))\n",
    "    model.add(LSTM(32,return_sequences=True))\n",
    "    model.add(GRU(32,return_sequences=True))\n",
    "    model.add(GRU(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "    lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "    df = pd.read_csv('./stock_v11.csv', encoding='cp949')\n",
    "\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "    max_val = max(df['종가'])\n",
    "    min_val = min(df['종가'])\n",
    "\n",
    "    training_size=int(len(sdf)*0.70)\n",
    "    test_size=len(sdf)-training_size\n",
    "    train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "    def create_dataset(dataset, time_step=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), kk]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 15\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(32, return_sequences=True,input_shape=(15,len(kk)), activation='tanh'))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "    train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "    test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "    lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "    lstm_r2 = r2_score(y_test,test_predict)\n",
    "    algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "    rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "    r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "    def listToString(str_list):\n",
    "        result = \"\"\n",
    "        for s in str_list:\n",
    "            result += s + \" \"\n",
    "        return result.strip()\n",
    "\n",
    "\n",
    "    col_li = list(df.iloc[:,kk].columns)\n",
    "    result = listToString(col_li)\n",
    "    \n",
    "    \n",
    "    data = {'data' : result,\n",
    "        'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "            'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "            'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "    comparison = pd.DataFrame(data)    \n",
    "    combili.append(comparison)\n",
    "\n",
    "merged_df = pd.concat(combili, axis=0)\n",
    "merged_df = merged_df.sort_values(['r2'], ascending=False)\n",
    "merged_df.to_csv('./gogo1.csv', encoding='cp949', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
