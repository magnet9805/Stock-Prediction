{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101a34a1",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 최적화 / 노드수,layer 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee06b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81084d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1060.821149</td>\n",
       "      <td>0.976107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1061.459099</td>\n",
       "      <td>0.976078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1065.928089</td>\n",
       "      <td>0.975876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1066.931401</td>\n",
       "      <td>0.975831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1069.690636</td>\n",
       "      <td>0.975706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3119.481703</td>\n",
       "      <td>0.793388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>3121.460831</td>\n",
       "      <td>0.793126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>3124.448762</td>\n",
       "      <td>0.792730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>3143.635678</td>\n",
       "      <td>0.790176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>3150.942674</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators max_depth  min_samples_leaf  min_samples_split         RMSE  \\\n",
       "0            200         5                 1                  2  1060.821149   \n",
       "0            300         5                 1                  5  1061.459099   \n",
       "0            100         5                 1                  5  1065.928089   \n",
       "0            500         5                 1                  5  1066.931401   \n",
       "0            500         5                 1                  2  1069.690636   \n",
       "..           ...       ...               ...                ...          ...   \n",
       "0            300        20                30                 10  3119.481703   \n",
       "0            100      None                30                 25  3121.460831   \n",
       "0            200         5                30                 25  3124.448762   \n",
       "0            100        10                30                 15  3143.635678   \n",
       "0            100        20                30                 15  3150.942674   \n",
       "\n",
       "          R2  \n",
       "0   0.976107  \n",
       "0   0.976078  \n",
       "0   0.975876  \n",
       "0   0.975831  \n",
       "0   0.975706  \n",
       "..       ...  \n",
       "0   0.793388  \n",
       "0   0.793126  \n",
       "0   0.792730  \n",
       "0   0.790176  \n",
       "0   0.789200  \n",
       "\n",
       "[864 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,1,2,6]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "df_li = []\n",
    "\n",
    "n_li = [100,200,300,500]\n",
    "md_li = [None,5,10,15,20,30]\n",
    "msl_li = [1,5,10,15,20,30]\n",
    "mss_li = [2,5,10,15,25,30]\n",
    "\n",
    "for n in n_li :\n",
    "    for md in md_li:\n",
    "        for msl in msl_li :\n",
    "            for mss in mss_li:\n",
    "                \n",
    "                time_step = 1\n",
    "                X_train, y_train = create_dataset(train_data, time_step)\n",
    "                X_test, y_test = create_dataset(test_data, time_step)\n",
    "                X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "                X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "                \n",
    "                rf = RandomForestRegressor(n_estimators=n, max_depth=md,min_samples_leaf=msl,min_samples_split=mss)\n",
    "                rf.fit(X_train, y_train)\n",
    "                train_predict=rf.predict(X_train)\n",
    "                test_predict=rf.predict(X_test)\n",
    "\n",
    "                train_predict = train_predict.reshape(-1,1)\n",
    "                train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_train = y_train.reshape(-1,1)\n",
    "                y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "                test_predict = test_predict.reshape(-1,1)\n",
    "                test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_test = y_test.reshape(-1,1)\n",
    "                y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "                rf_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "                rf_r2 = r2_score(y_test,test_predict)\n",
    "                \n",
    "                data = {'n_estimators' : [n], 'max_depth':[md], 'min_samples_leaf':[msl], 'min_samples_split':[mss],\n",
    "                       'RMSE':[rf_rmse], 'R2':[rf_r2]}\n",
    "                df = pd.DataFrame(data)\n",
    "                df_li.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_li, axis=0)\n",
    "merged_df = merged_df.sort_values(['R2'], ascending=False)\n",
    "merged_df.to_csv('./rf_hyper.csv', encoding='cp949', index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e7e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>metric</th>\n",
       "      <th>leaf_size</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>10</td>\n",
       "      <td>1008.580179</td>\n",
       "      <td>0.978402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>50</td>\n",
       "      <td>1008.732711</td>\n",
       "      <td>0.978396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>30</td>\n",
       "      <td>1008.732711</td>\n",
       "      <td>0.978396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>50</td>\n",
       "      <td>1008.732711</td>\n",
       "      <td>0.978396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>30</td>\n",
       "      <td>1008.732711</td>\n",
       "      <td>0.978396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>50</td>\n",
       "      <td>1227.304037</td>\n",
       "      <td>0.968019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>30</td>\n",
       "      <td>1227.304037</td>\n",
       "      <td>0.968019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>20</td>\n",
       "      <td>1227.357143</td>\n",
       "      <td>0.968016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>20</td>\n",
       "      <td>1227.357143</td>\n",
       "      <td>0.968016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>20</td>\n",
       "      <td>1227.564466</td>\n",
       "      <td>0.968005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  weights     metric  leaf_size         RMSE        R2\n",
       "0            10  uniform  manhattan         10  1008.580179  0.978402\n",
       "0            15  uniform  euclidean         50  1008.732711  0.978396\n",
       "0            15  uniform  euclidean         30  1008.732711  0.978396\n",
       "0            15  uniform  minkowski         50  1008.732711  0.978396\n",
       "0            15  uniform  minkowski         30  1008.732711  0.978396\n",
       "..          ...      ...        ...        ...          ...       ...\n",
       "0            30  uniform  manhattan         50  1227.304037  0.968019\n",
       "0            30  uniform  manhattan         30  1227.304037  0.968019\n",
       "0            30  uniform  euclidean         20  1227.357143  0.968016\n",
       "0            30  uniform  minkowski         20  1227.357143  0.968016\n",
       "0            30  uniform  manhattan         20  1227.564466  0.968005\n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "df_li = []\n",
    "\n",
    "n_li = [10,15,20,25,30]\n",
    "w_li = ['uniform','distance']\n",
    "m_li = ['minkowski','euclidean','manhattan']\n",
    "l_li = [10,20,30,50]\n",
    "\n",
    "\n",
    "for n in n_li :\n",
    "    for w in w_li:\n",
    "        for m in m_li :\n",
    "            for l in l_li:\n",
    "                \n",
    "                time_step = 1\n",
    "                X_train, y_train = create_dataset(train_data, time_step)\n",
    "                X_test, y_test = create_dataset(test_data, time_step)\n",
    "                X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "                X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "                \n",
    "                knn = neighbors.KNeighborsRegressor(n_neighbors=n,weights=w,metric=m,leaf_size=l)\n",
    "                knn.fit(X_train, y_train)\n",
    "\n",
    "                train_predict=knn.predict(X_train)\n",
    "                test_predict=knn.predict(X_test)\n",
    "\n",
    "                train_predict = train_predict.reshape(-1,1)\n",
    "                train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_train = y_train.reshape(-1,1)\n",
    "                y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "                test_predict = test_predict.reshape(-1,1)\n",
    "                test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_test = y_test.reshape(-1,1)\n",
    "                y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "                knn_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "                knn_r2 = r2_score(y_test,test_predict)\n",
    "                \n",
    "                data = {'n_neighbors' : [n], 'weights':[w], 'metric':[m], 'leaf_size':[l],\n",
    "                       'RMSE':[knn_rmse], 'R2':[knn_r2]}\n",
    "                df = pd.DataFrame(data)\n",
    "                df_li.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_li, axis=0)\n",
    "merged_df = merged_df.sort_values(['R2'], ascending=False)\n",
    "merged_df.to_csv('./knn_hyper.csv', encoding='cp949', index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe9af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987.713780</td>\n",
       "      <td>0.979287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987.713780</td>\n",
       "      <td>0.979287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987.753458</td>\n",
       "      <td>0.979285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>988.596865</td>\n",
       "      <td>0.979249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>988.596865</td>\n",
       "      <td>0.979249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3898.508309</td>\n",
       "      <td>0.677309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3898.508309</td>\n",
       "      <td>0.677309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3961.821288</td>\n",
       "      <td>0.666742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3961.821288</td>\n",
       "      <td>0.666742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3961.821288</td>\n",
       "      <td>0.666742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  num_leaves  learning_rate         RMSE        R2\n",
       "0            500         20          20           0.01   987.713780  0.979287\n",
       "0            500         -1          20           0.01   987.713780  0.979287\n",
       "0            500         10          20           0.01   987.753458  0.979285\n",
       "0            100         20          10           0.05   988.596865  0.979249\n",
       "0            100         -1          10           0.05   988.596865  0.979249\n",
       "..           ...        ...         ...            ...          ...       ...\n",
       "0            100         10          20           0.01  3898.508309  0.677309\n",
       "0            100         -1          20           0.01  3898.508309  0.677309\n",
       "0            100         20          10           0.01  3961.821288  0.666742\n",
       "0            100         10          10           0.01  3961.821288  0.666742\n",
       "0            100         -1          10           0.01  3961.821288  0.666742\n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "df_li = []\n",
    "\n",
    "n_li = [100, 200, 300, 500]\n",
    "m_li = [-1,10,20]\n",
    "nl_li = [10,20,31]\n",
    "l_li = [0.01,0.03,0.05,0.1]\n",
    "\n",
    "\n",
    "for n in n_li :\n",
    "    for m in m_li:\n",
    "        for nl in nl_li :\n",
    "            for l in l_li:\n",
    "                \n",
    "                time_step = 1\n",
    "                X_train, y_train = create_dataset(train_data, time_step)\n",
    "                X_test, y_test = create_dataset(test_data, time_step)\n",
    "                X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "                X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "                \n",
    "                lgbm = LGBMRegressor(n_estimators=n,max_depth=m,num_leaves=nl,learning_rate=l)\n",
    "                lgbm.fit(X_train, y_train)\n",
    "\n",
    "                train_predict=lgbm.predict(X_train)\n",
    "                test_predict=lgbm.predict(X_test)\n",
    "\n",
    "                train_predict = train_predict.reshape(-1,1)\n",
    "                train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_train = y_train.reshape(-1,1)\n",
    "                y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "                test_predict = test_predict.reshape(-1,1)\n",
    "                test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "                y_test = y_test.reshape(-1,1)\n",
    "                y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "                lgbm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "                lgbm_r2 = r2_score(y_test,test_predict)\n",
    "                \n",
    "                data = {'n_estimators':[n], 'max_depth':[m], 'num_leaves':[nl], 'learning_rate':[l],\n",
    "                       'RMSE':[lgbm_rmse], 'R2':[lgbm_r2]}\n",
    "                df = pd.DataFrame(data)\n",
    "                df_li.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_li, axis=0)\n",
    "merged_df = merged_df.sort_values(['R2'], ascending=False)\n",
    "merged_df.to_csv('./lgbm_hyper.csv', encoding='cp949', index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfbd6e",
   "metadata": {},
   "source": [
    "n_estimators:300, max_depth:10, num_leaves:10, learning_rate:0.05\n",
    "\n",
    "RMSE : 1008.6739  R2 : 0.9783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa19631",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./fs01.csv', encoding='cp949')\n",
    "b = pd.read_csv('./fs02.csv', encoding='cp949')\n",
    "c = pd.read_csv('./fs03.csv', encoding='cp949')\n",
    "df = pd.concat([a,b,c], axis=0)\n",
    "df = df.sort_values(['r2'], ascending=False)\n",
    "df.to_csv('./fs.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a28e60",
   "metadata": {},
   "source": [
    "# 시계열 딥러닝 알고리즘 최적 변수\n",
    "\n",
    "LSTM : 종가 WMA MA5 foreign_보유수량     (인덱스 0,1,2,4)\n",
    "\n",
    "GRU : 종가 PER WMA MA5 foreign_보유수량 RSI     (인덱스 0,1,2,3,4,5)\n",
    "\n",
    "LSTM+GRU : 종가 WMA foreign_보유수량     (인덱스 0,1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06ea1f",
   "metadata": {},
   "source": [
    "# layer, 노드 수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d538765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 8s 61ms/step - loss: 0.0208 - val_loss: 0.0026\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 9.9690e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 7.7531e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 7.1257e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.9933e-04 - val_loss: 8.4238e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.9376e-04 - val_loss: 6.2294e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 8.8170e-04 - val_loss: 8.7617e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 8.2615e-04 - val_loss: 8.2418e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.6171e-04 - val_loss: 5.3537e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 8.2294e-04 - val_loss: 5.2365e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.3152e-04 - val_loss: 0.0011\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.3709e-04 - val_loss: 4.6533e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.3081e-04 - val_loss: 4.4828e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 6.4318e-04 - val_loss: 4.7660e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.0532e-04 - val_loss: 5.1534e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.4952e-04 - val_loss: 5.5562e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.3972e-04 - val_loss: 4.0026e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1453e-04 - val_loss: 5.0582e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1704e-04 - val_loss: 7.6479e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.1497e-04 - val_loss: 6.8974e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3775e-04 - val_loss: 6.1456e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8320e-04 - val_loss: 3.5887e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6414e-04 - val_loss: 3.5234e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8877e-04 - val_loss: 3.7001e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1404e-04 - val_loss: 4.0487e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6183e-04 - val_loss: 4.1822e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2892e-04 - val_loss: 4.2818e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.5454e-04 - val_loss: 5.4214e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5505e-04 - val_loss: 3.2823e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2149e-04 - val_loss: 3.4829e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1274e-04 - val_loss: 3.5201e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8794e-04 - val_loss: 3.4177e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.4717e-04 - val_loss: 6.1849e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8945e-04 - val_loss: 3.8259e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7899e-04 - val_loss: 3.4028e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9378e-04 - val_loss: 4.6962e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3120e-04 - val_loss: 3.4448e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6526e-04 - val_loss: 3.8109e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7865e-04 - val_loss: 3.1139e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0181e-04 - val_loss: 3.1540e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.3664e-04 - val_loss: 5.1248e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0731e-04 - val_loss: 3.0887e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7612e-04 - val_loss: 3.6872e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0714e-04 - val_loss: 3.6742e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.3486e-04 - val_loss: 4.0380e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2820e-04 - val_loss: 4.7905e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2725e-04 - val_loss: 3.9566e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5149e-04 - val_loss: 3.5313e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9007e-04 - val_loss: 3.3272e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7189e-04 - val_loss: 3.1250e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5794e-04 - val_loss: 3.1083e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4879e-04 - val_loss: 3.1572e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6913e-04 - val_loss: 4.5353e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0362e-04 - val_loss: 3.0513e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7006e-04 - val_loss: 3.3156e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7493e-04 - val_loss: 3.0308e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6266e-04 - val_loss: 3.2168e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9146e-04 - val_loss: 2.9729e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9232e-04 - val_loss: 3.4823e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0455e-04 - val_loss: 4.1828e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7644e-04 - val_loss: 3.1597e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8455e-04 - val_loss: 2.9609e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8859e-04 - val_loss: 3.7108e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6421e-04 - val_loss: 3.7794e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8906e-04 - val_loss: 2.9735e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4143e-04 - val_loss: 4.0121e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7491e-04 - val_loss: 4.5969e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5758e-04 - val_loss: 3.0758e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6478e-04 - val_loss: 4.9388e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9604e-04 - val_loss: 4.4102e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.3584e-04 - val_loss: 3.9774e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1908e-04 - val_loss: 3.4124e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.9157e-04 - val_loss: 2.9167e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4126e-04 - val_loss: 3.1461e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5093e-04 - val_loss: 3.3164e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3785e-04 - val_loss: 2.8791e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1315e-04 - val_loss: 8.3380e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.5439e-04 - val_loss: 2.8751e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4304e-04 - val_loss: 3.0263e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7690e-04 - val_loss: 4.7259e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9450e-04 - val_loss: 3.9560e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4765e-04 - val_loss: 2.8776e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5059e-04 - val_loss: 2.9254e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5370e-04 - val_loss: 3.7662e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4224e-04 - val_loss: 2.9041e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3385e-04 - val_loss: 3.4091e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9953e-04 - val_loss: 3.1104e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5299e-04 - val_loss: 2.9246e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5763e-04 - val_loss: 3.0677e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6222e-04 - val_loss: 2.9363e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6270e-04 - val_loss: 2.8639e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5360e-04 - val_loss: 2.8755e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.6794e-04 - val_loss: 3.4949e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4761e-04 - val_loss: 2.8875e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.3829e-04 - val_loss: 2.9242e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6977e-04 - val_loss: 7.0217e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6928e-04 - val_loss: 3.1420e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3974e-04 - val_loss: 5.0048e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9552e-04 - val_loss: 3.4047e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.9805e-04 - val_loss: 4.7470e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.6294e-04 - val_loss: 3.6034e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.8440e-04 - val_loss: 3.6025e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6041e-04 - val_loss: 4.1079e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0296e-04 - val_loss: 2.9388e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8770e-04 - val_loss: 4.8902e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8150e-04 - val_loss: 4.7306e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4024e-04 - val_loss: 2.9662e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0824e-04 - val_loss: 2.9749e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6679e-04 - val_loss: 3.5026e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6004e-04 - val_loss: 3.2286e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.2857e-04 - val_loss: 2.9268e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2846e-04 - val_loss: 2.8818e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4419e-04 - val_loss: 3.2462e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6523e-04 - val_loss: 2.8527e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5365e-04 - val_loss: 3.1117e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5229e-04 - val_loss: 3.2234e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6571e-04 - val_loss: 2.9323e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5411e-04 - val_loss: 3.2539e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.2884e-04 - val_loss: 3.5812e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6951e-04 - val_loss: 6.6783e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8271e-04 - val_loss: 4.9822e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7245e-04 - val_loss: 2.9605e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0951e-04 - val_loss: 5.0671e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9055e-04 - val_loss: 2.8608e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7529e-04 - val_loss: 3.1726e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5457e-04 - val_loss: 3.0703e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4296e-04 - val_loss: 3.3054e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0094e-04 - val_loss: 3.4899e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2751e-04 - val_loss: 3.2657e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4668e-04 - val_loss: 5.6627e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1383e-04 - val_loss: 2.9069e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4278e-04 - val_loss: 3.1636e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4193e-04 - val_loss: 2.9071e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9499e-04 - val_loss: 5.4673e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0551e-04 - val_loss: 3.1782e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0187e-04 - val_loss: 2.9594e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7190e-04 - val_loss: 2.9640e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1494e-04 - val_loss: 6.4629e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7522e-04 - val_loss: 2.8360e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3830e-04 - val_loss: 4.2074e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7315e-04 - val_loss: 4.1816e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8070e-04 - val_loss: 3.3865e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0151e-04 - val_loss: 3.1521e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4896e-04 - val_loss: 3.7370e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4421e-04 - val_loss: 2.9171e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5709e-04 - val_loss: 2.9012e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6110e-04 - val_loss: 3.4087e-04\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5519e-04 - val_loss: 2.9592e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5948e-04 - val_loss: 3.5402e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4143e-04 - val_loss: 3.5632e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.3627e-04 - val_loss: 7.8899e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7818e-04 - val_loss: 3.7707e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4057e-04 - val_loss: 3.2912e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7205e-04 - val_loss: 3.9063e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.2890e-04 - val_loss: 3.6405e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6620e-04 - val_loss: 2.8811e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2547e-04 - val_loss: 2.9066e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5955e-04 - val_loss: 7.9547e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4723e-04 - val_loss: 2.8947e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.2852e-04 - val_loss: 3.5334e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5223e-04 - val_loss: 3.3984e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4582e-04 - val_loss: 4.4034e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5827e-04 - val_loss: 2.8506e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3834e-04 - val_loss: 3.1472e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5466e-04 - val_loss: 2.8507e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3952e-04 - val_loss: 3.1151e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5412e-04 - val_loss: 2.8604e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7322e-04 - val_loss: 3.1032e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4408e-04 - val_loss: 3.1717e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 8s 71ms/step - loss: 0.0419 - val_loss: 0.0168\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0015 - val_loss: 9.7235e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0014 - val_loss: 9.3719e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 8.5175e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0013 - val_loss: 8.8933e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0014 - val_loss: 7.0066e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0013 - val_loss: 6.8252e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0012 - val_loss: 6.8748e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0011 - val_loss: 6.4737e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.2195e-04 - val_loss: 8.9118e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0011 - val_loss: 9.0012e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 8.8151e-04 - val_loss: 8.2897e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 8.8646e-04 - val_loss: 0.0011\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 8.9289e-04 - val_loss: 5.4277e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0011 - val_loss: 7.0133e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 8.9949e-04 - val_loss: 8.7317e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 8.3470e-04 - val_loss: 5.5565e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 9.6782e-04 - val_loss: 5.2379e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 8.4291e-04 - val_loss: 5.7291e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 7.7264e-04 - val_loss: 4.7327e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 7.8475e-04 - val_loss: 5.3652e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.7088e-04 - val_loss: 4.7719e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 7.0016e-04 - val_loss: 4.7386e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 7.0513e-04 - val_loss: 0.0013\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 7.1618e-04 - val_loss: 4.9677e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 8.3151e-04 - val_loss: 7.9100e-04\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 30ms/step - loss: 6.6729e-04 - val_loss: 4.2909e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.6828e-04 - val_loss: 0.0019\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 8.4759e-04 - val_loss: 4.8450e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.7260e-04 - val_loss: 4.2174e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.8781e-04 - val_loss: 4.4217e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.9657e-04 - val_loss: 4.2251e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.4157e-04 - val_loss: 4.7029e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.0650e-04 - val_loss: 3.9828e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.7174e-04 - val_loss: 5.8242e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.1138e-04 - val_loss: 8.6709e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.3877e-04 - val_loss: 5.6639e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.9306e-04 - val_loss: 4.2261e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.9398e-04 - val_loss: 4.6188e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.5446e-04 - val_loss: 3.9190e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.6071e-04 - val_loss: 3.5524e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.2767e-04 - val_loss: 3.6498e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.4516e-04 - val_loss: 3.9736e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.2867e-04 - val_loss: 3.9126e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1808e-04 - val_loss: 4.3481e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.6673e-04 - val_loss: 4.3631e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.2110e-04 - val_loss: 4.0791e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.3702e-04 - val_loss: 3.4017e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.1305e-04 - val_loss: 3.6755e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.4547e-04 - val_loss: 5.8269e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.3080e-04 - val_loss: 8.2023e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8857e-04 - val_loss: 3.0784e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.7977e-04 - val_loss: 3.0932e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.2778e-04 - val_loss: 5.1025e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.4961e-04 - val_loss: 3.6999e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6982e-04 - val_loss: 3.0968e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6108e-04 - val_loss: 2.9830e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.0113e-04 - val_loss: 3.0064e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8061e-04 - val_loss: 4.0095e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.5602e-04 - val_loss: 3.1553e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8390e-04 - val_loss: 3.5662e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7057e-04 - val_loss: 3.0961e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6732e-04 - val_loss: 4.4461e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.0242e-04 - val_loss: 5.0282e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.3616e-04 - val_loss: 7.3515e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.9815e-04 - val_loss: 3.6740e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7005e-04 - val_loss: 3.6885e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7553e-04 - val_loss: 3.7532e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.8191e-04 - val_loss: 3.7554e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.2556e-04 - val_loss: 3.1282e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.2251e-04 - val_loss: 5.9969e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.4485e-04 - val_loss: 4.6600e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7581e-04 - val_loss: 3.2682e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.3593e-04 - val_loss: 3.0051e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7856e-04 - val_loss: 3.4438e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5954e-04 - val_loss: 3.4067e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6935e-04 - val_loss: 2.9351e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4774e-04 - val_loss: 4.4443e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.2402e-04 - val_loss: 6.0676e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.5362e-04 - val_loss: 4.4446e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.2018e-04 - val_loss: 3.6998e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7893e-04 - val_loss: 3.0948e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6508e-04 - val_loss: 4.9923e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8370e-04 - val_loss: 2.9138e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8359e-04 - val_loss: 6.6199e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 5.4135e-04 - val_loss: 3.0982e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7414e-04 - val_loss: 4.9839e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.5334e-04 - val_loss: 3.7770e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6230e-04 - val_loss: 2.8999e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.3624e-04 - val_loss: 3.0336e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.1731e-04 - val_loss: 3.7483e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.3985e-04 - val_loss: 3.1994e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4996e-04 - val_loss: 3.0666e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6123e-04 - val_loss: 3.0192e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0669e-04 - val_loss: 3.1739e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5049e-04 - val_loss: 2.9810e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.3189e-04 - val_loss: 2.9129e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6229e-04 - val_loss: 3.1200e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7618e-04 - val_loss: 2.9370e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8328e-04 - val_loss: 4.3139e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5330e-04 - val_loss: 4.9479e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9420e-04 - val_loss: 3.0526e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8579e-04 - val_loss: 4.4588e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8156e-04 - val_loss: 0.0013\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4543e-04 - val_loss: 2.9818e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4351e-04 - val_loss: 4.0708e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1302e-04 - val_loss: 2.9613e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.0671e-04 - val_loss: 7.3402e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1043e-04 - val_loss: 3.0652e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5373e-04 - val_loss: 3.1853e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8135e-04 - val_loss: 3.7512e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5386e-04 - val_loss: 2.9494e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6948e-04 - val_loss: 3.3427e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6711e-04 - val_loss: 3.0033e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2287e-04 - val_loss: 3.6920e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1197e-04 - val_loss: 3.7834e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7260e-04 - val_loss: 3.5475e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5180e-04 - val_loss: 2.9840e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5988e-04 - val_loss: 6.9727e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 4s 39ms/step - loss: 0.1282 - val_loss: 0.0077\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 7.2570e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 8.1253e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 8.5251e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 9.0010e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.8873e-04 - val_loss: 8.7908e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.9342e-04 - val_loss: 9.5471e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.9792e-04 - val_loss: 6.9216e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.4208e-04 - val_loss: 7.8440e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.4727e-04 - val_loss: 5.9251e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.4843e-04 - val_loss: 6.1159e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.3718e-04 - val_loss: 7.1366e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.6834e-04 - val_loss: 8.4047e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.2533e-04 - val_loss: 8.7189e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.5702e-04 - val_loss: 9.9457e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6785e-04 - val_loss: 5.5144e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.3853e-04 - val_loss: 8.0057e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3115e-04 - val_loss: 5.6510e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.0149e-04 - val_loss: 6.9668e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.6829e-04 - val_loss: 6.5608e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.9276e-04 - val_loss: 0.0010\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.5114e-04 - val_loss: 6.2978e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.8617e-04 - val_loss: 6.1457e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7233e-04 - val_loss: 7.2246e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7338e-04 - val_loss: 6.4376e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3353e-04 - val_loss: 5.9922e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.8493e-04 - val_loss: 5.0359e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.8324e-04 - val_loss: 7.8449e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7588e-04 - val_loss: 9.6099e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.6363e-04 - val_loss: 5.5547e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 7.4565e-04 - val_loss: 5.2308e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.1175e-04 - val_loss: 5.9179e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.9614e-04 - val_loss: 7.2399e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2804e-04 - val_loss: 0.0015\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.0529e-04 - val_loss: 6.0029e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.3208e-04 - val_loss: 6.7334e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7558e-04 - val_loss: 5.9797e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 6.6255e-04 - val_loss: 4.7880e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.4990e-04 - val_loss: 6.0654e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.2207e-04 - val_loss: 4.7534e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.4576e-04 - val_loss: 4.8709e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.7135e-04 - val_loss: 5.1088e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.0797e-04 - val_loss: 5.1475e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.5293e-04 - val_loss: 5.2137e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.4980e-04 - val_loss: 4.6333e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.0429e-04 - val_loss: 4.5619e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.9841e-04 - val_loss: 4.4817e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.1847e-04 - val_loss: 8.7244e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.0057e-04 - val_loss: 4.3974e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.2075e-04 - val_loss: 7.2094e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.8522e-04 - val_loss: 4.5671e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.6409e-04 - val_loss: 4.2273e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.6686e-04 - val_loss: 7.0961e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4944e-04 - val_loss: 4.8194e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4506e-04 - val_loss: 4.5538e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.3980e-04 - val_loss: 5.1110e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.5667e-04 - val_loss: 4.1094e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.6382e-04 - val_loss: 5.0304e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.2727e-04 - val_loss: 4.2659e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.6357e-04 - val_loss: 6.4254e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.2691e-04 - val_loss: 5.0207e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.1536e-04 - val_loss: 5.0961e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.1348e-04 - val_loss: 4.6384e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.3689e-04 - val_loss: 3.9918e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.7024e-04 - val_loss: 4.1384e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0954e-04 - val_loss: 5.7646e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.2259e-04 - val_loss: 4.4851e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0536e-04 - val_loss: 4.0656e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.2302e-04 - val_loss: 4.6641e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.2432e-04 - val_loss: 4.7470e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8142e-04 - val_loss: 3.9526e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.9657e-04 - val_loss: 3.7830e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8209e-04 - val_loss: 3.7991e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.0090e-04 - val_loss: 3.8828e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5258e-04 - val_loss: 4.0126e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.5765e-04 - val_loss: 3.7287e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8602e-04 - val_loss: 3.7440e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9039e-04 - val_loss: 3.7316e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.2361e-04 - val_loss: 3.8155e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6440e-04 - val_loss: 3.7205e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5656e-04 - val_loss: 4.0627e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6793e-04 - val_loss: 3.6968e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2268e-04 - val_loss: 3.7897e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.1037e-04 - val_loss: 3.8122e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3738e-04 - val_loss: 3.6424e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3753e-04 - val_loss: 7.2182e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5981e-04 - val_loss: 6.3892e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.2492e-04 - val_loss: 5.1356e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4304e-04 - val_loss: 3.9886e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1440e-04 - val_loss: 4.6324e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2767e-04 - val_loss: 4.2245e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0837e-04 - val_loss: 3.8379e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3956e-04 - val_loss: 5.6208e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0658e-04 - val_loss: 5.4886e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3796e-04 - val_loss: 3.6268e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9890e-04 - val_loss: 4.8599e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7641e-04 - val_loss: 4.7878e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.1239e-04 - val_loss: 4.1367e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1212e-04 - val_loss: 3.3975e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9926e-04 - val_loss: 3.7660e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9910e-04 - val_loss: 3.4785e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7872e-04 - val_loss: 3.9659e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0163e-04 - val_loss: 6.0363e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2241e-04 - val_loss: 3.5382e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5961e-04 - val_loss: 3.3276e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8787e-04 - val_loss: 3.4820e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9825e-04 - val_loss: 3.3088e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8280e-04 - val_loss: 3.3006e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8370e-04 - val_loss: 3.2720e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9228e-04 - val_loss: 3.7971e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0847e-04 - val_loss: 3.9207e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8122e-04 - val_loss: 3.3051e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9107e-04 - val_loss: 6.0052e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1736e-04 - val_loss: 6.9712e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3694e-04 - val_loss: 3.2679e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7309e-04 - val_loss: 3.3203e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6332e-04 - val_loss: 3.1813e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7281e-04 - val_loss: 3.1566e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6403e-04 - val_loss: 3.5674e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.4304e-04 - val_loss: 3.2238e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7423e-04 - val_loss: 3.2962e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7628e-04 - val_loss: 3.1210e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5696e-04 - val_loss: 3.1364e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5492e-04 - val_loss: 5.7566e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9974e-04 - val_loss: 3.2275e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7770e-04 - val_loss: 3.2039e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1047e-04 - val_loss: 3.6102e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5896e-04 - val_loss: 3.1218e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9150e-04 - val_loss: 3.1783e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9839e-04 - val_loss: 3.6460e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5778e-04 - val_loss: 3.4975e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5088e-04 - val_loss: 3.1286e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8220e-04 - val_loss: 4.2709e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6883e-04 - val_loss: 4.2324e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6149e-04 - val_loss: 3.2486e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4651e-04 - val_loss: 3.5711e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5276e-04 - val_loss: 3.6293e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6994e-04 - val_loss: 4.0904e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8287e-04 - val_loss: 3.7128e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4637e-04 - val_loss: 3.0839e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5171e-04 - val_loss: 3.1609e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6709e-04 - val_loss: 3.0443e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5763e-04 - val_loss: 3.3829e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5431e-04 - val_loss: 3.0044e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6650e-04 - val_loss: 3.5883e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7878e-04 - val_loss: 3.2648e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4315e-04 - val_loss: 3.5771e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6420e-04 - val_loss: 3.0887e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7331e-04 - val_loss: 3.0583e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5759e-04 - val_loss: 3.4736e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1163e-04 - val_loss: 3.6673e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6673e-04 - val_loss: 3.6837e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6400e-04 - val_loss: 2.9894e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6535e-04 - val_loss: 3.5428e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9546e-04 - val_loss: 3.0057e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7888e-04 - val_loss: 3.2904e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6205e-04 - val_loss: 3.4940e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3660e-04 - val_loss: 3.9998e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5827e-04 - val_loss: 3.7237e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4746e-04 - val_loss: 3.1395e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2585e-04 - val_loss: 2.9414e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4320e-04 - val_loss: 3.1795e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1130e-04 - val_loss: 3.3521e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7589e-04 - val_loss: 2.9536e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7579e-04 - val_loss: 3.2433e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4230e-04 - val_loss: 3.3569e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5908e-04 - val_loss: 3.0049e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3499e-04 - val_loss: 5.6370e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7018e-04 - val_loss: 3.4094e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5435e-04 - val_loss: 2.9287e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8741e-04 - val_loss: 4.5569e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6999e-04 - val_loss: 3.8261e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7048e-04 - val_loss: 2.9774e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3332e-04 - val_loss: 3.6000e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6527e-04 - val_loss: 2.9346e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9037e-04 - val_loss: 2.9976e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7008e-04 - val_loss: 2.9104e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3839e-04 - val_loss: 2.9372e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8418e-04 - val_loss: 3.1690e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5666e-04 - val_loss: 5.1024e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1256e-04 - val_loss: 6.3662e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7668e-04 - val_loss: 3.5730e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3964e-04 - val_loss: 3.0431e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3008e-04 - val_loss: 3.2719e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6230e-04 - val_loss: 3.3001e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3785e-04 - val_loss: 3.2754e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3999e-04 - val_loss: 2.9482e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3357e-04 - val_loss: 3.3314e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5205e-04 - val_loss: 5.1359e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7773e-04 - val_loss: 2.9154e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9707e-04 - val_loss: 4.1515e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7967e-04 - val_loss: 3.8477e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4544e-04 - val_loss: 2.9091e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6631e-04 - val_loss: 3.1583e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4642e-04 - val_loss: 2.9300e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3115e-04 - val_loss: 2.9458e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5470e-04 - val_loss: 3.0829e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4746e-04 - val_loss: 3.2481e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5280e-04 - val_loss: 3.8590e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7424e-04 - val_loss: 3.0991e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2997e-04 - val_loss: 3.2177e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5963e-04 - val_loss: 3.1135e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2897e-04 - val_loss: 2.9024e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3367e-04 - val_loss: 2.8984e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4247e-04 - val_loss: 3.1258e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6539e-04 - val_loss: 2.9159e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3274e-04 - val_loss: 3.4474e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5320e-04 - val_loss: 4.3743e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5426e-04 - val_loss: 2.9325e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5076e-04 - val_loss: 3.5847e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2749e-04 - val_loss: 2.9206e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3458e-04 - val_loss: 4.0744e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5574e-04 - val_loss: 4.5382e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8649e-04 - val_loss: 2.9691e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3061e-04 - val_loss: 2.9289e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3330e-04 - val_loss: 2.9192e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4129e-04 - val_loss: 2.9925e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3040e-04 - val_loss: 3.7017e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3029e-04 - val_loss: 5.3678e-04\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4159e-04 - val_loss: 2.9123e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4056e-04 - val_loss: 4.0469e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4898e-04 - val_loss: 3.9988e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9397e-04 - val_loss: 4.0950e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5586e-04 - val_loss: 2.9268e-04\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2248e-04 - val_loss: 3.2697e-04\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3782e-04 - val_loss: 2.9372e-04\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2607e-04 - val_loss: 3.4694e-04\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.1600e-04 - val_loss: 2.9145e-04\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3815e-04 - val_loss: 3.6244e-04\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4298e-04 - val_loss: 2.9043e-04\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7949e-04 - val_loss: 2.8935e-04\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5139e-04 - val_loss: 2.9732e-04\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2719e-04 - val_loss: 2.9495e-04\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2198e-04 - val_loss: 3.5103e-04\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5562e-04 - val_loss: 3.1583e-04\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5058e-04 - val_loss: 4.1750e-04\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4025e-04 - val_loss: 2.9813e-04\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5248e-04 - val_loss: 3.1580e-04\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3180e-04 - val_loss: 2.8976e-04\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4978e-04 - val_loss: 3.2324e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2428e-04 - val_loss: 2.9541e-04\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3598e-04 - val_loss: 2.8946e-04\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3175e-04 - val_loss: 3.0547e-04\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4788e-04 - val_loss: 3.0492e-04\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2487e-04 - val_loss: 2.9627e-04\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6656e-04 - val_loss: 3.4423e-04\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5391e-04 - val_loss: 3.0427e-04\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3934e-04 - val_loss: 2.9275e-04\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2174e-04 - val_loss: 2.9240e-04\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2579e-04 - val_loss: 2.9195e-04\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2467e-04 - val_loss: 2.9121e-04\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1614e-04 - val_loss: 3.2853e-04\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3780e-04 - val_loss: 2.9663e-04\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2859e-04 - val_loss: 2.9976e-04\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.2814e-04 - val_loss: 3.0611e-04\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7110e-04 - val_loss: 2.9489e-04\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3070e-04 - val_loss: 2.9411e-04\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5803e-04 - val_loss: 2.9041e-04\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3567e-04 - val_loss: 3.0064e-04\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3311e-04 - val_loss: 2.9379e-04\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4312e-04 - val_loss: 3.4822e-04\n",
      "  algorithm        rmse        r2\n",
      "0      lstm  910.900104  0.982628\n",
      "1       gru  901.810128  0.982973\n",
      "2   lstmgru  911.907512  0.982590\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(32,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "\n",
    "print(comparison1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b5d39",
   "metadata": {},
   "source": [
    "lstm 910.900104  0.982628\n",
    "\n",
    "gru  901.810128  0.982973\n",
    "\n",
    "lstmgru  911.907512  0.982590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b527ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 6s 72ms/step - loss: 0.0157 - val_loss: 0.0072\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0011 - val_loss: 6.9043e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 9.4379e-04 - val_loss: 6.4429e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.3246e-04 - val_loss: 5.8440e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 8.8505e-04 - val_loss: 5.4403e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.1553e-04 - val_loss: 5.4716e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 7.3854e-04 - val_loss: 5.7658e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.3503e-04 - val_loss: 5.0807e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 6.5656e-04 - val_loss: 4.4687e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 6.4017e-04 - val_loss: 4.9037e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.3625e-04 - val_loss: 4.6816e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 5.9390e-04 - val_loss: 4.4828e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 5.3941e-04 - val_loss: 4.8757e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 5.8136e-04 - val_loss: 3.8724e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.0898e-04 - val_loss: 4.1665e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.7969e-04 - val_loss: 3.5531e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.5511e-04 - val_loss: 3.7252e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.6980e-04 - val_loss: 3.3527e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.5084e-04 - val_loss: 3.7845e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.5596e-04 - val_loss: 3.2218e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.0412e-04 - val_loss: 3.4163e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.1356e-04 - val_loss: 7.4001e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.4613e-04 - val_loss: 3.2233e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.1277e-04 - val_loss: 3.0961e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.0520e-04 - val_loss: 5.8416e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.2500e-04 - val_loss: 3.1453e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7876e-04 - val_loss: 3.8376e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.2813e-04 - val_loss: 3.1837e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.5122e-04 - val_loss: 3.3234e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.1276e-04 - val_loss: 3.4630e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.0473e-04 - val_loss: 3.6222e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.9607e-04 - val_loss: 3.3678e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.0225e-04 - val_loss: 3.6161e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.1057e-04 - val_loss: 3.2668e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.8388e-04 - val_loss: 3.0129e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5292e-04 - val_loss: 4.7912e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.1348e-04 - val_loss: 3.1030e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.9320e-04 - val_loss: 2.9655e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.3101e-04 - val_loss: 3.6162e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.9861e-04 - val_loss: 3.0021e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.5259e-04 - val_loss: 5.7634e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.1207e-04 - val_loss: 3.4383e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.3976e-04 - val_loss: 2.8981e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7105e-04 - val_loss: 3.5622e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7250e-04 - val_loss: 3.3257e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7852e-04 - val_loss: 4.0200e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.0258e-04 - val_loss: 3.6267e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.9479e-04 - val_loss: 2.9341e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6753e-04 - val_loss: 5.7040e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.2477e-04 - val_loss: 3.0955e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8522e-04 - val_loss: 2.9409e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.8380e-04 - val_loss: 2.9478e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.3480e-04 - val_loss: 5.6212e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.9500e-04 - val_loss: 2.9798e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.2652e-04 - val_loss: 6.0540e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.8485e-04 - val_loss: 4.8448e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.9859e-04 - val_loss: 3.2607e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.4755e-04 - val_loss: 3.9683e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.4831e-04 - val_loss: 6.0137e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.1032e-04 - val_loss: 3.0517e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8453e-04 - val_loss: 2.9465e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8674e-04 - val_loss: 3.3741e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.6542e-04 - val_loss: 3.7988e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5209e-04 - val_loss: 3.0136e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.6303e-04 - val_loss: 3.4602e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3499e-04 - val_loss: 3.1188e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.3471e-04 - val_loss: 4.1324e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.8616e-04 - val_loss: 2.8595e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.7392e-04 - val_loss: 2.8881e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.2477e-04 - val_loss: 5.1203e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4246e-04 - val_loss: 3.1194e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.3479e-04 - val_loss: 3.7113e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.3542e-04 - val_loss: 4.0201e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.1354e-04 - val_loss: 4.6730e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.2853e-04 - val_loss: 3.2948e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.5378e-04 - val_loss: 3.3129e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.0932e-04 - val_loss: 2.9603e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.0965e-04 - val_loss: 3.1912e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5974e-04 - val_loss: 4.5951e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8371e-04 - val_loss: 5.1087e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.1007e-04 - val_loss: 5.0872e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.2642e-04 - val_loss: 3.2159e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.6611e-04 - val_loss: 2.9774e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4423e-04 - val_loss: 6.5651e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.0597e-04 - val_loss: 5.0484e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.7631e-04 - val_loss: 2.8899e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.7228e-04 - val_loss: 3.0259e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.4178e-04 - val_loss: 3.4061e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.0688e-04 - val_loss: 5.6193e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.9229e-04 - val_loss: 5.9695e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.9905e-04 - val_loss: 4.1050e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.4143e-04 - val_loss: 4.0825e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6061e-04 - val_loss: 3.4884e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.1058e-04 - val_loss: 4.0125e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7818e-04 - val_loss: 4.8086e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.1770e-04 - val_loss: 2.8360e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3485e-04 - val_loss: 3.1445e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3970e-04 - val_loss: 2.8896e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.4203e-04 - val_loss: 3.6470e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5604e-04 - val_loss: 2.9374e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.4455e-04 - val_loss: 3.0462e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.4426e-04 - val_loss: 3.2165e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.7390e-04 - val_loss: 2.9684e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.5010e-04 - val_loss: 2.8769e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.2953e-04 - val_loss: 3.3622e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3251e-04 - val_loss: 3.1016e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.4606e-04 - val_loss: 3.6033e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.6043e-04 - val_loss: 4.3371e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.0178e-04 - val_loss: 2.9540e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.6222e-04 - val_loss: 2.9061e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6938e-04 - val_loss: 3.0097e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.9318e-04 - val_loss: 4.4939e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.9479e-04 - val_loss: 3.2425e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.4508e-04 - val_loss: 2.9624e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.9811e-04 - val_loss: 2.9320e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.4651e-04 - val_loss: 2.9772e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4107e-04 - val_loss: 2.8572e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0184e-04 - val_loss: 3.2284e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7554e-04 - val_loss: 3.2034e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.7507e-04 - val_loss: 3.4589e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.9031e-04 - val_loss: 2.8387e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.7731e-04 - val_loss: 6.6111e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.1688e-04 - val_loss: 3.1617e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6702e-04 - val_loss: 5.1948e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.2425e-04 - val_loss: 2.9152e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.2903e-04 - val_loss: 2.9611e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 9s 82ms/step - loss: 0.0130 - val_loss: 0.0021\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0017 - val_loss: 9.6354e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0016 - val_loss: 8.7049e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0018 - val_loss: 8.2411e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0013 - val_loss: 7.9220e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0012 - val_loss: 7.0069e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0011 - val_loss: 7.2092e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0015 - val_loss: 7.9260e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0013 - val_loss: 8.2006e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0011 - val_loss: 6.0269e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 9.7775e-04 - val_loss: 5.7271e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 9.1490e-04 - val_loss: 6.6253e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 8.4026e-04 - val_loss: 5.4526e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 8.3356e-04 - val_loss: 5.8863e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 8.0174e-04 - val_loss: 5.6868e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 8.1521e-04 - val_loss: 0.0017\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 7.7173e-04 - val_loss: 4.9939e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 9.1361e-04 - val_loss: 4.8108e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.7623e-04 - val_loss: 6.3593e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 7.3374e-04 - val_loss: 5.4249e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 7.0190e-04 - val_loss: 4.3418e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 6.4544e-04 - val_loss: 4.2066e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 7.8222e-04 - val_loss: 6.2806e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 8.3286e-04 - val_loss: 5.6304e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 6.2454e-04 - val_loss: 0.0012\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.6711e-04 - val_loss: 3.9269e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.0451e-04 - val_loss: 7.3600e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.2210e-04 - val_loss: 3.7526e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.7291e-04 - val_loss: 4.0069e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.6051e-04 - val_loss: 3.6656e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.9329e-04 - val_loss: 4.1655e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.6128e-04 - val_loss: 3.6662e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.3689e-04 - val_loss: 3.7531e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.9041e-04 - val_loss: 3.3675e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.6053e-04 - val_loss: 7.9847e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.8738e-04 - val_loss: 3.2745e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5625e-04 - val_loss: 3.3258e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5486e-04 - val_loss: 3.9894e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.0586e-04 - val_loss: 3.2753e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.3151e-04 - val_loss: 3.7020e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5226e-04 - val_loss: 3.2815e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.3998e-04 - val_loss: 4.6325e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.3987e-04 - val_loss: 3.1632e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.5476e-04 - val_loss: 5.3823e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.6632e-04 - val_loss: 3.3235e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.7910e-04 - val_loss: 8.0555e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.1276e-04 - val_loss: 3.7614e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.9893e-04 - val_loss: 3.7223e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5187e-04 - val_loss: 3.3117e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.8480e-04 - val_loss: 4.1295e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8843e-04 - val_loss: 6.7546e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.4336e-04 - val_loss: 4.6651e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.5596e-04 - val_loss: 5.1867e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 7.0237e-04 - val_loss: 3.0108e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.8481e-04 - val_loss: 6.7934e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.3036e-04 - val_loss: 2.9863e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.1370e-04 - val_loss: 3.0574e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.2184e-04 - val_loss: 3.0255e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.8625e-04 - val_loss: 5.2226e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.4950e-04 - val_loss: 2.9221e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.9966e-04 - val_loss: 2.9094e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.9402e-04 - val_loss: 3.8665e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9545e-04 - val_loss: 7.2154e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.6221e-04 - val_loss: 2.9116e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.7678e-04 - val_loss: 2.8822e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8122e-04 - val_loss: 3.3185e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.0679e-04 - val_loss: 3.8216e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5689e-04 - val_loss: 7.5832e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6800e-04 - val_loss: 3.2011e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.6655e-04 - val_loss: 2.8700e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.1701e-04 - val_loss: 3.7574e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.2597e-04 - val_loss: 4.2314e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 6.3857e-04 - val_loss: 4.5687e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0700e-04 - val_loss: 3.3054e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.9168e-04 - val_loss: 8.9173e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.4064e-04 - val_loss: 4.4650e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1424e-04 - val_loss: 5.0000e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.4979e-04 - val_loss: 2.9491e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.7333e-04 - val_loss: 3.0010e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7884e-04 - val_loss: 3.3743e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7177e-04 - val_loss: 2.8913e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1623e-04 - val_loss: 3.3509e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.6671e-04 - val_loss: 3.4392e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8064e-04 - val_loss: 4.4694e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.5732e-04 - val_loss: 4.5895e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.2075e-04 - val_loss: 5.9914e-04\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0945e-04 - val_loss: 3.9441e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.2409e-04 - val_loss: 4.5355e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.6200e-04 - val_loss: 3.4421e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.5436e-04 - val_loss: 3.0429e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.9268e-04 - val_loss: 4.8517e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6267e-04 - val_loss: 4.0358e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9541e-04 - val_loss: 8.6791e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.7340e-04 - val_loss: 3.5854e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.1313e-04 - val_loss: 2.9390e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6739e-04 - val_loss: 3.3728e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9547e-04 - val_loss: 3.2024e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4706e-04 - val_loss: 2.8557e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5528e-04 - val_loss: 3.5603e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8009e-04 - val_loss: 3.9755e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.4132e-04 - val_loss: 2.9168e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5496e-04 - val_loss: 3.3227e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4877e-04 - val_loss: 4.3062e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.6973e-04 - val_loss: 2.9193e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.9317e-04 - val_loss: 2.8825e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4656e-04 - val_loss: 6.3217e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4955e-04 - val_loss: 3.3756e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.6047e-04 - val_loss: 4.9360e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.7595e-04 - val_loss: 3.6414e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0550e-04 - val_loss: 3.0088e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.3905e-04 - val_loss: 2.9808e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0322e-04 - val_loss: 2.8748e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.7991e-04 - val_loss: 3.1133e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0522e-04 - val_loss: 9.5826e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.1701e-04 - val_loss: 3.6795e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.7042e-04 - val_loss: 3.2988e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0821e-04 - val_loss: 4.9189e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.5164e-04 - val_loss: 3.9315e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.3934e-04 - val_loss: 3.1270e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.4539e-04 - val_loss: 9.1954e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.3163e-04 - val_loss: 2.9063e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6400e-04 - val_loss: 7.5295e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.4099e-04 - val_loss: 2.9436e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8284e-04 - val_loss: 3.5073e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6797e-04 - val_loss: 3.2492e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8367e-04 - val_loss: 3.2309e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.0910e-04 - val_loss: 3.3832e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8170e-04 - val_loss: 2.8766e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 3s 37ms/step - loss: 0.0706 - val_loss: 0.0086\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 9.9538e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 8.8272e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 7.6522e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 7.5774e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.7018e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 7.3456e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.5048e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.6689e-04 - val_loss: 0.0011\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.7243e-04 - val_loss: 6.2034e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.6600e-04 - val_loss: 6.0345e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.3008e-04 - val_loss: 9.9549e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 8.0712e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 7.1403e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.6399e-04 - val_loss: 5.7749e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.9102e-04 - val_loss: 5.8587e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.7013e-04 - val_loss: 5.5377e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.0842e-04 - val_loss: 6.1059e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.0962e-04 - val_loss: 7.1491e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2649e-04 - val_loss: 6.0291e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2523e-04 - val_loss: 6.0320e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6072e-04 - val_loss: 6.7521e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3268e-04 - val_loss: 6.1117e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0679e-04 - val_loss: 5.2563e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.9828e-04 - val_loss: 5.2668e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.6098e-04 - val_loss: 5.0090e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.2210e-04 - val_loss: 6.8943e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.5578e-04 - val_loss: 6.0485e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.4886e-04 - val_loss: 5.7227e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.2844e-04 - val_loss: 4.9635e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.9090e-04 - val_loss: 6.7437e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7467e-04 - val_loss: 4.8126e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.5969e-04 - val_loss: 7.0730e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.5059e-04 - val_loss: 5.0652e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.5539e-04 - val_loss: 6.2379e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.4768e-04 - val_loss: 4.9857e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.4738e-04 - val_loss: 5.4648e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3434e-04 - val_loss: 5.0955e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.9589e-04 - val_loss: 6.4974e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.1925e-04 - val_loss: 4.9281e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.1844e-04 - val_loss: 5.0846e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.1997e-04 - val_loss: 6.5910e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.9947e-04 - val_loss: 0.0011\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3233e-04 - val_loss: 8.4447e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.7285e-04 - val_loss: 5.7695e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.6916e-04 - val_loss: 4.4700e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4996e-04 - val_loss: 5.0542e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4409e-04 - val_loss: 4.5939e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.3533e-04 - val_loss: 4.6830e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.5886e-04 - val_loss: 7.5703e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4950e-04 - val_loss: 4.2916e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.1364e-04 - val_loss: 4.3852e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.2534e-04 - val_loss: 6.4461e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.5142e-04 - val_loss: 7.1987e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.1693e-04 - val_loss: 8.0712e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4311e-04 - val_loss: 5.8291e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.7118e-04 - val_loss: 5.6517e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4625e-04 - val_loss: 4.6211e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9861e-04 - val_loss: 4.8545e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0775e-04 - val_loss: 4.2070e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4866e-04 - val_loss: 6.4858e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.9986e-04 - val_loss: 4.1530e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.5092e-04 - val_loss: 5.3301e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8442e-04 - val_loss: 5.4848e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8111e-04 - val_loss: 4.1221e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6750e-04 - val_loss: 4.1047e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6533e-04 - val_loss: 3.9193e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7013e-04 - val_loss: 4.7962e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8017e-04 - val_loss: 7.4332e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.8622e-04 - val_loss: 5.2587e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6472e-04 - val_loss: 7.1553e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8354e-04 - val_loss: 4.3509e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5435e-04 - val_loss: 4.2025e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5143e-04 - val_loss: 3.7454e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.4669e-04 - val_loss: 3.9074e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3901e-04 - val_loss: 4.3042e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7296e-04 - val_loss: 5.5284e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.1234e-04 - val_loss: 5.4029e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0166e-04 - val_loss: 4.6736e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4457e-04 - val_loss: 4.4259e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8277e-04 - val_loss: 3.5671e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.5336e-04 - val_loss: 3.7240e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5445e-04 - val_loss: 3.7307e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2043e-04 - val_loss: 4.9386e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6730e-04 - val_loss: 9.8646e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5703e-04 - val_loss: 3.7041e-04\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3289e-04 - val_loss: 3.7909e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2203e-04 - val_loss: 3.4526e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7138e-04 - val_loss: 3.6762e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0281e-04 - val_loss: 3.5773e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1033e-04 - val_loss: 6.0533e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1110e-04 - val_loss: 3.4289e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6931e-04 - val_loss: 4.8264e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0984e-04 - val_loss: 3.5614e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9603e-04 - val_loss: 3.4256e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9714e-04 - val_loss: 3.6080e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.2307e-04 - val_loss: 4.9605e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.8522e-04 - val_loss: 3.6348e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3716e-04 - val_loss: 3.3317e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9033e-04 - val_loss: 3.4696e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8670e-04 - val_loss: 4.3552e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7058e-04 - val_loss: 4.6321e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7991e-04 - val_loss: 3.5424e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3745e-04 - val_loss: 3.6097e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8771e-04 - val_loss: 3.5434e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8076e-04 - val_loss: 3.3548e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3777e-04 - val_loss: 3.2399e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3167e-04 - val_loss: 3.2530e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3245e-04 - val_loss: 3.5138e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0818e-04 - val_loss: 3.6219e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1277e-04 - val_loss: 3.2051e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6943e-04 - val_loss: 3.2850e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9040e-04 - val_loss: 3.9666e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7899e-04 - val_loss: 6.0903e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6354e-04 - val_loss: 3.1281e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5979e-04 - val_loss: 3.1573e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6041e-04 - val_loss: 4.0235e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5787e-04 - val_loss: 3.3194e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7155e-04 - val_loss: 3.3386e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6086e-04 - val_loss: 3.7475e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1339e-04 - val_loss: 4.8846e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0447e-04 - val_loss: 4.9466e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6299e-04 - val_loss: 3.3067e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4543e-04 - val_loss: 3.1659e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5933e-04 - val_loss: 3.9742e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4950e-04 - val_loss: 3.1057e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5589e-04 - val_loss: 3.5077e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3425e-04 - val_loss: 3.2227e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7464e-04 - val_loss: 3.2885e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5367e-04 - val_loss: 3.2788e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5618e-04 - val_loss: 3.9138e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5340e-04 - val_loss: 3.3613e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5136e-04 - val_loss: 3.4976e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7467e-04 - val_loss: 4.0116e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8480e-04 - val_loss: 3.2015e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5222e-04 - val_loss: 4.1276e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8405e-04 - val_loss: 6.1565e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9828e-04 - val_loss: 4.7270e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7316e-04 - val_loss: 3.4502e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7684e-04 - val_loss: 3.2521e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5545e-04 - val_loss: 3.4926e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1497e-04 - val_loss: 3.7900e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2645e-04 - val_loss: 3.3170e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3825e-04 - val_loss: 3.1617e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6662e-04 - val_loss: 3.8953e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8253e-04 - val_loss: 3.7579e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5905e-04 - val_loss: 2.9807e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4503e-04 - val_loss: 3.1192e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5283e-04 - val_loss: 2.9676e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4482e-04 - val_loss: 3.0026e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9416e-04 - val_loss: 2.9655e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6576e-04 - val_loss: 3.6330e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1944e-04 - val_loss: 5.5910e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.2263e-04 - val_loss: 3.1552e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4582e-04 - val_loss: 3.0724e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3386e-04 - val_loss: 2.9864e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4204e-04 - val_loss: 3.3491e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5289e-04 - val_loss: 3.5061e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8586e-04 - val_loss: 3.3346e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5900e-04 - val_loss: 3.4425e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8029e-04 - val_loss: 3.5862e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3268e-04 - val_loss: 2.9604e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6731e-04 - val_loss: 3.9975e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4155e-04 - val_loss: 2.9853e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3819e-04 - val_loss: 3.0616e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5961e-04 - val_loss: 3.5553e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7579e-04 - val_loss: 2.9936e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3183e-04 - val_loss: 3.8169e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.2893e-04 - val_loss: 4.3482e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7553e-04 - val_loss: 3.0845e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3126e-04 - val_loss: 2.9640e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3668e-04 - val_loss: 3.1343e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4708e-04 - val_loss: 3.1215e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6992e-04 - val_loss: 2.9558e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5907e-04 - val_loss: 2.9891e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3100e-04 - val_loss: 2.9681e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2495e-04 - val_loss: 3.1454e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.2645e-04 - val_loss: 2.9637e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2758e-04 - val_loss: 3.1324e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7412e-04 - val_loss: 3.1936e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.3712e-04 - val_loss: 3.6216e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.3197e-04 - val_loss: 3.1628e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.2924e-04 - val_loss: 7.3121e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9328e-04 - val_loss: 3.8977e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3117e-04 - val_loss: 3.8312e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5033e-04 - val_loss: 2.9185e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7178e-04 - val_loss: 3.1866e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4021e-04 - val_loss: 2.9368e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3860e-04 - val_loss: 3.1837e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9490e-04 - val_loss: 3.0109e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4599e-04 - val_loss: 3.2354e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1445e-04 - val_loss: 4.9113e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5677e-04 - val_loss: 3.0541e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3523e-04 - val_loss: 3.4735e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3634e-04 - val_loss: 3.2209e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0850e-04 - val_loss: 4.2892e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4094e-04 - val_loss: 3.2416e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.2341e-04 - val_loss: 2.9931e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3420e-04 - val_loss: 4.1205e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5614e-04 - val_loss: 3.0743e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.1935e-04 - val_loss: 2.9645e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6215e-04 - val_loss: 3.1452e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3189e-04 - val_loss: 4.6446e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2667e-04 - val_loss: 3.0447e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.2755e-04 - val_loss: 3.0746e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4547e-04 - val_loss: 3.1733e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.4000e-04 - val_loss: 3.1341e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.3160e-04 - val_loss: 3.0032e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2379e-04 - val_loss: 2.9392e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4525e-04 - val_loss: 3.3102e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3447e-04 - val_loss: 3.0077e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4963e-04 - val_loss: 2.9358e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9980e-04 - val_loss: 3.1249e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0038e-04 - val_loss: 3.0312e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3873e-04 - val_loss: 2.9790e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.2004e-04 - val_loss: 2.9264e-04\n",
      "  algorithm        rmse        r2\n",
      "0      lstm  914.831766  0.982478\n",
      "1       gru  901.801397  0.982973\n",
      "2   lstmgru  904.933202  0.982855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "\n",
    "print(comparison1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6751ec",
   "metadata": {},
   "source": [
    "lstm  914.831766  0.982478\n",
    "\n",
    "gru  901.801397  0.982973\n",
    "\n",
    "lstmgru  904.933202  0.982855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7fa660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 6s 58ms/step - loss: 0.0156 - val_loss: 0.0081\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 7.4410e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 9.2892e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 8.4287e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 9.5387e-04 - val_loss: 6.6665e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 9.1884e-04 - val_loss: 7.9191e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 9.0047e-04 - val_loss: 0.0011\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.4543e-04 - val_loss: 5.3521e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.4981e-04 - val_loss: 5.9707e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.3017e-04 - val_loss: 5.1109e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.7145e-04 - val_loss: 5.5506e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.3292e-04 - val_loss: 5.6069e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.3513e-04 - val_loss: 5.1272e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.1940e-04 - val_loss: 4.5413e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.4182e-04 - val_loss: 6.0877e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.0468e-04 - val_loss: 4.1507e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.2672e-04 - val_loss: 5.0103e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.9090e-04 - val_loss: 4.0808e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8782e-04 - val_loss: 4.6675e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.6482e-04 - val_loss: 5.5521e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8259e-04 - val_loss: 4.1832e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6301e-04 - val_loss: 4.7605e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.6632e-04 - val_loss: 4.0176e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1127e-04 - val_loss: 4.4923e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2218e-04 - val_loss: 3.6444e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3077e-04 - val_loss: 3.9552e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3319e-04 - val_loss: 5.3893e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7528e-04 - val_loss: 4.6761e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0852e-04 - val_loss: 5.3197e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1825e-04 - val_loss: 5.2604e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7646e-04 - val_loss: 4.2298e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0703e-04 - val_loss: 4.1639e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.6016e-04 - val_loss: 4.0152e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2733e-04 - val_loss: 5.3038e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2874e-04 - val_loss: 7.2074e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0223e-04 - val_loss: 3.9290e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7663e-04 - val_loss: 3.7106e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8811e-04 - val_loss: 3.8254e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7135e-04 - val_loss: 4.3520e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3696e-04 - val_loss: 4.4258e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7123e-04 - val_loss: 4.0391e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8869e-04 - val_loss: 3.4352e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6982e-04 - val_loss: 8.0641e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.3155e-04 - val_loss: 6.9192e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6885e-04 - val_loss: 3.4977e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6905e-04 - val_loss: 5.2445e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8618e-04 - val_loss: 4.8604e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7224e-04 - val_loss: 3.3150e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8078e-04 - val_loss: 7.3722e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5875e-04 - val_loss: 4.6199e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4855e-04 - val_loss: 7.0577e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5345e-04 - val_loss: 4.0825e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7511e-04 - val_loss: 4.5487e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0227e-04 - val_loss: 3.6745e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6476e-04 - val_loss: 3.6526e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1635e-04 - val_loss: 3.1836e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3718e-04 - val_loss: 5.5189e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.5578e-04 - val_loss: 4.0556e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5366e-04 - val_loss: 4.3680e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6401e-04 - val_loss: 3.4449e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7239e-04 - val_loss: 5.1846e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8826e-04 - val_loss: 7.1299e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1239e-04 - val_loss: 3.4553e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7561e-04 - val_loss: 6.5832e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8924e-04 - val_loss: 4.4363e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5255e-04 - val_loss: 4.3269e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.4462e-04 - val_loss: 3.2322e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0929e-04 - val_loss: 3.4731e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5736e-04 - val_loss: 6.2515e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8238e-04 - val_loss: 6.8335e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.0166e-04 - val_loss: 3.7714e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0813e-04 - val_loss: 7.2437e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4889e-04 - val_loss: 4.6479e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4162e-04 - val_loss: 3.6060e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4855e-04 - val_loss: 4.4822e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3990e-04 - val_loss: 3.3849e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3289e-04 - val_loss: 3.8083e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5644e-04 - val_loss: 3.2775e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6137e-04 - val_loss: 4.5924e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7806e-04 - val_loss: 3.7288e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7244e-04 - val_loss: 5.2403e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5363e-04 - val_loss: 3.2602e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5946e-04 - val_loss: 3.6459e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8873e-04 - val_loss: 4.8513e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5258e-04 - val_loss: 4.3299e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5527e-04 - val_loss: 3.3347e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 9s 106ms/step - loss: 0.0273 - val_loss: 0.0032\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0040 - val_loss: 0.0081\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0016 - val_loss: 9.8560e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 8.9629e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 8.4515e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0016 - val_loss: 7.3966e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 8.1222e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0012 - val_loss: 7.9992e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0011 - val_loss: 6.8345e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0010 - val_loss: 7.7177e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 9.4182e-04 - val_loss: 6.4640e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 8.8756e-04 - val_loss: 7.1270e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.9215e-04 - val_loss: 6.7479e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.4798e-04 - val_loss: 0.0011\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 8.6124e-04 - val_loss: 5.8227e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.7286e-04 - val_loss: 8.9447e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 7.6835e-04 - val_loss: 5.3563e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.7454e-04 - val_loss: 5.4751e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 7.4820e-04 - val_loss: 5.1722e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.9083e-04 - val_loss: 4.8421e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.9099e-04 - val_loss: 4.8453e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.3063e-04 - val_loss: 7.8229e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.6161e-04 - val_loss: 5.6959e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 6.4811e-04 - val_loss: 4.7996e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.5823e-04 - val_loss: 4.1963e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.7063e-04 - val_loss: 0.0011\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.7192e-04 - val_loss: 7.4224e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.6408e-04 - val_loss: 6.7778e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.4598e-04 - val_loss: 3.8650e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.4489e-04 - val_loss: 4.4594e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.5507e-04 - val_loss: 8.1301e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.0799e-04 - val_loss: 3.6110e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.0260e-04 - val_loss: 6.6068e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.5480e-04 - val_loss: 6.1601e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.0022e-04 - val_loss: 5.0028e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.2920e-04 - val_loss: 3.6346e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.5452e-04 - val_loss: 4.8545e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.2976e-04 - val_loss: 3.4990e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.4451e-04 - val_loss: 3.5791e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.5323e-04 - val_loss: 3.2191e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.4318e-04 - val_loss: 8.2648e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.8636e-04 - val_loss: 8.2873e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 5.1294e-04 - val_loss: 3.8728e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.4518e-04 - val_loss: 3.2228e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.5679e-04 - val_loss: 6.3455e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.2287e-04 - val_loss: 4.3832e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.6085e-04 - val_loss: 3.1657e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.7862e-04 - val_loss: 3.3581e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.1996e-04 - val_loss: 3.8893e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.7003e-04 - val_loss: 4.3983e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.2962e-04 - val_loss: 3.5307e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.4226e-04 - val_loss: 3.1359e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.8958e-04 - val_loss: 5.0704e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.3771e-04 - val_loss: 7.5821e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.1200e-04 - val_loss: 5.2097e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.3075e-04 - val_loss: 3.8337e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.8164e-04 - val_loss: 3.5692e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.5321e-04 - val_loss: 2.9688e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.9911e-04 - val_loss: 3.4235e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0512e-04 - val_loss: 5.7124e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.4552e-04 - val_loss: 3.0595e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 3.9003e-04 - val_loss: 4.2854e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.8754e-04 - val_loss: 5.3593e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.6994e-04 - val_loss: 2.9203e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 3.8454e-04 - val_loss: 7.6378e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.3157e-04 - val_loss: 3.8037e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.2142e-04 - val_loss: 2.8846e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.3514e-04 - val_loss: 2.8877e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 5.4943e-04 - val_loss: 7.7497e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.4178e-04 - val_loss: 3.0495e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.4727e-04 - val_loss: 2.9419e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.9826e-04 - val_loss: 4.1212e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.5562e-04 - val_loss: 4.0061e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9417e-04 - val_loss: 5.2603e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.6459e-04 - val_loss: 2.9448e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4851e-04 - val_loss: 2.9088e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.9766e-04 - val_loss: 2.9098e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.5423e-04 - val_loss: 3.0649e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.3345e-04 - val_loss: 4.3235e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.4143e-04 - val_loss: 3.2941e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4754e-04 - val_loss: 3.1180e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.7467e-04 - val_loss: 2.9913e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 3.6309e-04 - val_loss: 3.2660e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 4.1201e-04 - val_loss: 3.0074e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 3.9698e-04 - val_loss: 2.9228e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.7532e-04 - val_loss: 2.9609e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.0250e-04 - val_loss: 3.0176e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.4093e-04 - val_loss: 3.0662e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.8040e-04 - val_loss: 4.4558e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.8808e-04 - val_loss: 2.9148e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.5030e-04 - val_loss: 3.1929e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 3.4249e-04 - val_loss: 4.6045e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 3.5134e-04 - val_loss: 3.1943e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.6158e-04 - val_loss: 3.2909e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 4.2834e-04 - val_loss: 2.9542e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4955e-04 - val_loss: 4.6982e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.6997e-04 - val_loss: 3.6689e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 7s 83ms/step - loss: 0.0341 - val_loss: 0.0037\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0017 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0015 - val_loss: 9.5859e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0014 - val_loss: 8.5121e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0015 - val_loss: 8.8813e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0014 - val_loss: 8.1682e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0013 - val_loss: 7.5185e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0012 - val_loss: 8.1324e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.0012 - val_loss: 7.2539e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0013 - val_loss: 7.6359e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 7.2893e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0011 - val_loss: 7.2406e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0011 - val_loss: 6.8383e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 9.7981e-04 - val_loss: 7.1005e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 9.1865e-04 - val_loss: 6.1202e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 9.2029e-04 - val_loss: 6.6783e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 8.9708e-04 - val_loss: 7.1724e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 8.4258e-04 - val_loss: 6.5465e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 8.6149e-04 - val_loss: 6.6590e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 8.1083e-04 - val_loss: 7.6652e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 8.4323e-04 - val_loss: 7.2491e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 7.7961e-04 - val_loss: 6.3350e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.6342e-04 - val_loss: 6.8954e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.2764e-04 - val_loss: 5.8061e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.1707e-04 - val_loss: 5.8634e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.7427e-04 - val_loss: 5.6607e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.1703e-04 - val_loss: 5.1792e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.2486e-04 - val_loss: 5.6330e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.4282e-04 - val_loss: 8.8339e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.4819e-04 - val_loss: 6.9785e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 9.0582e-04 - val_loss: 9.3303e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.6825e-04 - val_loss: 5.2747e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.8233e-04 - val_loss: 4.8317e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.0564e-04 - val_loss: 6.8760e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.2862e-04 - val_loss: 4.7226e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.9578e-04 - val_loss: 4.5129e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.7196e-04 - val_loss: 4.3625e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.2585e-04 - val_loss: 4.3444e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.3971e-04 - val_loss: 4.3516e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.8414e-04 - val_loss: 7.9144e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.9210e-04 - val_loss: 4.5699e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.7248e-04 - val_loss: 5.1268e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.4335e-04 - val_loss: 5.5361e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.2974e-04 - val_loss: 4.6891e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.7963e-04 - val_loss: 8.0647e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.8925e-04 - val_loss: 0.0011\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.0903e-04 - val_loss: 4.7313e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5950e-04 - val_loss: 3.9695e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.4059e-04 - val_loss: 5.4856e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5502e-04 - val_loss: 3.6531e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5703e-04 - val_loss: 3.8201e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.2164e-04 - val_loss: 5.7187e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.1940e-04 - val_loss: 3.5721e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.0576e-04 - val_loss: 5.6765e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.3592e-04 - val_loss: 3.3426e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.6429e-04 - val_loss: 3.3012e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.1445e-04 - val_loss: 6.5187e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.0358e-04 - val_loss: 3.2517e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.0818e-04 - val_loss: 3.2172e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.1628e-04 - val_loss: 3.6074e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.1237e-04 - val_loss: 4.4170e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.2356e-04 - val_loss: 3.5597e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.5946e-04 - val_loss: 8.3374e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.3891e-04 - val_loss: 3.3092e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.9701e-04 - val_loss: 3.3744e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.3834e-04 - val_loss: 3.0753e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.9571e-04 - val_loss: 4.0539e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.2166e-04 - val_loss: 3.1011e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.6604e-04 - val_loss: 6.0375e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.4888e-04 - val_loss: 3.2380e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.3260e-04 - val_loss: 3.2583e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.8188e-04 - val_loss: 5.6219e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0483e-04 - val_loss: 3.2656e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7041e-04 - val_loss: 3.3760e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5779e-04 - val_loss: 3.0015e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.2568e-04 - val_loss: 2.9324e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.0155e-04 - val_loss: 3.5311e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.0923e-04 - val_loss: 4.6381e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.2576e-04 - val_loss: 4.3836e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9560e-04 - val_loss: 3.8187e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.4739e-04 - val_loss: 6.0149e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8009e-04 - val_loss: 3.9649e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7531e-04 - val_loss: 3.1018e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9273e-04 - val_loss: 3.3478e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0021e-04 - val_loss: 3.0237e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6680e-04 - val_loss: 3.0493e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7124e-04 - val_loss: 2.9601e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0148e-04 - val_loss: 3.7650e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7518e-04 - val_loss: 5.2156e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5207e-04 - val_loss: 2.9355e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9030e-04 - val_loss: 2.9327e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.9858e-04 - val_loss: 4.3247e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7697e-04 - val_loss: 2.9535e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.8257e-04 - val_loss: 3.5273e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.6787e-04 - val_loss: 4.2038e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1841e-04 - val_loss: 3.8782e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.1499e-04 - val_loss: 3.1633e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.8049e-04 - val_loss: 3.4445e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.1686e-04 - val_loss: 3.2003e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5691e-04 - val_loss: 3.1895e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8650e-04 - val_loss: 3.3144e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.7599e-04 - val_loss: 3.4056e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.3322e-04 - val_loss: 4.2712e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8728e-04 - val_loss: 4.5145e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.7757e-04 - val_loss: 3.2370e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.7234e-04 - val_loss: 2.9868e-04\n",
      "  algorithm        rmse        r2\n",
      "0      lstm  916.996935  0.982395\n",
      "1       gru  955.479888  0.980886\n",
      "2   lstmgru  909.505924  0.982681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(16,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(16,return_sequences=True))\n",
    "model.add(GRU(16))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "\n",
    "print(comparison1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0eea1b",
   "metadata": {},
   "source": [
    "0      lstm  916.996935  0.982395\n",
    "\n",
    "1       gru  955.479888  0.980886\n",
    "\n",
    "2   lstmgru  909.505924  0.982681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820a5bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 4s 52ms/step - loss: 0.0230 - val_loss: 0.0038\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 9.4576e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 8.0972e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 9.9259e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 8.7211e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 9.2647e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 7.9203e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 6.2770e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.5700e-04 - val_loss: 6.8760e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 5.9599e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 5.9078e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 9.1884e-04 - val_loss: 5.7022e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.2246e-04 - val_loss: 5.8814e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.5619e-04 - val_loss: 5.8940e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.4835e-04 - val_loss: 5.3910e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.3720e-04 - val_loss: 5.8866e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.0578e-04 - val_loss: 5.9102e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.4308e-04 - val_loss: 5.9507e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.8996e-04 - val_loss: 5.1424e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 7.9510e-04 - val_loss: 5.7921e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 8.4195e-04 - val_loss: 5.4803e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.2036e-04 - val_loss: 5.0871e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.0371e-04 - val_loss: 7.6241e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.8936e-04 - val_loss: 5.8782e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.1412e-04 - val_loss: 4.7592e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.2711e-04 - val_loss: 4.7184e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7914e-04 - val_loss: 4.5217e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7231e-04 - val_loss: 0.0012\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2002e-04 - val_loss: 4.6484e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.3503e-04 - val_loss: 4.5665e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.3888e-04 - val_loss: 4.7836e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.3380e-04 - val_loss: 4.4766e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9653e-04 - val_loss: 5.5204e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7332e-04 - val_loss: 4.2464e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9844e-04 - val_loss: 4.9385e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4257e-04 - val_loss: 4.1663e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7378e-04 - val_loss: 4.1577e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8793e-04 - val_loss: 4.3896e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.8955e-04 - val_loss: 4.1546e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2097e-04 - val_loss: 4.0579e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.1733e-04 - val_loss: 4.1008e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9530e-04 - val_loss: 4.0757e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0772e-04 - val_loss: 4.0702e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7952e-04 - val_loss: 5.1364e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0675e-04 - val_loss: 5.1014e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8292e-04 - val_loss: 3.8118e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.1343e-04 - val_loss: 3.8091e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7672e-04 - val_loss: 3.7333e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8673e-04 - val_loss: 6.2740e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9152e-04 - val_loss: 4.0186e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5473e-04 - val_loss: 5.0040e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9776e-04 - val_loss: 4.1930e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0530e-04 - val_loss: 4.0625e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8701e-04 - val_loss: 3.6377e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3655e-04 - val_loss: 4.1659e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2633e-04 - val_loss: 3.5557e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6247e-04 - val_loss: 3.8021e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4753e-04 - val_loss: 5.6454e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.6083e-04 - val_loss: 6.9091e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.2839e-04 - val_loss: 3.3970e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8389e-04 - val_loss: 3.3995e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1684e-04 - val_loss: 4.3300e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7744e-04 - val_loss: 3.3236e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0260e-04 - val_loss: 3.4374e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2867e-04 - val_loss: 3.7406e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3313e-04 - val_loss: 3.7882e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6427e-04 - val_loss: 3.2378e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8210e-04 - val_loss: 3.6373e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8731e-04 - val_loss: 3.3211e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0907e-04 - val_loss: 3.7725e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0695e-04 - val_loss: 4.0770e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1176e-04 - val_loss: 3.8832e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1989e-04 - val_loss: 3.6670e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0329e-04 - val_loss: 3.4601e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6088e-04 - val_loss: 4.1790e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2746e-04 - val_loss: 3.1925e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1601e-04 - val_loss: 3.6764e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.7176e-04 - val_loss: 3.7663e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0639e-04 - val_loss: 3.2072e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9026e-04 - val_loss: 3.6266e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6942e-04 - val_loss: 3.0195e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5604e-04 - val_loss: 3.3335e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3490e-04 - val_loss: 3.8437e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6715e-04 - val_loss: 2.9905e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0726e-04 - val_loss: 3.4282e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.5572e-04 - val_loss: 3.0385e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1453e-04 - val_loss: 3.1765e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6227e-04 - val_loss: 3.0920e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8516e-04 - val_loss: 2.9607e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5041e-04 - val_loss: 3.3704e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1933e-04 - val_loss: 4.6426e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1848e-04 - val_loss: 3.0121e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9833e-04 - val_loss: 4.7345e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0394e-04 - val_loss: 3.1628e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2265e-04 - val_loss: 2.9672e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6337e-04 - val_loss: 3.0105e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7249e-04 - val_loss: 3.4306e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9680e-04 - val_loss: 3.3383e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5244e-04 - val_loss: 3.0923e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5212e-04 - val_loss: 2.9379e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2530e-04 - val_loss: 2.9339e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7583e-04 - val_loss: 3.7662e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4415e-04 - val_loss: 2.9821e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5226e-04 - val_loss: 3.2499e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.3595e-04 - val_loss: 3.3976e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5552e-04 - val_loss: 3.2935e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6854e-04 - val_loss: 2.9435e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.3364e-04 - val_loss: 2.9341e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5822e-04 - val_loss: 3.5420e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1119e-04 - val_loss: 3.4702e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8336e-04 - val_loss: 3.0055e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4434e-04 - val_loss: 3.1798e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4655e-04 - val_loss: 2.9305e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6327e-04 - val_loss: 3.1963e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0809e-04 - val_loss: 3.1941e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7377e-04 - val_loss: 2.9168e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6582e-04 - val_loss: 7.2627e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6411e-04 - val_loss: 2.9837e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7628e-04 - val_loss: 4.5014e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.0543e-04 - val_loss: 3.7838e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8584e-04 - val_loss: 3.6069e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7663e-04 - val_loss: 3.5043e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6043e-04 - val_loss: 3.2472e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6483e-04 - val_loss: 3.3332e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6862e-04 - val_loss: 2.9134e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.2214e-04 - val_loss: 7.4176e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.8372e-04 - val_loss: 3.8851e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2170e-04 - val_loss: 4.5913e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.0175e-04 - val_loss: 3.9852e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8306e-04 - val_loss: 3.1326e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6435e-04 - val_loss: 3.2579e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4841e-04 - val_loss: 2.9300e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.3995e-04 - val_loss: 2.9183e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.0140e-04 - val_loss: 3.5736e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6220e-04 - val_loss: 3.3954e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8710e-04 - val_loss: 3.7358e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6471e-04 - val_loss: 2.9478e-04\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4247e-04 - val_loss: 3.5199e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4488e-04 - val_loss: 3.2503e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4294e-04 - val_loss: 2.9443e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6414e-04 - val_loss: 3.2981e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7286e-04 - val_loss: 4.0316e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7340e-04 - val_loss: 2.9211e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.3991e-04 - val_loss: 2.9185e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5240e-04 - val_loss: 5.4581e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8813e-04 - val_loss: 3.0673e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5053e-04 - val_loss: 3.1137e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7567e-04 - val_loss: 3.2555e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9018e-04 - val_loss: 2.9534e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4413e-04 - val_loss: 4.9863e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9200e-04 - val_loss: 3.6990e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9439e-04 - val_loss: 3.2807e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6142e-04 - val_loss: 3.0049e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6051e-04 - val_loss: 3.4206e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5432e-04 - val_loss: 3.0142e-04\n",
      "914.0298083346822\n",
      "0.9825085355302514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val0      lstm  916.996935  0.982395\n",
    "1       gru  955.479888  0.980886\n",
    "2   lstmgru  909.505924  0.982681\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "print(lstm_rmse)\n",
    "print(lstm_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5eef0",
   "metadata": {},
   "source": [
    "914.0298083346822\n",
    "\n",
    "0.9825085355302514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40877d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 7s 62ms/step - loss: 0.0637 - val_loss: 0.0048\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 8.9745e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 8.4038e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 8.2437e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 8.6972e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 6.9422e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 7.3746e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 6.5959e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 8.7011e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 7.8572e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 7.0642e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 9.5841e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 6.4021e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 6.1610e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.6105e-04 - val_loss: 6.0907e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.2172e-04 - val_loss: 6.1390e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.5921e-04 - val_loss: 9.3935e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.7168e-04 - val_loss: 0.0011\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.2642e-04 - val_loss: 6.7381e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.6636e-04 - val_loss: 7.2532e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.5242e-04 - val_loss: 7.1864e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.2812e-04 - val_loss: 5.7731e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.8805e-04 - val_loss: 7.5629e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.8579e-04 - val_loss: 6.9096e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.3718e-04 - val_loss: 7.4274e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.4923e-04 - val_loss: 7.1528e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.5179e-04 - val_loss: 8.5543e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.6351e-04 - val_loss: 6.5384e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.3546e-04 - val_loss: 5.4219e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.8823e-04 - val_loss: 6.5229e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.6247e-04 - val_loss: 5.7667e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.2046e-04 - val_loss: 5.7195e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.1809e-04 - val_loss: 5.3994e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.7340e-04 - val_loss: 0.0011\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.5735e-04 - val_loss: 0.0010\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.5508e-04 - val_loss: 5.0921e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.7446e-04 - val_loss: 9.9313e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.3286e-04 - val_loss: 8.8815e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.7357e-04 - val_loss: 5.4627e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.3929e-04 - val_loss: 4.9529e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.1422e-04 - val_loss: 5.8078e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9950e-04 - val_loss: 5.0238e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.4274e-04 - val_loss: 8.0168e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.0636e-04 - val_loss: 0.0010\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.0713e-04 - val_loss: 5.8873e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.6033e-04 - val_loss: 5.1940e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.7041e-04 - val_loss: 4.5089e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.5030e-04 - val_loss: 5.4460e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.6382e-04 - val_loss: 5.6104e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4008e-04 - val_loss: 4.4762e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2579e-04 - val_loss: 4.6503e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1797e-04 - val_loss: 4.5909e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.3399e-04 - val_loss: 6.4057e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4141e-04 - val_loss: 4.2721e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1155e-04 - val_loss: 4.1814e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9606e-04 - val_loss: 4.2359e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8261e-04 - val_loss: 4.5970e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2451e-04 - val_loss: 4.5606e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0155e-04 - val_loss: 4.1053e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2683e-04 - val_loss: 4.0476e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0426e-04 - val_loss: 3.9733e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0273e-04 - val_loss: 4.8097e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4175e-04 - val_loss: 3.9451e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5399e-04 - val_loss: 4.3563e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9076e-04 - val_loss: 3.9846e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5937e-04 - val_loss: 4.1170e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1231e-04 - val_loss: 4.3355e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8605e-04 - val_loss: 6.0209e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0050e-04 - val_loss: 9.4707e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9245e-04 - val_loss: 4.0466e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3008e-04 - val_loss: 3.5305e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3405e-04 - val_loss: 3.7769e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3149e-04 - val_loss: 3.9409e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8917e-04 - val_loss: 3.3936e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5634e-04 - val_loss: 3.9282e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2486e-04 - val_loss: 3.9415e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4007e-04 - val_loss: 3.8130e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3929e-04 - val_loss: 4.4160e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6461e-04 - val_loss: 3.2963e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1342e-04 - val_loss: 3.4111e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3971e-04 - val_loss: 4.1269e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3292e-04 - val_loss: 3.3444e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1013e-04 - val_loss: 3.6041e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8080e-04 - val_loss: 6.9165e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.5494e-04 - val_loss: 3.5340e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4869e-04 - val_loss: 9.8446e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3441e-04 - val_loss: 3.6708e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1505e-04 - val_loss: 3.2577e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6914e-04 - val_loss: 3.5952e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2254e-04 - val_loss: 3.7194e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.6554e-04 - val_loss: 3.8232e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8405e-04 - val_loss: 7.7434e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3973e-04 - val_loss: 4.1269e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9917e-04 - val_loss: 3.1358e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9128e-04 - val_loss: 3.0300e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.6093e-04 - val_loss: 3.0904e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.0263e-04 - val_loss: 4.5931e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.8863e-04 - val_loss: 3.2224e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4028e-04 - val_loss: 3.2404e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5225e-04 - val_loss: 3.1411e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5002e-04 - val_loss: 3.1305e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0116e-04 - val_loss: 3.1406e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.1566e-04 - val_loss: 3.4904e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.4024e-04 - val_loss: 3.4133e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5354e-04 - val_loss: 3.0151e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8581e-04 - val_loss: 4.3858e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8947e-04 - val_loss: 4.3934e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6353e-04 - val_loss: 4.9156e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7433e-04 - val_loss: 3.0744e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0477e-04 - val_loss: 3.3945e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5294e-04 - val_loss: 3.2329e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.8207e-04 - val_loss: 7.7822e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4902e-04 - val_loss: 3.0441e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3788e-04 - val_loss: 3.6908e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5805e-04 - val_loss: 3.0377e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8633e-04 - val_loss: 4.8573e-04\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8965e-04 - val_loss: 5.1560e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6372e-04 - val_loss: 3.3419e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5309e-04 - val_loss: 3.3717e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5583e-04 - val_loss: 2.9822e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.5735e-04 - val_loss: 3.4500e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9969e-04 - val_loss: 5.6208e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6369e-04 - val_loss: 3.0512e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7342e-04 - val_loss: 2.9742e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0704e-04 - val_loss: 3.1436e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4651e-04 - val_loss: 3.8743e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5210e-04 - val_loss: 3.0509e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4203e-04 - val_loss: 3.1756e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9381e-04 - val_loss: 3.6914e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.0499e-04 - val_loss: 3.0565e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8855e-04 - val_loss: 3.0863e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9176e-04 - val_loss: 3.0506e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0605e-04 - val_loss: 4.1509e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9424e-04 - val_loss: 3.4817e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.6939e-04 - val_loss: 2.9896e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1922e-04 - val_loss: 3.6807e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7365e-04 - val_loss: 3.7478e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6372e-04 - val_loss: 3.2070e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6220e-04 - val_loss: 3.5811e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4913e-04 - val_loss: 3.6181e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.5055e-04 - val_loss: 4.6311e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7454e-04 - val_loss: 3.0799e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3785e-04 - val_loss: 3.2146e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3870e-04 - val_loss: 5.5367e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5732e-04 - val_loss: 3.3361e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5155e-04 - val_loss: 3.5368e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6410e-04 - val_loss: 3.2214e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4457e-04 - val_loss: 3.5113e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3619e-04 - val_loss: 3.0251e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0002e-04 - val_loss: 3.8455e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8682e-04 - val_loss: 3.1661e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3517e-04 - val_loss: 3.2250e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3942e-04 - val_loss: 4.1701e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3293e-04 - val_loss: 3.0642e-04\n",
      "923.5088948925932\n",
      "0.9821438584759484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "print(lstm_rmse)\n",
    "print(lstm_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b1e1a",
   "metadata": {},
   "source": [
    "923.5088948925932\n",
    "\n",
    "0.9821438584759484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(16,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(16,return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "gru_rmse, gru_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd323397",
   "metadata": {},
   "source": [
    "# LSTM 16 2 / GRU 64 3 / LSTM+GRU 64 2 2 최종 선정!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03166fba",
   "metadata": {},
   "source": [
    "EarlyStopping patience 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a56c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 5s 53ms/step - loss: 0.1862 - val_loss: 0.0072\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0025\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.9502e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.5389e-04 - val_loss: 0.0019\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.4182e-04 - val_loss: 0.0011\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.0949e-04 - val_loss: 0.0016\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 9.8216e-04 - val_loss: 0.0010\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.7850e-04 - val_loss: 7.2201e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.7507e-04 - val_loss: 7.2845e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.0931e-04 - val_loss: 9.5963e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 9.3210e-04 - val_loss: 5.9820e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.0533e-04 - val_loss: 0.0010\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.0538e-04 - val_loss: 9.9857e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2632e-04 - val_loss: 9.4548e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0720e-04 - val_loss: 5.8516e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.1433e-04 - val_loss: 9.0155e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0226e-04 - val_loss: 7.2202e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.9500e-04 - val_loss: 7.9963e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.7570e-04 - val_loss: 7.1640e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.7162e-04 - val_loss: 7.0954e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.3632e-04 - val_loss: 7.2375e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.6995e-04 - val_loss: 5.6995e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.5601e-04 - val_loss: 0.0013\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.4247e-04 - val_loss: 7.2992e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.2248e-04 - val_loss: 6.1713e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.0673e-04 - val_loss: 6.4761e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.4191e-04 - val_loss: 9.8136e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.1423e-04 - val_loss: 8.4237e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.0169e-04 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.9478e-04 - val_loss: 7.8790e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3247e-04 - val_loss: 5.1623e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.0432e-04 - val_loss: 4.8507e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.3944e-04 - val_loss: 8.6933e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.3363e-04 - val_loss: 6.4448e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.2547e-04 - val_loss: 6.7600e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.7447e-04 - val_loss: 5.6154e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.3305e-04 - val_loss: 5.6052e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.1962e-04 - val_loss: 4.9810e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.0867e-04 - val_loss: 4.5361e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.7588e-04 - val_loss: 7.3454e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.2475e-04 - val_loss: 8.1525e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 6.3963e-04 - val_loss: 5.0236e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0546e-04 - val_loss: 6.3055e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.7990e-04 - val_loss: 6.7046e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.9958e-04 - val_loss: 6.2329e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.4115e-04 - val_loss: 8.8622e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.7403e-04 - val_loss: 4.3966e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.5875e-04 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.0800e-04 - val_loss: 4.2626e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.1270e-04 - val_loss: 6.5351e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.7533e-04 - val_loss: 5.7375e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.5755e-04 - val_loss: 5.0972e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.5357e-04 - val_loss: 4.2365e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.9991e-04 - val_loss: 7.4216e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4501e-04 - val_loss: 5.1059e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.2383e-04 - val_loss: 4.7739e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4537e-04 - val_loss: 5.5978e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.1731e-04 - val_loss: 4.5170e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.1857e-04 - val_loss: 4.1441e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.4734e-04 - val_loss: 6.9402e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0853e-04 - val_loss: 5.5031e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2361e-04 - val_loss: 5.8035e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9146e-04 - val_loss: 4.4499e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2511e-04 - val_loss: 5.5400e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0370e-04 - val_loss: 5.6679e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.7744e-04 - val_loss: 4.3205e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.9263e-04 - val_loss: 4.8396e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 5.1021e-04 - val_loss: 9.5977e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.1529e-04 - val_loss: 6.1115e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.8732e-04 - val_loss: 3.8593e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9467e-04 - val_loss: 4.7017e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8968e-04 - val_loss: 9.3987e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8800e-04 - val_loss: 4.1977e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7742e-04 - val_loss: 5.0691e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7752e-04 - val_loss: 7.1434e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0450e-04 - val_loss: 4.4890e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7493e-04 - val_loss: 3.7476e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.6164e-04 - val_loss: 7.0737e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.6361e-04 - val_loss: 4.5502e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.6470e-04 - val_loss: 4.2393e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.2274e-04 - val_loss: 7.7204e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9631e-04 - val_loss: 7.3965e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.1774e-04 - val_loss: 5.3864e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3060e-04 - val_loss: 3.9650e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.6063e-04 - val_loss: 4.7825e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2402e-04 - val_loss: 4.4872e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.8084e-04 - val_loss: 3.5866e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.4878e-04 - val_loss: 5.6539e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3149e-04 - val_loss: 3.7876e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.2309e-04 - val_loss: 3.7491e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.7020e-04 - val_loss: 6.6547e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.0881e-04 - val_loss: 6.1943e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1598e-04 - val_loss: 3.5045e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.4372e-04 - val_loss: 5.2548e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1625e-04 - val_loss: 3.5016e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3429e-04 - val_loss: 3.4308e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0919e-04 - val_loss: 5.2936e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4028e-04 - val_loss: 4.4234e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0446e-04 - val_loss: 3.3949e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9280e-04 - val_loss: 4.3882e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0343e-04 - val_loss: 3.3510e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3569e-04 - val_loss: 3.3624e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0416e-04 - val_loss: 3.3459e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2476e-04 - val_loss: 3.6628e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2961e-04 - val_loss: 7.5965e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2722e-04 - val_loss: 3.3656e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0744e-04 - val_loss: 4.1252e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0595e-04 - val_loss: 4.0541e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8510e-04 - val_loss: 3.2625e-04\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8601e-04 - val_loss: 3.2899e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8367e-04 - val_loss: 3.4802e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0662e-04 - val_loss: 4.0992e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8035e-04 - val_loss: 3.9168e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7726e-04 - val_loss: 3.4956e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6990e-04 - val_loss: 4.2696e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7986e-04 - val_loss: 4.3452e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8659e-04 - val_loss: 3.8558e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5955e-04 - val_loss: 3.3673e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7834e-04 - val_loss: 3.7306e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7843e-04 - val_loss: 3.2537e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7112e-04 - val_loss: 4.3277e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5854e-04 - val_loss: 4.6168e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9131e-04 - val_loss: 3.6721e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8085e-04 - val_loss: 3.1939e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5872e-04 - val_loss: 3.0871e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5200e-04 - val_loss: 3.7383e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.8526e-04 - val_loss: 3.2100e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9035e-04 - val_loss: 3.2014e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9113e-04 - val_loss: 4.4736e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6322e-04 - val_loss: 3.1164e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7149e-04 - val_loss: 3.1381e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1928e-04 - val_loss: 4.3139e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2155e-04 - val_loss: 3.3012e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2020e-04 - val_loss: 3.7656e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3927e-04 - val_loss: 3.0514e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5595e-04 - val_loss: 3.0529e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6427e-04 - val_loss: 3.0313e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7401e-04 - val_loss: 3.3020e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7788e-04 - val_loss: 3.1287e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6064e-04 - val_loss: 4.2115e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4655e-04 - val_loss: 3.1915e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6085e-04 - val_loss: 3.9200e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6821e-04 - val_loss: 3.0524e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5665e-04 - val_loss: 2.9731e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6009e-04 - val_loss: 3.2662e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4873e-04 - val_loss: 3.1554e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4902e-04 - val_loss: 4.5461e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6709e-04 - val_loss: 3.2676e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3855e-04 - val_loss: 3.3162e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5850e-04 - val_loss: 4.7333e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7087e-04 - val_loss: 3.6953e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4443e-04 - val_loss: 3.0515e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5133e-04 - val_loss: 2.9681e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4441e-04 - val_loss: 3.3809e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7792e-04 - val_loss: 4.0318e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5106e-04 - val_loss: 4.3194e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3687e-04 - val_loss: 3.0332e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4420e-04 - val_loss: 2.9963e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3539e-04 - val_loss: 3.6232e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4349e-04 - val_loss: 3.3094e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3595e-04 - val_loss: 2.9348e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3649e-04 - val_loss: 3.7987e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5864e-04 - val_loss: 4.2297e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1165e-04 - val_loss: 3.3216e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4127e-04 - val_loss: 3.0477e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3798e-04 - val_loss: 3.0946e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3268e-04 - val_loss: 3.0716e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4480e-04 - val_loss: 2.9290e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5318e-04 - val_loss: 2.9343e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3408e-04 - val_loss: 2.9157e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6091e-04 - val_loss: 3.5018e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3431e-04 - val_loss: 2.9870e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8992e-04 - val_loss: 4.5122e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4608e-04 - val_loss: 3.4422e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8109e-04 - val_loss: 4.2380e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3716e-04 - val_loss: 3.5088e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9898e-04 - val_loss: 3.1679e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3680e-04 - val_loss: 2.9187e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3443e-04 - val_loss: 3.5890e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5962e-04 - val_loss: 3.2604e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7270e-04 - val_loss: 3.2447e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5505e-04 - val_loss: 4.3220e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5089e-04 - val_loss: 2.9340e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7414e-04 - val_loss: 2.9111e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6694e-04 - val_loss: 3.0295e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5073e-04 - val_loss: 3.3427e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3748e-04 - val_loss: 2.9195e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3901e-04 - val_loss: 5.2130e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9595e-04 - val_loss: 7.6585e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6507e-04 - val_loss: 3.6370e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.2907e-04 - val_loss: 2.9041e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4659e-04 - val_loss: 4.2806e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5651e-04 - val_loss: 3.4960e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8307e-04 - val_loss: 4.1439e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7435e-04 - val_loss: 3.0754e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3366e-04 - val_loss: 3.0524e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3091e-04 - val_loss: 4.6035e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8696e-04 - val_loss: 2.9351e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4352e-04 - val_loss: 2.9805e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6541e-04 - val_loss: 2.9719e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8401e-04 - val_loss: 3.9545e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7824e-04 - val_loss: 2.9286e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4254e-04 - val_loss: 3.1476e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4611e-04 - val_loss: 3.4625e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8831e-04 - val_loss: 3.6098e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4063e-04 - val_loss: 3.1890e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5683e-04 - val_loss: 4.2015e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6293e-04 - val_loss: 3.4726e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7353e-04 - val_loss: 3.2280e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7591e-04 - val_loss: 3.2014e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5607e-04 - val_loss: 3.0223e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2461e-04 - val_loss: 3.2018e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5394e-04 - val_loss: 3.2912e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6649e-04 - val_loss: 3.0781e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5060e-04 - val_loss: 3.1240e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3821e-04 - val_loss: 3.0473e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4811e-04 - val_loss: 3.0404e-04\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6055e-04 - val_loss: 3.2028e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.2694e-04 - val_loss: 3.9646e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3250e-04 - val_loss: 3.1591e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3636e-04 - val_loss: 2.9021e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3782e-04 - val_loss: 3.8461e-04\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4968e-04 - val_loss: 2.9151e-04\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5515e-04 - val_loss: 3.4045e-04\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6168e-04 - val_loss: 4.1422e-04\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0664e-04 - val_loss: 4.6577e-04\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3622e-04 - val_loss: 2.9330e-04\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6771e-04 - val_loss: 3.2920e-04\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3773e-04 - val_loss: 3.2980e-04\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4662e-04 - val_loss: 2.9235e-04\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3478e-04 - val_loss: 3.2786e-04\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4011e-04 - val_loss: 3.0473e-04\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6071e-04 - val_loss: 6.1534e-04\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7321e-04 - val_loss: 2.9212e-04\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5145e-04 - val_loss: 3.1536e-04\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0071e-04 - val_loss: 3.1306e-04\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4534e-04 - val_loss: 3.3891e-04\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5080e-04 - val_loss: 3.0285e-04\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4106e-04 - val_loss: 4.9368e-04\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8767e-04 - val_loss: 3.5388e-04\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5300e-04 - val_loss: 3.4458e-04\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4190e-04 - val_loss: 3.5743e-04\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3648e-04 - val_loss: 3.0113e-04\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7142e-04 - val_loss: 2.9121e-04\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4544e-04 - val_loss: 5.4668e-04\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8258e-04 - val_loss: 2.9071e-04\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6515e-04 - val_loss: 3.1109e-04\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3912e-04 - val_loss: 3.4522e-04\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6278e-04 - val_loss: 3.4460e-04\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3927e-04 - val_loss: 3.1207e-04\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.2873e-04 - val_loss: 2.9991e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 7s 57ms/step - loss: 0.0172 - val_loss: 0.0050\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 7.1284e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 9.5761e-04 - val_loss: 6.4143e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 8.7968e-04 - val_loss: 5.7502e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 8.0836e-04 - val_loss: 5.5174e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 7.5539e-04 - val_loss: 5.0613e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.3054e-04 - val_loss: 4.9138e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.7737e-04 - val_loss: 4.9447e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.4854e-04 - val_loss: 7.4509e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.9913e-04 - val_loss: 4.2221e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.7456e-04 - val_loss: 3.9904e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 5.6371e-04 - val_loss: 4.1031e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 6.2215e-04 - val_loss: 4.8591e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.9739e-04 - val_loss: 3.6335e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.2296e-04 - val_loss: 3.5546e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6826e-04 - val_loss: 6.6593e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.5743e-04 - val_loss: 3.3666e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2289e-04 - val_loss: 3.3337e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.6621e-04 - val_loss: 3.3064e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4691e-04 - val_loss: 8.9776e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6388e-04 - val_loss: 3.5364e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9948e-04 - val_loss: 5.4632e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 5.1671e-04 - val_loss: 4.4653e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.7442e-04 - val_loss: 3.1420e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1365e-04 - val_loss: 3.0417e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8813e-04 - val_loss: 4.8182e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9477e-04 - val_loss: 4.7045e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2246e-04 - val_loss: 3.0430e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6301e-04 - val_loss: 3.3391e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1438e-04 - val_loss: 3.3727e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1758e-04 - val_loss: 4.2835e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.4286e-04 - val_loss: 3.9797e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8864e-04 - val_loss: 3.3759e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6103e-04 - val_loss: 5.6457e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.9335e-04 - val_loss: 3.7436e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5715e-04 - val_loss: 3.8160e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7157e-04 - val_loss: 3.0941e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5265e-04 - val_loss: 3.0166e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8531e-04 - val_loss: 5.7861e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0255e-04 - val_loss: 2.9495e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.7264e-04 - val_loss: 3.5105e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8017e-04 - val_loss: 5.1241e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5868e-04 - val_loss: 3.9644e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0925e-04 - val_loss: 3.1724e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6706e-04 - val_loss: 5.7797e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.3776e-04 - val_loss: 2.9126e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.5871e-04 - val_loss: 2.9981e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7334e-04 - val_loss: 3.4944e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6530e-04 - val_loss: 3.1731e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9266e-04 - val_loss: 4.2266e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5139e-04 - val_loss: 3.4034e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5835e-04 - val_loss: 3.5019e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9509e-04 - val_loss: 2.8594e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4201e-04 - val_loss: 3.0901e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0388e-04 - val_loss: 6.5198e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.3743e-04 - val_loss: 3.4375e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9522e-04 - val_loss: 5.4604e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8686e-04 - val_loss: 2.9468e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8655e-04 - val_loss: 2.8545e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1507e-04 - val_loss: 4.3577e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.1333e-04 - val_loss: 2.8268e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6210e-04 - val_loss: 3.2494e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5206e-04 - val_loss: 5.5176e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2861e-04 - val_loss: 2.9787e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.6623e-04 - val_loss: 5.2817e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.9500e-04 - val_loss: 2.8757e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0484e-04 - val_loss: 5.5649e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.0597e-04 - val_loss: 3.7523e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.4868e-04 - val_loss: 6.3864e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1568e-04 - val_loss: 3.8550e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9281e-04 - val_loss: 3.2727e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4215e-04 - val_loss: 2.9005e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4406e-04 - val_loss: 7.4988e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.0873e-04 - val_loss: 3.1110e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7724e-04 - val_loss: 2.8826e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6028e-04 - val_loss: 2.9942e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.6571e-04 - val_loss: 2.9308e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.1146e-04 - val_loss: 4.1907e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6717e-04 - val_loss: 3.0657e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.9546e-04 - val_loss: 4.4285e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5543e-04 - val_loss: 3.5173e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5061e-04 - val_loss: 3.2647e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6876e-04 - val_loss: 2.8782e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.9244e-04 - val_loss: 3.0628e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4803e-04 - val_loss: 2.8705e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5047e-04 - val_loss: 3.2595e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8491e-04 - val_loss: 3.8068e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.8818e-04 - val_loss: 3.9225e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.4536e-04 - val_loss: 4.8497e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.4586e-04 - val_loss: 2.8792e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.9432e-04 - val_loss: 7.9433e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 8s 79ms/step - loss: 0.0235 - val_loss: 0.0052\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0015 - val_loss: 8.2859e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0016 - val_loss: 8.9004e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0012 - val_loss: 8.0853e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0013 - val_loss: 7.4854e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0012 - val_loss: 8.1330e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0010 - val_loss: 8.4165e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 9.5880e-04 - val_loss: 0.0010\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0011 - val_loss: 9.7502e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 8.0150e-04 - val_loss: 5.6261e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 7.6033e-04 - val_loss: 7.8075e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 7.9546e-04 - val_loss: 9.2175e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.7324e-04 - val_loss: 5.2155e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 8.0256e-04 - val_loss: 5.6173e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 8.5037e-04 - val_loss: 9.6663e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 7.9585e-04 - val_loss: 4.8015e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.7482e-04 - val_loss: 5.6341e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.9408e-04 - val_loss: 9.4502e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.5695e-04 - val_loss: 6.2458e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.5701e-04 - val_loss: 5.3205e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.9606e-04 - val_loss: 0.0014\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.8653e-04 - val_loss: 5.2337e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.1944e-04 - val_loss: 4.1550e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.0970e-04 - val_loss: 4.2615e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.6885e-04 - val_loss: 4.0841e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.9057e-04 - val_loss: 3.8615e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.0963e-04 - val_loss: 3.4861e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.4411e-04 - val_loss: 4.5370e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.4096e-04 - val_loss: 4.4838e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.2401e-04 - val_loss: 3.2821e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.8059e-04 - val_loss: 3.2590e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.3907e-04 - val_loss: 5.8033e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.9607e-04 - val_loss: 3.1147e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.0997e-04 - val_loss: 7.6763e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 5.3576e-04 - val_loss: 3.2672e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 4.6081e-04 - val_loss: 3.0850e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.1541e-04 - val_loss: 4.0438e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.0752e-04 - val_loss: 3.1620e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.3241e-04 - val_loss: 4.8553e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.8437e-04 - val_loss: 3.1303e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.6590e-04 - val_loss: 3.5554e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.8427e-04 - val_loss: 4.4814e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.9171e-04 - val_loss: 2.9147e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.6838e-04 - val_loss: 7.4185e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.0745e-04 - val_loss: 5.0778e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 4.2966e-04 - val_loss: 3.6104e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.9608e-04 - val_loss: 4.0596e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.3018e-04 - val_loss: 3.7584e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.8928e-04 - val_loss: 4.6093e-04\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 42ms/step - loss: 4.3575e-04 - val_loss: 3.2186e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 4.5248e-04 - val_loss: 3.7308e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.0418e-04 - val_loss: 3.1047e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.3016e-04 - val_loss: 2.9814e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.6104e-04 - val_loss: 2.9954e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.7027e-04 - val_loss: 4.8550e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.9610e-04 - val_loss: 7.9185e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.3446e-04 - val_loss: 3.3399e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6276e-04 - val_loss: 2.9696e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8143e-04 - val_loss: 2.9310e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.4610e-04 - val_loss: 3.0416e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.8285e-04 - val_loss: 3.0595e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.4938e-04 - val_loss: 2.8772e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.9046e-04 - val_loss: 4.9891e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.4141e-04 - val_loss: 3.7015e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6098e-04 - val_loss: 4.3495e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0810e-04 - val_loss: 2.9068e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8913e-04 - val_loss: 3.0350e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5109e-04 - val_loss: 2.9110e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.8643e-04 - val_loss: 7.0159e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.1048e-04 - val_loss: 4.4060e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.7646e-04 - val_loss: 2.9053e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.0736e-04 - val_loss: 3.2594e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.7089e-04 - val_loss: 4.1102e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.7107e-04 - val_loss: 4.7021e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.4823e-04 - val_loss: 3.2074e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.2142e-04 - val_loss: 2.9321e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8290e-04 - val_loss: 2.9911e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5704e-04 - val_loss: 3.4740e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8738e-04 - val_loss: 3.2661e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.3459e-04 - val_loss: 3.3284e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.5920e-04 - val_loss: 2.9463e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5111e-04 - val_loss: 3.0428e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.2023e-04 - val_loss: 2.9434e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.4038e-04 - val_loss: 2.9931e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1805e-04 - val_loss: 9.3374e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.0569e-04 - val_loss: 3.4373e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7137e-04 - val_loss: 4.3639e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1109e-04 - val_loss: 4.5384e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.6544e-04 - val_loss: 9.2060e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.3715e-04 - val_loss: 2.9377e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5966e-04 - val_loss: 3.0491e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8165e-04 - val_loss: 2.9603e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>912.249923</td>\n",
       "      <td>0.982577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>900.343877</td>\n",
       "      <td>0.983028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>908.328702</td>\n",
       "      <td>0.982726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm        rmse        r2\n",
       "0      lstm  912.249923  0.982577\n",
       "1       gru  900.343877  0.983028\n",
       "2   lstmgru  908.328702  0.982726"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "result_li = []\n",
    "\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "comparison1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba803a1",
   "metadata": {},
   "source": [
    "EarlyStopping patience 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8192c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 4s 38ms/step - loss: 0.0650 - val_loss: 0.0106\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.9213e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.8705e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 9.4947e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 7.9658e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.7345e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 7.3901e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 7.1418e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.8715e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.9929e-04 - val_loss: 9.1289e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.5985e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.7216e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.8174e-04 - val_loss: 6.5780e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.0440e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.7325e-04 - val_loss: 7.3079e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.4007e-04 - val_loss: 6.0938e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 9.3198e-04 - val_loss: 6.8912e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.8715e-04 - val_loss: 6.4550e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.9717e-04 - val_loss: 5.9332e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 9.7564e-04 - val_loss: 0.0011\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.9630e-04 - val_loss: 5.7335e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6804e-04 - val_loss: 5.9482e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.4198e-04 - val_loss: 6.1405e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3008e-04 - val_loss: 5.6848e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0983e-04 - val_loss: 5.5773e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0954e-04 - val_loss: 5.4851e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.7946e-04 - val_loss: 5.2830e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3163e-04 - val_loss: 8.1566e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.6433e-04 - val_loss: 6.9364e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.9087e-04 - val_loss: 5.2360e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.9833e-04 - val_loss: 5.8148e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.5971e-04 - val_loss: 6.2081e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.8317e-04 - val_loss: 5.8658e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.8124e-04 - val_loss: 6.0545e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.3576e-04 - val_loss: 5.1279e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.4736e-04 - val_loss: 5.9341e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0074e-04 - val_loss: 7.6074e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0466e-04 - val_loss: 5.0470e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.4500e-04 - val_loss: 4.9293e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.9257e-04 - val_loss: 6.1045e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.6656e-04 - val_loss: 5.1038e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.6109e-04 - val_loss: 7.9067e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.1090e-04 - val_loss: 5.2237e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6319e-04 - val_loss: 4.6707e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.5663e-04 - val_loss: 4.9602e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.7603e-04 - val_loss: 5.2516e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.8054e-04 - val_loss: 4.6668e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.3846e-04 - val_loss: 4.8670e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4213e-04 - val_loss: 4.6522e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4167e-04 - val_loss: 4.6763e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.2984e-04 - val_loss: 7.6991e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.8446e-04 - val_loss: 8.4837e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.5616e-04 - val_loss: 4.7769e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4237e-04 - val_loss: 5.9096e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.0559e-04 - val_loss: 4.8475e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.9123e-04 - val_loss: 4.4148e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4705e-04 - val_loss: 7.9006e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0276e-04 - val_loss: 4.5462e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.5797e-04 - val_loss: 4.5634e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.5618e-04 - val_loss: 6.0417e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8382e-04 - val_loss: 7.2860e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.7498e-04 - val_loss: 4.7942e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.5523e-04 - val_loss: 4.3951e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7258e-04 - val_loss: 5.2612e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.5999e-04 - val_loss: 5.7693e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.5748e-04 - val_loss: 7.3445e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.6560e-04 - val_loss: 4.2803e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.8643e-04 - val_loss: 8.3719e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.8084e-04 - val_loss: 4.1010e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.3821e-04 - val_loss: 6.4162e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4051e-04 - val_loss: 4.9426e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7144e-04 - val_loss: 5.6997e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.3093e-04 - val_loss: 4.0426e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9452e-04 - val_loss: 4.4054e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.8247e-04 - val_loss: 6.7218e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.0943e-04 - val_loss: 4.1622e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8182e-04 - val_loss: 4.7796e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9020e-04 - val_loss: 4.3700e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7593e-04 - val_loss: 4.1056e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.8650e-04 - val_loss: 3.9784e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9963e-04 - val_loss: 4.1830e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9841e-04 - val_loss: 4.2844e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7574e-04 - val_loss: 3.8730e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.6048e-04 - val_loss: 4.0241e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9955e-04 - val_loss: 3.8120e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9157e-04 - val_loss: 4.5697e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.3375e-04 - val_loss: 4.4953e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.9306e-04 - val_loss: 3.8559e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9096e-04 - val_loss: 3.7677e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6732e-04 - val_loss: 3.8989e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.9165e-04 - val_loss: 3.7767e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7385e-04 - val_loss: 4.3294e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8931e-04 - val_loss: 3.8329e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6804e-04 - val_loss: 3.6415e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2924e-04 - val_loss: 3.9206e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5712e-04 - val_loss: 5.1353e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5957e-04 - val_loss: 4.0641e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.7413e-04 - val_loss: 3.6062e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2576e-04 - val_loss: 3.7174e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1849e-04 - val_loss: 3.6098e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0974e-04 - val_loss: 3.6989e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.5716e-04 - val_loss: 6.3712e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4773e-04 - val_loss: 5.0439e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.7806e-04 - val_loss: 5.4620e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.1286e-04 - val_loss: 4.7728e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1772e-04 - val_loss: 3.5507e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3795e-04 - val_loss: 4.4348e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0735e-04 - val_loss: 3.5629e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.4786e-04 - val_loss: 4.8800e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.5158e-04 - val_loss: 3.4984e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9182e-04 - val_loss: 4.5033e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6578e-04 - val_loss: 3.4134e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1561e-04 - val_loss: 4.1176e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3119e-04 - val_loss: 3.4297e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1611e-04 - val_loss: 3.7027e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2645e-04 - val_loss: 3.4443e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0336e-04 - val_loss: 3.6764e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0203e-04 - val_loss: 4.5922e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4349e-04 - val_loss: 3.3656e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9316e-04 - val_loss: 3.4685e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5554e-04 - val_loss: 4.4223e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1616e-04 - val_loss: 3.2569e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0505e-04 - val_loss: 3.5434e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5613e-04 - val_loss: 3.6644e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7726e-04 - val_loss: 3.6688e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7134e-04 - val_loss: 3.2331e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9645e-04 - val_loss: 3.2700e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3514e-04 - val_loss: 5.2679e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2810e-04 - val_loss: 5.7430e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2842e-04 - val_loss: 3.2195e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7720e-04 - val_loss: 3.3266e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7721e-04 - val_loss: 3.2809e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3990e-04 - val_loss: 4.3519e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1009e-04 - val_loss: 4.6734e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9164e-04 - val_loss: 3.2500e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6164e-04 - val_loss: 3.2180e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5264e-04 - val_loss: 3.2705e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6292e-04 - val_loss: 3.8078e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9752e-04 - val_loss: 3.4889e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8172e-04 - val_loss: 3.0861e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7788e-04 - val_loss: 3.0929e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8564e-04 - val_loss: 3.4057e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7105e-04 - val_loss: 3.1342e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3315e-04 - val_loss: 4.4417e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9208e-04 - val_loss: 3.9086e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5976e-04 - val_loss: 3.1043e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6686e-04 - val_loss: 4.9195e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9795e-04 - val_loss: 4.0904e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5320e-04 - val_loss: 3.4015e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7209e-04 - val_loss: 3.2286e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 11s 64ms/step - loss: 0.0199 - val_loss: 0.0036\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 7.6136e-04\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 7.5663e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 9.9336e-04 - val_loss: 7.1683e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.8179e-04 - val_loss: 5.9705e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 8.1590e-04 - val_loss: 5.4543e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 7.8030e-04 - val_loss: 6.2693e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 7.3026e-04 - val_loss: 7.3404e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 7.2341e-04 - val_loss: 4.8300e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 6.5114e-04 - val_loss: 5.1646e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 6.0273e-04 - val_loss: 8.3167e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 6.2396e-04 - val_loss: 6.8509e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.1787e-04 - val_loss: 4.2692e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.0569e-04 - val_loss: 3.8456e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.3043e-04 - val_loss: 4.3271e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.2443e-04 - val_loss: 4.9343e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.0267e-04 - val_loss: 3.8945e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.6731e-04 - val_loss: 4.4184e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4566e-04 - val_loss: 3.4483e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2680e-04 - val_loss: 3.3975e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.9844e-04 - val_loss: 3.8268e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2332e-04 - val_loss: 3.2751e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.6644e-04 - val_loss: 4.3586e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.4384e-04 - val_loss: 4.0046e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4679e-04 - val_loss: 8.5639e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1132e-04 - val_loss: 3.3812e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7618e-04 - val_loss: 3.4208e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4144e-04 - val_loss: 4.3569e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.1866e-04 - val_loss: 4.0350e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.3001e-04 - val_loss: 3.1334e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.6993e-04 - val_loss: 3.5191e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3635e-04 - val_loss: 3.8712e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0168e-04 - val_loss: 3.5473e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6572e-04 - val_loss: 4.1634e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.3555e-04 - val_loss: 3.0117e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.3858e-04 - val_loss: 5.3214e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.5970e-04 - val_loss: 3.0368e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7269e-04 - val_loss: 3.2257e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3803e-04 - val_loss: 3.1124e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4191e-04 - val_loss: 2.9805e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8028e-04 - val_loss: 3.0774e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.8324e-04 - val_loss: 2.8869e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7696e-04 - val_loss: 3.0157e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6246e-04 - val_loss: 2.8776e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6532e-04 - val_loss: 3.0313e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.5652e-04 - val_loss: 2.8730e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.1986e-04 - val_loss: 5.7152e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.2657e-04 - val_loss: 2.8735e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6517e-04 - val_loss: 3.2741e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.4297e-04 - val_loss: 5.0893e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0373e-04 - val_loss: 3.1718e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.8594e-04 - val_loss: 3.6898e-04\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4624e-04 - val_loss: 3.2316e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1777e-04 - val_loss: 3.4675e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9290e-04 - val_loss: 3.0066e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9449e-04 - val_loss: 3.6092e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 9s 93ms/step - loss: 0.0206 - val_loss: 0.0024\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0015 - val_loss: 9.2296e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0015 - val_loss: 8.6335e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0013 - val_loss: 8.0847e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0013 - val_loss: 8.0619e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0011 - val_loss: 7.1785e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0011 - val_loss: 7.1952e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 9.8130e-04 - val_loss: 6.5619e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 9.1230e-04 - val_loss: 6.1022e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 9.6998e-04 - val_loss: 7.9609e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0010 - val_loss: 6.1942e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.3080e-04 - val_loss: 5.3001e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 7.6189e-04 - val_loss: 0.0020\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.1915e-04 - val_loss: 7.0977e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.2803e-04 - val_loss: 9.4933e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 7.2934e-04 - val_loss: 5.1153e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.4906e-04 - val_loss: 4.6569e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.2206e-04 - val_loss: 4.4349e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.9830e-04 - val_loss: 6.1122e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.2738e-04 - val_loss: 6.1013e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.4894e-04 - val_loss: 9.0254e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.1104e-04 - val_loss: 8.9580e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.9364e-04 - val_loss: 5.5736e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.9814e-04 - val_loss: 5.3941e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.8825e-04 - val_loss: 5.3759e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.3704e-04 - val_loss: 3.7155e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.6710e-04 - val_loss: 5.0591e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.9485e-04 - val_loss: 6.5371e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.6462e-04 - val_loss: 3.5895e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.7898e-04 - val_loss: 4.1461e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.7455e-04 - val_loss: 4.1770e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.9768e-04 - val_loss: 6.1120e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.7722e-04 - val_loss: 3.4292e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.6715e-04 - val_loss: 4.1870e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.5461e-04 - val_loss: 3.1421e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5992e-04 - val_loss: 3.1719e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0203e-04 - val_loss: 3.2642e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.5407e-04 - val_loss: 3.7317e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.8335e-04 - val_loss: 4.7770e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 8.7467e-04 - val_loss: 4.4475e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.2686e-04 - val_loss: 3.5442e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.2598e-04 - val_loss: 0.0011\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.3660e-04 - val_loss: 3.0307e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.8072e-04 - val_loss: 5.8459e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.1417e-04 - val_loss: 4.2896e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.2843e-04 - val_loss: 4.3600e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.4578e-04 - val_loss: 9.9522e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.4825e-04 - val_loss: 3.3533e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.9961e-04 - val_loss: 3.1805e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8574e-04 - val_loss: 3.6635e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.7979e-04 - val_loss: 2.9761e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.0298e-04 - val_loss: 7.1673e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.1846e-04 - val_loss: 3.2282e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8087e-04 - val_loss: 2.9239e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.6683e-04 - val_loss: 2.9232e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.5443e-04 - val_loss: 3.2348e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.9704e-04 - val_loss: 2.9387e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.2919e-04 - val_loss: 3.4077e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.9016e-04 - val_loss: 6.0883e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8282e-04 - val_loss: 3.1191e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0737e-04 - val_loss: 3.2465e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.4719e-04 - val_loss: 4.1847e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.7392e-04 - val_loss: 2.9709e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.3728e-04 - val_loss: 4.0989e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.9164e-04 - val_loss: 4.9223e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>940.735804</td>\n",
       "      <td>0.981471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>907.672176</td>\n",
       "      <td>0.982751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>915.565456</td>\n",
       "      <td>0.982450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm        rmse        r2\n",
       "0      lstm  940.735804  0.981471\n",
       "1       gru  907.672176  0.982751\n",
       "2   lstmgru  915.565456  0.982450"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "result_li = []\n",
    "\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "comparison1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48d4b3",
   "metadata": {},
   "source": [
    "EarlyStopping patience 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae17729e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 5s 44ms/step - loss: 0.1123 - val_loss: 0.0192\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.9870e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 8.4193e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 9.2396e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 7.3506e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 9.0906e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 6.6951e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 6.4442e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 7.6620e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7932e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 6.9877e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.9708e-04 - val_loss: 6.5252e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.0842e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3854e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.7658e-04 - val_loss: 8.1636e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.2366e-04 - val_loss: 7.4270e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.2267e-04 - val_loss: 6.0931e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.0847e-04 - val_loss: 6.5523e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.5580e-04 - val_loss: 8.8102e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 9.0667e-04 - val_loss: 9.6387e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.9906e-04 - val_loss: 7.0530e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.4486e-04 - val_loss: 5.7356e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.5707e-04 - val_loss: 6.9683e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.8836e-04 - val_loss: 5.3451e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.6423e-04 - val_loss: 6.3896e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.5398e-04 - val_loss: 5.4726e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.2995e-04 - val_loss: 5.1281e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.9576e-04 - val_loss: 5.1023e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.5517e-04 - val_loss: 5.8298e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.8563e-04 - val_loss: 6.7333e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.0755e-04 - val_loss: 8.2231e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.5392e-04 - val_loss: 6.4916e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.6014e-04 - val_loss: 5.2273e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.6637e-04 - val_loss: 6.1309e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.4418e-04 - val_loss: 4.9029e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.1810e-04 - val_loss: 5.6675e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.1655e-04 - val_loss: 4.9587e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.9970e-04 - val_loss: 6.3616e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.9043e-04 - val_loss: 6.0139e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.9945e-04 - val_loss: 4.7669e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.1354e-04 - val_loss: 8.1416e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.7904e-04 - val_loss: 5.6584e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6162e-04 - val_loss: 4.7417e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6871e-04 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.6799e-04 - val_loss: 5.1488e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.9286e-04 - val_loss: 9.2359e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 7.1050e-04 - val_loss: 5.2891e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.5025e-04 - val_loss: 6.6564e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.3995e-04 - val_loss: 5.1099e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.0722e-04 - val_loss: 4.6701e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0849e-04 - val_loss: 5.6451e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1552e-04 - val_loss: 5.9227e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.5034e-04 - val_loss: 4.6525e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0961e-04 - val_loss: 4.9455e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.2248e-04 - val_loss: 5.4432e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 8.1316e-04 - val_loss: 4.6756e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.9924e-04 - val_loss: 7.4360e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.8243e-04 - val_loss: 4.4561e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.6242e-04 - val_loss: 4.6394e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.7052e-04 - val_loss: 4.4159e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.5329e-04 - val_loss: 4.5218e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.8515e-04 - val_loss: 9.2890e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0383e-04 - val_loss: 4.6286e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4945e-04 - val_loss: 4.9131e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.0608e-04 - val_loss: 4.5121e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.9717e-04 - val_loss: 5.6463e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.6188e-04 - val_loss: 4.2959e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.8983e-04 - val_loss: 4.5814e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.5051e-04 - val_loss: 4.8712e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.2721e-04 - val_loss: 4.3573e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.5457e-04 - val_loss: 4.6188e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.0732e-04 - val_loss: 4.6901e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.1503e-04 - val_loss: 4.1540e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9866e-04 - val_loss: 4.2072e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.1277e-04 - val_loss: 4.7789e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9946e-04 - val_loss: 4.1039e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1979e-04 - val_loss: 5.2675e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.1064e-04 - val_loss: 4.0941e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.0237e-04 - val_loss: 4.4132e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.8676e-04 - val_loss: 4.2464e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0984e-04 - val_loss: 7.5138e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.4022e-04 - val_loss: 5.6326e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.9446e-04 - val_loss: 4.3229e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7288e-04 - val_loss: 4.7425e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.8649e-04 - val_loss: 4.4304e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.0027e-04 - val_loss: 3.9335e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.3434e-04 - val_loss: 5.6556e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3143e-04 - val_loss: 4.4812e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7987e-04 - val_loss: 4.3262e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5687e-04 - val_loss: 3.8093e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7642e-04 - val_loss: 6.3660e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.3403e-04 - val_loss: 8.4909e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.6614e-04 - val_loss: 4.5333e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9802e-04 - val_loss: 4.1552e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7429e-04 - val_loss: 6.7546e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8663e-04 - val_loss: 5.8462e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3354e-04 - val_loss: 4.5606e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.5201e-04 - val_loss: 3.7575e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5907e-04 - val_loss: 4.9828e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2876e-04 - val_loss: 4.0159e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2883e-04 - val_loss: 3.6048e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3809e-04 - val_loss: 3.6334e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5292e-04 - val_loss: 3.5297e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5276e-04 - val_loss: 3.9964e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3848e-04 - val_loss: 3.7113e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9176e-04 - val_loss: 3.5567e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6694e-04 - val_loss: 4.1099e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.7001e-04 - val_loss: 3.4991e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1076e-04 - val_loss: 5.1086e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2273e-04 - val_loss: 5.6099e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2986e-04 - val_loss: 3.8147e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3696e-04 - val_loss: 3.5388e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1928e-04 - val_loss: 3.5244e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0227e-04 - val_loss: 3.5071e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0566e-04 - val_loss: 3.3896e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0006e-04 - val_loss: 3.3571e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4950e-04 - val_loss: 4.1115e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6682e-04 - val_loss: 3.3634e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7053e-04 - val_loss: 3.3556e-04\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 10ms/step - loss: 3.8661e-04 - val_loss: 3.2735e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9834e-04 - val_loss: 3.2570e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9838e-04 - val_loss: 3.2535e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0692e-04 - val_loss: 3.6366e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0131e-04 - val_loss: 3.3550e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8128e-04 - val_loss: 3.1860e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9012e-04 - val_loss: 3.2415e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.0032e-04 - val_loss: 3.1760e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7075e-04 - val_loss: 3.2059e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7519e-04 - val_loss: 4.8979e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6808e-04 - val_loss: 3.1744e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2917e-04 - val_loss: 3.9913e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6138e-04 - val_loss: 5.5396e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9947e-04 - val_loss: 3.1375e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.5046e-04 - val_loss: 5.3724e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0535e-04 - val_loss: 3.1774e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8334e-04 - val_loss: 4.0997e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7943e-04 - val_loss: 3.2252e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8062e-04 - val_loss: 3.2040e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8207e-04 - val_loss: 3.1748e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7257e-04 - val_loss: 4.3518e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5698e-04 - val_loss: 4.0430e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1706e-04 - val_loss: 3.2327e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7260e-04 - val_loss: 3.6019e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0014e-04 - val_loss: 3.1787e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8420e-04 - val_loss: 3.0644e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7383e-04 - val_loss: 3.1396e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7477e-04 - val_loss: 3.1916e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1002e-04 - val_loss: 3.0947e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.4716e-04 - val_loss: 3.7105e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6751e-04 - val_loss: 2.9978e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7794e-04 - val_loss: 4.6278e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5742e-04 - val_loss: 3.2407e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5531e-04 - val_loss: 3.6766e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2526e-04 - val_loss: 4.1224e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7014e-04 - val_loss: 3.5049e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7177e-04 - val_loss: 3.8002e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6587e-04 - val_loss: 3.1330e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7817e-04 - val_loss: 3.0492e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4879e-04 - val_loss: 3.0882e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5091e-04 - val_loss: 6.0477e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8541e-04 - val_loss: 3.4874e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6695e-04 - val_loss: 2.9597e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7303e-04 - val_loss: 5.5280e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.3596e-04 - val_loss: 6.1032e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5005e-04 - val_loss: 3.0168e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6455e-04 - val_loss: 3.2603e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6892e-04 - val_loss: 3.3167e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5114e-04 - val_loss: 4.2006e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5837e-04 - val_loss: 3.7135e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4638e-04 - val_loss: 3.1171e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4371e-04 - val_loss: 3.8865e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4633e-04 - val_loss: 2.9312e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4762e-04 - val_loss: 3.1908e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5154e-04 - val_loss: 3.6019e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5113e-04 - val_loss: 3.1022e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3497e-04 - val_loss: 2.9773e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6694e-04 - val_loss: 8.0614e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.1845e-04 - val_loss: 3.5520e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8525e-04 - val_loss: 3.0772e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4610e-04 - val_loss: 3.3580e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7373e-04 - val_loss: 3.1587e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4933e-04 - val_loss: 4.1522e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3713e-04 - val_loss: 3.0788e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5440e-04 - val_loss: 3.4040e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0734e-04 - val_loss: 3.2632e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4719e-04 - val_loss: 3.0771e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4599e-04 - val_loss: 3.4186e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5790e-04 - val_loss: 3.3811e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4759e-04 - val_loss: 3.2717e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6905e-04 - val_loss: 5.6395e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7926e-04 - val_loss: 3.8283e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4969e-04 - val_loss: 2.9091e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5416e-04 - val_loss: 3.7026e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7414e-04 - val_loss: 3.0689e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3904e-04 - val_loss: 2.9174e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5036e-04 - val_loss: 2.9718e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4040e-04 - val_loss: 3.2195e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4360e-04 - val_loss: 3.5917e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7836e-04 - val_loss: 4.3426e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.8233e-04 - val_loss: 2.9297e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5859e-04 - val_loss: 3.1327e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6096e-04 - val_loss: 3.2647e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4561e-04 - val_loss: 3.9201e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4959e-04 - val_loss: 3.2039e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3336e-04 - val_loss: 3.4102e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3783e-04 - val_loss: 3.5262e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4770e-04 - val_loss: 2.9014e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3970e-04 - val_loss: 3.3547e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3977e-04 - val_loss: 4.6073e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5224e-04 - val_loss: 4.4036e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.9412e-04 - val_loss: 4.7069e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7221e-04 - val_loss: 4.7977e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5489e-04 - val_loss: 3.1109e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5916e-04 - val_loss: 2.9885e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4638e-04 - val_loss: 3.5021e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5233e-04 - val_loss: 3.3068e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3534e-04 - val_loss: 3.0495e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.2993e-04 - val_loss: 3.0606e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5908e-04 - val_loss: 3.1246e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3422e-04 - val_loss: 3.5713e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4103e-04 - val_loss: 2.9373e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5170e-04 - val_loss: 3.2873e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4162e-04 - val_loss: 3.7092e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3843e-04 - val_loss: 3.7386e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3355e-04 - val_loss: 2.9179e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5475e-04 - val_loss: 3.0346e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5099e-04 - val_loss: 3.0368e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3287e-04 - val_loss: 3.3151e-04\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3877e-04 - val_loss: 3.9235e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5510e-04 - val_loss: 2.9206e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3829e-04 - val_loss: 3.0940e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6128e-04 - val_loss: 3.0942e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3052e-04 - val_loss: 2.9333e-04\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7836e-04 - val_loss: 3.1215e-04\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.6267e-04 - val_loss: 2.9685e-04\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5299e-04 - val_loss: 3.9468e-04\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5690e-04 - val_loss: 2.9254e-04\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3472e-04 - val_loss: 2.9410e-04\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3486e-04 - val_loss: 3.0136e-04\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4058e-04 - val_loss: 2.9720e-04\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.7472e-04 - val_loss: 2.9189e-04\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3215e-04 - val_loss: 3.1712e-04\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.3730e-04 - val_loss: 3.3104e-04\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.8496e-04 - val_loss: 2.9562e-04\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6877e-04 - val_loss: 3.2656e-04\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5759e-04 - val_loss: 3.9628e-04\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6545e-04 - val_loss: 3.4959e-04\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3744e-04 - val_loss: 2.9535e-04\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4431e-04 - val_loss: 3.2349e-04\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3209e-04 - val_loss: 3.0420e-04\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4626e-04 - val_loss: 3.0156e-04\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4071e-04 - val_loss: 4.4824e-04\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4693e-04 - val_loss: 3.3645e-04\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4543e-04 - val_loss: 3.4195e-04\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.2379e-04 - val_loss: 2.9307e-04\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.4029e-04 - val_loss: 3.3999e-04\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 3.5882e-04 - val_loss: 3.2040e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 9s 102ms/step - loss: 0.0222 - val_loss: 0.0013\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0018 - val_loss: 8.4379e-04\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 6.3238e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 9.5471e-04 - val_loss: 7.4262e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 8.2796e-04 - val_loss: 7.1742e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 8.1918e-04 - val_loss: 6.0542e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 7.1769e-04 - val_loss: 5.7964e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 7.4647e-04 - val_loss: 4.9805e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 7.4113e-04 - val_loss: 5.0219e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 6.2531e-04 - val_loss: 4.5469e-04\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 6.1211e-04 - val_loss: 4.0819e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.6570e-04 - val_loss: 4.7866e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.7640e-04 - val_loss: 6.5359e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 6.5978e-04 - val_loss: 4.1589e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 5.0803e-04 - val_loss: 3.8750e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.9989e-04 - val_loss: 3.5350e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.0817e-04 - val_loss: 5.4296e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.5539e-04 - val_loss: 3.4379e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.9432e-04 - val_loss: 3.4869e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.8646e-04 - val_loss: 3.5940e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.9742e-04 - val_loss: 4.3584e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.4890e-04 - val_loss: 4.0618e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.3235e-04 - val_loss: 4.3014e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.3780e-04 - val_loss: 3.4934e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.3237e-04 - val_loss: 5.7668e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.7034e-04 - val_loss: 3.1056e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.9863e-04 - val_loss: 7.7939e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.6033e-04 - val_loss: 3.1305e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.9747e-04 - val_loss: 3.0879e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.6300e-04 - val_loss: 3.2660e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9134e-04 - val_loss: 3.0439e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.8926e-04 - val_loss: 2.9688e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.0376e-04 - val_loss: 5.3205e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.6820e-04 - val_loss: 2.9356e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5456e-04 - val_loss: 2.9188e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.9244e-04 - val_loss: 4.1510e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.8027e-04 - val_loss: 3.3378e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.0045e-04 - val_loss: 2.8889e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9237e-04 - val_loss: 3.0596e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6086e-04 - val_loss: 3.3256e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5352e-04 - val_loss: 3.0166e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.4972e-04 - val_loss: 3.1728e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7151e-04 - val_loss: 4.2177e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.9684e-04 - val_loss: 6.8619e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.8907e-04 - val_loss: 3.2648e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.0589e-04 - val_loss: 6.1553e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.6894e-04 - val_loss: 2.9705e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.7771e-04 - val_loss: 2.9317e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5909e-04 - val_loss: 2.9192e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5582e-04 - val_loss: 3.1666e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 5.3862e-04 - val_loss: 3.3094e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.4794e-04 - val_loss: 3.9326e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.5921e-04 - val_loss: 3.0385e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.9301e-04 - val_loss: 3.0452e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.4511e-04 - val_loss: 4.0714e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 5.1946e-04 - val_loss: 4.5227e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.4854e-04 - val_loss: 3.1016e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.1583e-04 - val_loss: 2.9938e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.8146e-04 - val_loss: 3.7958e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.7700e-04 - val_loss: 3.0686e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.8265e-04 - val_loss: 4.2827e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.4612e-04 - val_loss: 4.2851e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.5136e-04 - val_loss: 2.8707e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.7559e-04 - val_loss: 8.0577e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.8063e-04 - val_loss: 3.4045e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0435e-04 - val_loss: 6.1894e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.3166e-04 - val_loss: 3.3951e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8064e-04 - val_loss: 3.0222e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.7041e-04 - val_loss: 2.8275e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.7658e-04 - val_loss: 4.7936e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8294e-04 - val_loss: 2.9693e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 4.2219e-04 - val_loss: 3.0645e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.5051e-04 - val_loss: 3.0910e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.7824e-04 - val_loss: 2.8376e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6205e-04 - val_loss: 4.8546e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7725e-04 - val_loss: 3.4177e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.5696e-04 - val_loss: 4.5657e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 5.0445e-04 - val_loss: 3.2037e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.4191e-04 - val_loss: 3.2290e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5385e-04 - val_loss: 3.0150e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.0650e-04 - val_loss: 4.3714e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.4497e-04 - val_loss: 4.2015e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.1772e-04 - val_loss: 5.2679e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.6215e-04 - val_loss: 3.2306e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 3.8418e-04 - val_loss: 2.8713e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.1281e-04 - val_loss: 3.8800e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4864e-04 - val_loss: 3.0212e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.0424e-04 - val_loss: 5.8907e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.5981e-04 - val_loss: 3.5223e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.5436e-04 - val_loss: 3.0658e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5258e-04 - val_loss: 3.2424e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5867e-04 - val_loss: 3.3140e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.7465e-04 - val_loss: 2.8849e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0543e-04 - val_loss: 2.9419e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.9462e-04 - val_loss: 2.8403e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 5.1465e-04 - val_loss: 0.0016\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 5.4432e-04 - val_loss: 5.3834e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.1241e-04 - val_loss: 3.6577e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.4684e-04 - val_loss: 3.0754e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6987e-04 - val_loss: 3.5450e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8078e-04 - val_loss: 2.9316e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4193e-04 - val_loss: 2.8923e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3930e-04 - val_loss: 2.9338e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.2652e-04 - val_loss: 4.8849e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8893e-04 - val_loss: 2.8710e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6852e-04 - val_loss: 2.8812e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.4873e-04 - val_loss: 3.1351e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.2462e-04 - val_loss: 4.0465e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.4836e-04 - val_loss: 3.4295e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.5255e-04 - val_loss: 3.0053e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7320e-04 - val_loss: 3.6197e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.8901e-04 - val_loss: 3.0745e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.3956e-04 - val_loss: 3.0045e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4659e-04 - val_loss: 3.1192e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.3507e-04 - val_loss: 3.3421e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.7313e-04 - val_loss: 3.2926e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.6589e-04 - val_loss: 3.0592e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 4.2095e-04 - val_loss: 3.2586e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.4744e-04 - val_loss: 3.5466e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 13s 140ms/step - loss: 0.0277 - val_loss: 0.0043\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0017 - val_loss: 9.4518e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0021 - val_loss: 9.3828e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 7.6792e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0011 - val_loss: 6.6296e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0010 - val_loss: 6.2815e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0010 - val_loss: 6.4617e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0010 - val_loss: 8.7990e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0011 - val_loss: 9.0976e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 9.1702e-04 - val_loss: 6.1508e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0011 - val_loss: 5.7154e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 7.9722e-04 - val_loss: 8.4972e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 9.5560e-04 - val_loss: 5.0684e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 7.9591e-04 - val_loss: 6.5229e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.8958e-04 - val_loss: 6.2325e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 8.3980e-04 - val_loss: 4.8573e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.6348e-04 - val_loss: 4.6799e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.6676e-04 - val_loss: 4.6171e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 6.1921e-04 - val_loss: 4.4069e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.9217e-04 - val_loss: 5.2207e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.6109e-04 - val_loss: 5.3348e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.4064e-04 - val_loss: 4.3127e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.4145e-04 - val_loss: 5.2725e-04\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 31ms/step - loss: 5.7182e-04 - val_loss: 4.2173e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.4795e-04 - val_loss: 0.0012\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.1755e-04 - val_loss: 3.9293e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5634e-04 - val_loss: 3.6451e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.7917e-04 - val_loss: 4.6607e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.4447e-04 - val_loss: 8.5307e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 7.7297e-04 - val_loss: 3.4371e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5728e-04 - val_loss: 3.7640e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.9720e-04 - val_loss: 4.0311e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.7446e-04 - val_loss: 6.4082e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.6579e-04 - val_loss: 5.0546e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8466e-04 - val_loss: 3.0943e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8209e-04 - val_loss: 3.2048e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8845e-04 - val_loss: 3.6645e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.2618e-04 - val_loss: 3.1943e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.1750e-04 - val_loss: 4.0473e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.3274e-04 - val_loss: 3.0604e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.3608e-04 - val_loss: 3.6081e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.1190e-04 - val_loss: 2.9930e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.9773e-04 - val_loss: 3.7471e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.9490e-04 - val_loss: 3.8774e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.0631e-04 - val_loss: 2.9996e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.2848e-04 - val_loss: 7.5787e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.7916e-04 - val_loss: 3.0304e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.3057e-04 - val_loss: 3.0799e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.9015e-04 - val_loss: 3.0103e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8806e-04 - val_loss: 4.9289e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.0232e-04 - val_loss: 4.9745e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.9430e-04 - val_loss: 5.1755e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.8823e-04 - val_loss: 2.9214e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0480e-04 - val_loss: 2.8935e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.9113e-04 - val_loss: 5.9729e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.0889e-04 - val_loss: 3.2842e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0216e-04 - val_loss: 2.9435e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0402e-04 - val_loss: 4.3427e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0434e-04 - val_loss: 2.9589e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.5291e-04 - val_loss: 2.9718e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.2393e-04 - val_loss: 3.1285e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.7345e-04 - val_loss: 4.0738e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.2967e-04 - val_loss: 4.3349e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.8672e-04 - val_loss: 3.7513e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.7261e-04 - val_loss: 6.3985e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.2643e-04 - val_loss: 3.3752e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.6982e-04 - val_loss: 3.1595e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.9061e-04 - val_loss: 4.2012e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.1829e-04 - val_loss: 3.4569e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.3067e-04 - val_loss: 3.7985e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.9691e-04 - val_loss: 2.8752e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8970e-04 - val_loss: 3.1844e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5398e-04 - val_loss: 2.9991e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.4062e-04 - val_loss: 4.3883e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.4912e-04 - val_loss: 3.3011e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5774e-04 - val_loss: 3.2879e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5853e-04 - val_loss: 3.0464e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4635e-04 - val_loss: 4.2276e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5873e-04 - val_loss: 3.3167e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.8490e-04 - val_loss: 8.9918e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 6.3206e-04 - val_loss: 7.2741e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.7207e-04 - val_loss: 5.2411e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.0549e-04 - val_loss: 3.3119e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.1714e-04 - val_loss: 4.3819e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6774e-04 - val_loss: 2.9690e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.1077e-04 - val_loss: 5.3260e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.0274e-04 - val_loss: 3.2878e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.9319e-04 - val_loss: 3.9463e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.8423e-04 - val_loss: 4.4958e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.8930e-04 - val_loss: 3.0739e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.6121e-04 - val_loss: 3.6579e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4438e-04 - val_loss: 6.3542e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.5343e-04 - val_loss: 2.9139e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.7376e-04 - val_loss: 6.7393e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.2376e-04 - val_loss: 2.9902e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.4112e-04 - val_loss: 4.0811e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.8126e-04 - val_loss: 4.4510e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.2584e-04 - val_loss: 4.2692e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7024e-04 - val_loss: 3.5565e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.3245e-04 - val_loss: 3.0618e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.7739e-04 - val_loss: 4.2413e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4656e-04 - val_loss: 2.9300e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5551e-04 - val_loss: 3.6860e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.7174e-04 - val_loss: 6.0040e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.1205e-04 - val_loss: 3.0308e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.3497e-04 - val_loss: 3.5442e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.0619e-04 - val_loss: 2.9644e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6375e-04 - val_loss: 2.9161e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.9297e-04 - val_loss: 4.3247e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.9221e-04 - val_loss: 5.8717e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9184e-04 - val_loss: 2.9474e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.1119e-04 - val_loss: 3.0339e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5244e-04 - val_loss: 3.1042e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.3542e-04 - val_loss: 2.8934e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.3734e-04 - val_loss: 3.2306e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.6654e-04 - val_loss: 4.5195e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 3.6621e-04 - val_loss: 3.4860e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 5.7757e-04 - val_loss: 9.3496e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.3793e-04 - val_loss: 3.3527e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.3264e-04 - val_loss: 2.9970e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.9175e-04 - val_loss: 3.0161e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>912.139573</td>\n",
       "      <td>0.982581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>900.453066</td>\n",
       "      <td>0.983024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>908.022369</td>\n",
       "      <td>0.982738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm        rmse        r2\n",
       "0      lstm  912.139573  0.982581\n",
       "1       gru  900.453066  0.983024\n",
       "2   lstmgru  908.022369  0.982738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "result_li = []\n",
    "\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop])\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, gru_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "comparison1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe22dae",
   "metadata": {},
   "source": [
    "# patience 30 채택!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b6253",
   "metadata": {},
   "source": [
    "# optimizer, batch_size, dropout 하이퍼파라미터 최적화\n",
    "\n",
    "optimizer : adam, adamax, nadam \n",
    "\n",
    "batch_size : 16, 32, 64. 128\n",
    "\n",
    "dropout : 0.1, 0.15, 0.2\n",
    "\n",
    "\n",
    "1. dropout 제외 최적화\n",
    "\n",
    "2. dropout 포함 최적화\n",
    "\n",
    "가장 성능 높은 모델 채택!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e77e011b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "52/52 [==============================] - 8s 54ms/step - loss: 0.0292 - val_loss: 0.0072\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 8.0730e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.0011 - val_loss: 7.1278e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 6.5856e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 6.3819e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 7.7800e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 9.0258e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 9.2644e-04 - val_loss: 7.7005e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 9.8071e-04 - val_loss: 0.0010\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 9.1521e-04 - val_loss: 8.2515e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 8.5674e-04 - val_loss: 8.7568e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 8.8274e-04 - val_loss: 6.8113e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 8.6136e-04 - val_loss: 8.8870e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 8.9578e-04 - val_loss: 5.6587e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 8.8081e-04 - val_loss: 5.7333e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 7.9528e-04 - val_loss: 5.2555e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 9.5926e-04 - val_loss: 0.0013\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 8.0235e-04 - val_loss: 7.7600e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 7.7811e-04 - val_loss: 5.8956e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 8.1491e-04 - val_loss: 4.8816e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 8.3065e-04 - val_loss: 5.6676e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 7.5419e-04 - val_loss: 5.8389e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 8.2204e-04 - val_loss: 8.8493e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 7.6314e-04 - val_loss: 5.3556e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 7.9689e-04 - val_loss: 5.5717e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 6.8317e-04 - val_loss: 6.4090e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 6.8083e-04 - val_loss: 5.4981e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 6.5847e-04 - val_loss: 7.1834e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 6.3046e-04 - val_loss: 4.5885e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 6.7354e-04 - val_loss: 4.5672e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 6.2878e-04 - val_loss: 5.8113e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 6.5950e-04 - val_loss: 5.9531e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 6.1612e-04 - val_loss: 5.9091e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 6.1157e-04 - val_loss: 4.4628e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 6.3092e-04 - val_loss: 4.9314e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 5.7148e-04 - val_loss: 4.3301e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.1993e-04 - val_loss: 8.6234e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 5.5715e-04 - val_loss: 4.5504e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 5.7054e-04 - val_loss: 4.5443e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 5.6687e-04 - val_loss: 5.1121e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 5.3289e-04 - val_loss: 4.2887e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 5.6304e-04 - val_loss: 4.7055e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 5.2639e-04 - val_loss: 4.0644e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 5.4214e-04 - val_loss: 4.2937e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 5.3962e-04 - val_loss: 4.1957e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 5.1878e-04 - val_loss: 4.1750e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 5.1362e-04 - val_loss: 4.1422e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 5.1247e-04 - val_loss: 4.0519e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 5.7406e-04 - val_loss: 8.4394e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.9788e-04 - val_loss: 3.9984e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 4.7611e-04 - val_loss: 4.2428e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 5.3273e-04 - val_loss: 3.7800e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.7285e-04 - val_loss: 4.0539e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.3839e-04 - val_loss: 4.4070e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 4.9066e-04 - val_loss: 3.7898e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 4.9412e-04 - val_loss: 3.7375e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 6.5993e-04 - val_loss: 5.6535e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 4.8643e-04 - val_loss: 4.3289e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.8663e-04 - val_loss: 5.3690e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.3590e-04 - val_loss: 3.5174e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.7218e-04 - val_loss: 4.8068e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 4.2965e-04 - val_loss: 4.5274e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.4627e-04 - val_loss: 4.2039e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.5133e-04 - val_loss: 4.3597e-04\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.2014e-04 - val_loss: 3.3482e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.5318e-04 - val_loss: 3.6918e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 4.7245e-04 - val_loss: 3.4442e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.6031e-04 - val_loss: 4.4864e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.2194e-04 - val_loss: 3.2846e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.9903e-04 - val_loss: 3.4035e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.1157e-04 - val_loss: 3.5917e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 4.3680e-04 - val_loss: 3.2281e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 4.2210e-04 - val_loss: 4.5566e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 4.6721e-04 - val_loss: 4.5217e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.9722e-04 - val_loss: 3.4024e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 4.7234e-04 - val_loss: 3.2945e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 4.7510e-04 - val_loss: 5.9841e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.9860e-04 - val_loss: 3.3754e-04\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9505e-04 - val_loss: 4.4203e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.9293e-04 - val_loss: 3.2587e-04\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.7279e-04 - val_loss: 3.9959e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.9322e-04 - val_loss: 3.2481e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7444e-04 - val_loss: 3.1565e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.9440e-04 - val_loss: 4.0780e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.6883e-04 - val_loss: 3.0670e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.7665e-04 - val_loss: 3.0437e-04\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.9840e-04 - val_loss: 3.0012e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.1274e-04 - val_loss: 3.9612e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.0210e-04 - val_loss: 3.0003e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.7904e-04 - val_loss: 4.3952e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.7555e-04 - val_loss: 3.0208e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.4740e-04 - val_loss: 3.0863e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.6230e-04 - val_loss: 5.5625e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.8936e-04 - val_loss: 3.3405e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.9675e-04 - val_loss: 2.9760e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.6094e-04 - val_loss: 3.4735e-04\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.7275e-04 - val_loss: 3.0473e-04\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.5569e-04 - val_loss: 5.3241e-04\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7442e-04 - val_loss: 2.9614e-04\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.5499e-04 - val_loss: 3.3679e-04\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.8391e-04 - val_loss: 3.9844e-04\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.8382e-04 - val_loss: 3.0782e-04\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.4443e-04 - val_loss: 2.9620e-04\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.7869e-04 - val_loss: 3.7771e-04\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.3432e-04 - val_loss: 3.1132e-04\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.6023e-04 - val_loss: 3.6090e-04\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5139e-04 - val_loss: 3.1850e-04\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4494e-04 - val_loss: 3.1254e-04\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4103e-04 - val_loss: 3.2967e-04\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 4.0542e-04 - val_loss: 4.8990e-04\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 4.1774e-04 - val_loss: 3.2073e-04\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7439e-04 - val_loss: 2.9778e-04\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4623e-04 - val_loss: 3.7108e-04\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.7668e-04 - val_loss: 2.9427e-04\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.3012e-04 - val_loss: 2.9801e-04\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6922e-04 - val_loss: 2.9275e-04\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5399e-04 - val_loss: 3.4500e-04\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4603e-04 - val_loss: 3.3360e-04\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5611e-04 - val_loss: 3.2105e-04\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 4.1169e-04 - val_loss: 3.0826e-04\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8971e-04 - val_loss: 4.9658e-04\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8777e-04 - val_loss: 3.1096e-04\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9796e-04 - val_loss: 2.9619e-04\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.5877e-04 - val_loss: 3.8177e-04\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.5439e-04 - val_loss: 5.1324e-04\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.7331e-04 - val_loss: 3.2677e-04\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.4526e-04 - val_loss: 2.9525e-04\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.5934e-04 - val_loss: 5.5665e-04\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 15ms/step - loss: 3.6767e-04 - val_loss: 2.9356e-04\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.2348e-04 - val_loss: 3.1283e-04\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.5248e-04 - val_loss: 3.2541e-04\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7659e-04 - val_loss: 3.5590e-04\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3006e-04 - val_loss: 3.4168e-04\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.8225e-04 - val_loss: 3.0731e-04\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 3.5850e-04 - val_loss: 4.1140e-04\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5359e-04 - val_loss: 3.0369e-04\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4639e-04 - val_loss: 3.1781e-04\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3366e-04 - val_loss: 2.9598e-04\n",
      "Epoch 161/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7168e-04 - val_loss: 6.1984e-04\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.5132e-04 - val_loss: 3.0216e-04\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 3.4850e-04 - val_loss: 3.4069e-04\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3717e-04 - val_loss: 3.5836e-04\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.6131e-04 - val_loss: 3.1289e-04\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.4675e-04 - val_loss: 3.2655e-04\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.6062e-04 - val_loss: 3.0192e-04\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.4171e-04 - val_loss: 3.0609e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 8s 42ms/step - loss: 0.0171 - val_loss: 9.3293e-04\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 7.1990e-04\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 9.8408e-04 - val_loss: 6.7640e-04\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 9.1046e-04 - val_loss: 7.1239e-04\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 8.2800e-04 - val_loss: 5.1258e-04\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 7.2209e-04 - val_loss: 5.2274e-04\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.5901e-04 - val_loss: 4.4213e-04\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 6.9457e-04 - val_loss: 4.2110e-04\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.9333e-04 - val_loss: 5.8094e-04\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 6.0718e-04 - val_loss: 4.9028e-04\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.4258e-04 - val_loss: 3.5538e-04\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.8551e-04 - val_loss: 3.4738e-04\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.7580e-04 - val_loss: 3.3390e-04\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.0324e-04 - val_loss: 3.6050e-04\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.4269e-04 - val_loss: 3.3107e-04\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.7663e-04 - val_loss: 3.2571e-04\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.9764e-04 - val_loss: 3.8108e-04\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.9221e-04 - val_loss: 3.1454e-04\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.5589e-04 - val_loss: 3.0196e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.9745e-04 - val_loss: 3.2662e-04\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.9745e-04 - val_loss: 3.3439e-04\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.9453e-04 - val_loss: 4.4124e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.7630e-04 - val_loss: 4.2806e-04\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.3517e-04 - val_loss: 5.2252e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.6394e-04 - val_loss: 2.8904e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.1420e-04 - val_loss: 4.4866e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.3083e-04 - val_loss: 3.3336e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.1853e-04 - val_loss: 4.2061e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.8857e-04 - val_loss: 4.5595e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.4291e-04 - val_loss: 3.9815e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5364e-04 - val_loss: 2.8986e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 3.9410e-04 - val_loss: 2.9051e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.0499e-04 - val_loss: 2.9728e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3301e-04 - val_loss: 4.0831e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.8217e-04 - val_loss: 4.0650e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 3.8120e-04 - val_loss: 4.4822e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 3.9356e-04 - val_loss: 2.8819e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.9068e-04 - val_loss: 3.9977e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 4.3730e-04 - val_loss: 3.1276e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3926e-04 - val_loss: 5.9876e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.7724e-04 - val_loss: 9.3439e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.3686e-04 - val_loss: 3.6928e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7399e-04 - val_loss: 3.2662e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.8287e-04 - val_loss: 3.1113e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.9207e-04 - val_loss: 3.8557e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7487e-04 - val_loss: 5.2391e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.3058e-04 - val_loss: 0.0011\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 7.1367e-04 - val_loss: 0.0012\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 6.1019e-04 - val_loss: 2.9717e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.4713e-04 - val_loss: 3.0163e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.7631e-04 - val_loss: 2.9822e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.8106e-04 - val_loss: 2.8654e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.1580e-04 - val_loss: 2.8748e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.4103e-04 - val_loss: 2.8613e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.6671e-04 - val_loss: 2.9557e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.6890e-04 - val_loss: 3.3275e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.6030e-04 - val_loss: 3.1677e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.2862e-04 - val_loss: 3.5909e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.6820e-04 - val_loss: 3.1066e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.8414e-04 - val_loss: 3.8017e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 5.8780e-04 - val_loss: 7.1672e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 5.6348e-04 - val_loss: 5.5083e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 3.7290e-04 - val_loss: 3.8182e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.9304e-04 - val_loss: 6.6565e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 4.3986e-04 - val_loss: 3.0274e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3385e-04 - val_loss: 4.3755e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.9912e-04 - val_loss: 3.0842e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.8551e-04 - val_loss: 8.6212e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.7438e-04 - val_loss: 6.0985e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.1577e-04 - val_loss: 3.0469e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 3.6936e-04 - val_loss: 7.4277e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.1182e-04 - val_loss: 3.0622e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.7665e-04 - val_loss: 2.9835e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 3.3103e-04 - val_loss: 2.8733e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 3.8107e-04 - val_loss: 3.1164e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 3.6328e-04 - val_loss: 2.8646e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 3.6554e-04 - val_loss: 2.9219e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 3.8195e-04 - val_loss: 2.8647e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 4.3812e-04 - val_loss: 3.2002e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 3.9007e-04 - val_loss: 2.8622e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 3.5478e-04 - val_loss: 5.0511e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 4.6449e-04 - val_loss: 0.0018\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 6.0282e-04 - val_loss: 3.0069e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 3.9326e-04 - val_loss: 3.5805e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 22s 137ms/step - loss: 0.0126 - val_loss: 0.0058\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 3s 66ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 3s 60ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 3s 59ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 3s 61ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 3s 62ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 3s 59ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 3s 58ms/step - loss: 0.0018 - val_loss: 9.6378e-04\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 3s 58ms/step - loss: 0.0018 - val_loss: 8.4654e-04\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 3s 64ms/step - loss: 0.0016 - val_loss: 8.3978e-04\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 3s 61ms/step - loss: 0.0018 - val_loss: 7.4076e-04\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 0.0013 - val_loss: 8.6938e-04\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 9.7109e-04 - val_loss: 0.0012\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 8.6937e-04 - val_loss: 5.1648e-04\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 8.1918e-04 - val_loss: 6.4300e-04\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 7.5320e-04 - val_loss: 6.4960e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 7.5532e-04 - val_loss: 9.4552e-04\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 6.1862e-04 - val_loss: 5.7684e-04\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 9.1816e-04 - val_loss: 5.0338e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 3s 56ms/step - loss: 6.9140e-04 - val_loss: 4.5427e-04\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 4s 68ms/step - loss: 6.9711e-04 - val_loss: 4.2007e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 5.8065e-04 - val_loss: 4.8200e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 3s 58ms/step - loss: 7.6243e-04 - val_loss: 9.8304e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 5.5200e-04 - val_loss: 3.4589e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 5.1716e-04 - val_loss: 3.5143e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 3s 49ms/step - loss: 4.5923e-04 - val_loss: 3.2854e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 6.6874e-04 - val_loss: 0.0018\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 7.2941e-04 - val_loss: 8.0737e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 4.8018e-04 - val_loss: 5.1025e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 4.3463e-04 - val_loss: 3.0827e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 5.1077e-04 - val_loss: 3.2562e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 4.4742e-04 - val_loss: 3.0353e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 4.0853e-04 - val_loss: 3.3183e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 5.4437e-04 - val_loss: 3.1144e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 4.9206e-04 - val_loss: 3.1053e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 4.3630e-04 - val_loss: 3.7150e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 4.5016e-04 - val_loss: 2.9812e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 4.1184e-04 - val_loss: 2.9470e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 3.7896e-04 - val_loss: 3.7474e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 4.3179e-04 - val_loss: 3.8283e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 4.5928e-04 - val_loss: 3.4417e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 4.1111e-04 - val_loss: 6.7036e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 4.2760e-04 - val_loss: 7.1164e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 3s 49ms/step - loss: 4.1013e-04 - val_loss: 3.5629e-04\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 67ms/step - loss: 4.2354e-04 - val_loss: 4.3843e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 5s 89ms/step - loss: 4.7813e-04 - val_loss: 6.5664e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 4s 72ms/step - loss: 5.9483e-04 - val_loss: 5.2205e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 4.0167e-04 - val_loss: 4.4420e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 3s 49ms/step - loss: 3.9488e-04 - val_loss: 4.2622e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 6.3603e-04 - val_loss: 0.0016\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 3s 59ms/step - loss: 6.1624e-04 - val_loss: 2.9653e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 3s 63ms/step - loss: 4.3250e-04 - val_loss: 2.9872e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 4.4638e-04 - val_loss: 2.9086e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 4.5813e-04 - val_loss: 4.1287e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 4.0844e-04 - val_loss: 6.8681e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 4.1478e-04 - val_loss: 2.9900e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 5.9805e-04 - val_loss: 0.0011\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 3s 49ms/step - loss: 4.5001e-04 - val_loss: 9.1520e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 4.2860e-04 - val_loss: 5.9867e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 3.9426e-04 - val_loss: 8.8593e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 4.6504e-04 - val_loss: 4.0876e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 3.8821e-04 - val_loss: 5.0446e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 5.4081e-04 - val_loss: 5.4848e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 5.5135e-04 - val_loss: 3.5054e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 5.6312e-04 - val_loss: 3.7187e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 3.9572e-04 - val_loss: 5.2755e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 3.7404e-04 - val_loss: 3.2979e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 4.1427e-04 - val_loss: 6.7816e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 4.5307e-04 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 3s 49ms/step - loss: 5.9980e-04 - val_loss: 9.8290e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 3.9821e-04 - val_loss: 5.2135e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 3s 66ms/step - loss: 3.6900e-04 - val_loss: 5.6894e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 3.8773e-04 - val_loss: 3.3166e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 4.1269e-04 - val_loss: 6.6296e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 3.8839e-04 - val_loss: 5.4693e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 3.5627e-04 - val_loss: 7.0044e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 3s 63ms/step - loss: 3.9679e-04 - val_loss: 3.0989e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 3s 63ms/step - loss: 4.2407e-04 - val_loss: 3.0425e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 3s 60ms/step - loss: 4.4809e-04 - val_loss: 3.6762e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 3s 57ms/step - loss: 4.3727e-04 - val_loss: 2.9490e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 3s 62ms/step - loss: 5.2627e-04 - val_loss: 4.8727e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 3s 61ms/step - loss: 3.7426e-04 - val_loss: 3.0069e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 3s 60ms/step - loss: 4.2171e-04 - val_loss: 4.1959e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 17s 123ms/step - loss: 0.0661 - val_loss: 0.0061\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0013 - val_loss: 8.5259e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0012 - val_loss: 9.2065e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 8.2934e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0012 - val_loss: 8.2301e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0012 - val_loss: 7.8436e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0012 - val_loss: 9.7600e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0011 - val_loss: 7.4956e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 8.1329e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 6.7915e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0011 - val_loss: 7.0422e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0010 - val_loss: 9.2565e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.9083e-04 - val_loss: 9.2959e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 9.8324e-04 - val_loss: 6.5283e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 9.9225e-04 - val_loss: 6.1712e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 9.4930e-04 - val_loss: 7.2482e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 9.2350e-04 - val_loss: 6.8558e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 9.3067e-04 - val_loss: 6.4116e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 9.3847e-04 - val_loss: 6.6294e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 8.8402e-04 - val_loss: 8.5508e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 9.4050e-04 - val_loss: 6.0024e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 8.7633e-04 - val_loss: 0.0011\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 8.7422e-04 - val_loss: 5.8500e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 8.5466e-04 - val_loss: 5.8492e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.2409e-04 - val_loss: 8.4520e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 8.2068e-04 - val_loss: 5.5855e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.4594e-04 - val_loss: 0.0010\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.8948e-04 - val_loss: 5.8471e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.3723e-04 - val_loss: 8.3383e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.7399e-04 - val_loss: 5.3780e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.1205e-04 - val_loss: 7.2909e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 7.4688e-04 - val_loss: 7.1524e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 7.2241e-04 - val_loss: 5.8455e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.3057e-04 - val_loss: 8.5362e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 6.9713e-04 - val_loss: 7.5940e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 6.9739e-04 - val_loss: 9.0514e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 6.8990e-04 - val_loss: 4.8968e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.6115e-04 - val_loss: 6.2291e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 7.8994e-04 - val_loss: 5.7949e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 7.6063e-04 - val_loss: 6.3900e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 6.7435e-04 - val_loss: 5.8617e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.4175e-04 - val_loss: 5.8770e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.6411e-04 - val_loss: 8.0495e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 6.5154e-04 - val_loss: 4.5814e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.0953e-04 - val_loss: 7.5488e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 6.1877e-04 - val_loss: 5.4955e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.6843e-04 - val_loss: 0.0011\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 6.0140e-04 - val_loss: 6.7691e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 6.0670e-04 - val_loss: 5.3050e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.1679e-04 - val_loss: 4.4682e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.7540e-04 - val_loss: 6.8458e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 6.2687e-04 - val_loss: 5.7027e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 6.4991e-04 - val_loss: 6.1569e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 5.4218e-04 - val_loss: 4.8993e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.2628e-04 - val_loss: 5.3927e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.1499e-04 - val_loss: 4.4068e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 5.4247e-04 - val_loss: 4.5263e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 5.6466e-04 - val_loss: 6.6548e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.0958e-04 - val_loss: 9.2818e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.4122e-04 - val_loss: 5.1322e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.1807e-04 - val_loss: 4.2073e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.4198e-04 - val_loss: 5.9893e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.1852e-04 - val_loss: 6.6256e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.8973e-04 - val_loss: 4.1965e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.9003e-04 - val_loss: 6.2567e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.8010e-04 - val_loss: 4.6486e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.6450e-04 - val_loss: 4.3481e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.9913e-04 - val_loss: 4.8794e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.6085e-04 - val_loss: 5.6548e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 4.5371e-04 - val_loss: 3.8333e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.5771e-04 - val_loss: 3.7790e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.6422e-04 - val_loss: 4.0366e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 5.5141e-04 - val_loss: 3.7713e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.1497e-04 - val_loss: 3.8022e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.5402e-04 - val_loss: 4.2506e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4794e-04 - val_loss: 4.4425e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 4.3097e-04 - val_loss: 4.6978e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.5086e-04 - val_loss: 3.8989e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.4611e-04 - val_loss: 3.9824e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.8632e-04 - val_loss: 4.7082e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 5.5049e-04 - val_loss: 6.2841e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5939e-04 - val_loss: 8.6392e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.9803e-04 - val_loss: 7.3151e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.5010e-04 - val_loss: 4.1518e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.3233e-04 - val_loss: 3.5866e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9027e-04 - val_loss: 4.9840e-04\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 23ms/step - loss: 5.0033e-04 - val_loss: 4.3358e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.0888e-04 - val_loss: 3.4440e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.1605e-04 - val_loss: 3.9289e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.2766e-04 - val_loss: 4.6257e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.9991e-04 - val_loss: 5.3382e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9879e-04 - val_loss: 3.5728e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8583e-04 - val_loss: 3.8167e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.8418e-04 - val_loss: 3.4220e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.9576e-04 - val_loss: 3.4062e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 4.0301e-04 - val_loss: 4.3852e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0823e-04 - val_loss: 3.2629e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0116e-04 - val_loss: 3.3438e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6753e-04 - val_loss: 4.6791e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.9205e-04 - val_loss: 3.3123e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.8941e-04 - val_loss: 3.2153e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6207e-04 - val_loss: 3.4143e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6475e-04 - val_loss: 4.4581e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7918e-04 - val_loss: 3.4320e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.7333e-04 - val_loss: 3.1747e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7621e-04 - val_loss: 3.4246e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 4.1661e-04 - val_loss: 3.2824e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.3636e-04 - val_loss: 4.1968e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7127e-04 - val_loss: 4.2108e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5902e-04 - val_loss: 3.8645e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6059e-04 - val_loss: 4.0725e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9226e-04 - val_loss: 3.0725e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6016e-04 - val_loss: 3.6150e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.4307e-04 - val_loss: 3.0621e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5275e-04 - val_loss: 5.3498e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.7164e-04 - val_loss: 4.1568e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6504e-04 - val_loss: 4.5897e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.6091e-04 - val_loss: 4.0221e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.5129e-04 - val_loss: 3.2609e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.4915e-04 - val_loss: 3.1308e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7088e-04 - val_loss: 4.8463e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0059e-04 - val_loss: 3.2682e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4052e-04 - val_loss: 3.3634e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4267e-04 - val_loss: 3.1197e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3978e-04 - val_loss: 4.7423e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9804e-04 - val_loss: 3.1495e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0412e-04 - val_loss: 2.9981e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4046e-04 - val_loss: 3.3095e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5992e-04 - val_loss: 3.5457e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.3613e-04 - val_loss: 3.1216e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.7044e-04 - val_loss: 8.1197e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.0153e-04 - val_loss: 3.0273e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5223e-04 - val_loss: 3.1528e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5696e-04 - val_loss: 2.9721e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4900e-04 - val_loss: 2.9805e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.2993e-04 - val_loss: 3.6824e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4886e-04 - val_loss: 3.2667e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.7020e-04 - val_loss: 3.4363e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.4223e-04 - val_loss: 3.0572e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.0108e-04 - val_loss: 3.1117e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3600e-04 - val_loss: 2.9808e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4630e-04 - val_loss: 3.9732e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.6900e-04 - val_loss: 3.3574e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.6835e-04 - val_loss: 3.1647e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6966e-04 - val_loss: 2.9762e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.6509e-04 - val_loss: 3.2140e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4696e-04 - val_loss: 3.3547e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8741e-04 - val_loss: 3.6366e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4640e-04 - val_loss: 3.3166e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.5954e-04 - val_loss: 4.9419e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.6434e-04 - val_loss: 3.1595e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.4755e-04 - val_loss: 4.2641e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.6090e-04 - val_loss: 3.0430e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6012e-04 - val_loss: 3.3847e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.3230e-04 - val_loss: 3.7714e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4413e-04 - val_loss: 3.3675e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4380e-04 - val_loss: 2.9319e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3609e-04 - val_loss: 3.8781e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.6551e-04 - val_loss: 4.9239e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 4.1228e-04 - val_loss: 3.0434e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.4327e-04 - val_loss: 3.3445e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.6887e-04 - val_loss: 2.9933e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.6014e-04 - val_loss: 4.0386e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.3327e-04 - val_loss: 2.9585e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3274e-04 - val_loss: 3.5713e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.3232e-04 - val_loss: 4.2796e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.8944e-04 - val_loss: 3.8836e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.2540e-04 - val_loss: 2.9322e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.6842e-04 - val_loss: 2.9386e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8114e-04 - val_loss: 2.9466e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.8469e-04 - val_loss: 2.9621e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.6632e-04 - val_loss: 4.2207e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7469e-04 - val_loss: 2.9201e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.3088e-04 - val_loss: 3.2611e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.4573e-04 - val_loss: 4.3513e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.6831e-04 - val_loss: 3.4570e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.4071e-04 - val_loss: 2.9587e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.3279e-04 - val_loss: 3.2923e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.6191e-04 - val_loss: 3.0036e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.5746e-04 - val_loss: 3.7198e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7255e-04 - val_loss: 3.6422e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5342e-04 - val_loss: 2.9805e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.2746e-04 - val_loss: 3.3044e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.3726e-04 - val_loss: 3.2110e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4837e-04 - val_loss: 4.0003e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5270e-04 - val_loss: 2.9566e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.2607e-04 - val_loss: 3.0109e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.5801e-04 - val_loss: 3.1471e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9997e-04 - val_loss: 3.6077e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.3356e-04 - val_loss: 3.1102e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.4713e-04 - val_loss: 2.9276e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5296e-04 - val_loss: 3.1169e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5139e-04 - val_loss: 2.9940e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3098e-04 - val_loss: 3.1401e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.3136e-04 - val_loss: 4.1307e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.5544e-04 - val_loss: 2.9988e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 3.7241e-04 - val_loss: 3.8187e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.3523e-04 - val_loss: 2.9144e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.2381e-04 - val_loss: 3.7165e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.3058e-04 - val_loss: 2.9433e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 3.3549e-04 - val_loss: 2.9675e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 3.6081e-04 - val_loss: 3.2334e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.7296e-04 - val_loss: 2.9947e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.4033e-04 - val_loss: 2.9165e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 3.3760e-04 - val_loss: 3.2107e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.3401e-04 - val_loss: 4.5570e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.4120e-04 - val_loss: 4.6239e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.4097e-04 - val_loss: 3.2753e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8770e-04 - val_loss: 3.6837e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.0577e-04 - val_loss: 2.9206e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.2686e-04 - val_loss: 2.9592e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.4894e-04 - val_loss: 3.5899e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.2367e-04 - val_loss: 2.9165e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.2756e-04 - val_loss: 2.9302e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.3274e-04 - val_loss: 3.2411e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5937e-04 - val_loss: 3.4415e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.3702e-04 - val_loss: 2.9151e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.2563e-04 - val_loss: 3.9385e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.4369e-04 - val_loss: 3.0916e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5582e-04 - val_loss: 4.9810e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.0442e-04 - val_loss: 4.9349e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.8084e-04 - val_loss: 4.4385e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9218e-04 - val_loss: 3.0422e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.3274e-04 - val_loss: 2.9106e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5160e-04 - val_loss: 3.4569e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3995e-04 - val_loss: 3.0563e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4769e-04 - val_loss: 2.9427e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3154e-04 - val_loss: 3.1546e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.3630e-04 - val_loss: 3.5288e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.5092e-04 - val_loss: 3.5473e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4370e-04 - val_loss: 2.9162e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 3.3584e-04 - val_loss: 4.5095e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.2765e-04 - val_loss: 2.9272e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.3278e-04 - val_loss: 2.9297e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.2527e-04 - val_loss: 2.9973e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.5613e-04 - val_loss: 3.2565e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 3.5748e-04 - val_loss: 3.4697e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.4260e-04 - val_loss: 3.2740e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.3372e-04 - val_loss: 3.5853e-04\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.2751e-04 - val_loss: 2.9584e-04\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4578e-04 - val_loss: 4.6360e-04\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3697e-04 - val_loss: 3.1870e-04\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7071e-04 - val_loss: 2.9701e-04\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.5325e-04 - val_loss: 3.0059e-04\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4050e-04 - val_loss: 3.2281e-04\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.2696e-04 - val_loss: 2.9498e-04\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4878e-04 - val_loss: 2.9684e-04\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4011e-04 - val_loss: 2.9720e-04\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.5822e-04 - val_loss: 3.4301e-04\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.3234e-04 - val_loss: 2.9350e-04\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.3541e-04 - val_loss: 3.3185e-04\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5610e-04 - val_loss: 3.1866e-04\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5795e-04 - val_loss: 3.2842e-04\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3845e-04 - val_loss: 3.6440e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 14s 151ms/step - loss: 0.0181 - val_loss: 0.0034\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0011 - val_loss: 8.5722e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 9.7232e-04 - val_loss: 6.5295e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 9.2787e-04 - val_loss: 6.5746e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 9.0773e-04 - val_loss: 5.7344e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 9.4739e-04 - val_loss: 5.4522e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 7.1820e-04 - val_loss: 5.0163e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 6.8583e-04 - val_loss: 4.8359e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 6.4528e-04 - val_loss: 6.3432e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 7.5159e-04 - val_loss: 4.8161e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 5.8260e-04 - val_loss: 6.3586e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.1388e-04 - val_loss: 4.3121e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 5.4818e-04 - val_loss: 4.4111e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 5.5786e-04 - val_loss: 3.8029e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 5.2524e-04 - val_loss: 3.8178e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 5.2504e-04 - val_loss: 3.7291e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 4.7839e-04 - val_loss: 3.7275e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 4.3331e-04 - val_loss: 4.5279e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.7362e-04 - val_loss: 3.6177e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 4.6246e-04 - val_loss: 3.3672e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 4.1368e-04 - val_loss: 3.9866e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.0969e-04 - val_loss: 3.5615e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 4.6009e-04 - val_loss: 3.3147e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.9712e-04 - val_loss: 3.8180e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.7745e-04 - val_loss: 3.6914e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.0336e-04 - val_loss: 3.5162e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.8372e-04 - val_loss: 3.0404e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.9450e-04 - val_loss: 3.3855e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.8967e-04 - val_loss: 3.2961e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.3141e-04 - val_loss: 5.0520e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.6998e-04 - val_loss: 3.1720e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.6986e-04 - val_loss: 3.0070e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.7082e-04 - val_loss: 3.4000e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.8412e-04 - val_loss: 4.1541e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.8374e-04 - val_loss: 3.3372e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.2724e-04 - val_loss: 3.1099e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.7577e-04 - val_loss: 2.9586e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.1892e-04 - val_loss: 3.1508e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.1018e-04 - val_loss: 2.9203e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.5681e-04 - val_loss: 2.9669e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.7495e-04 - val_loss: 3.5191e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.6212e-04 - val_loss: 4.2628e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.3026e-04 - val_loss: 3.0556e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.9070e-04 - val_loss: 3.3422e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.9371e-04 - val_loss: 2.9843e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.6011e-04 - val_loss: 3.0470e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.2113e-04 - val_loss: 3.5510e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.1470e-04 - val_loss: 2.8567e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.1163e-04 - val_loss: 3.2581e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 4.1216e-04 - val_loss: 2.8978e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.1786e-04 - val_loss: 2.8910e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.0069e-04 - val_loss: 3.0716e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 4.9839e-04 - val_loss: 2.9882e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.7759e-04 - val_loss: 3.5551e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 3.7930e-04 - val_loss: 3.1769e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 4.2119e-04 - val_loss: 4.4978e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.7716e-04 - val_loss: 3.0524e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 3.7366e-04 - val_loss: 3.8047e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.9376e-04 - val_loss: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7674e-04 - val_loss: 3.0269e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.1959e-04 - val_loss: 3.3001e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4386e-04 - val_loss: 2.9419e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.0847e-04 - val_loss: 3.1039e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.8917e-04 - val_loss: 3.0865e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4623e-04 - val_loss: 8.2608e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.3536e-04 - val_loss: 3.6521e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.8574e-04 - val_loss: 3.5682e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4403e-04 - val_loss: 3.4992e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.6766e-04 - val_loss: 4.0666e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.3861e-04 - val_loss: 3.5985e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7560e-04 - val_loss: 4.1810e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7220e-04 - val_loss: 3.8626e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.8617e-04 - val_loss: 3.0041e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4300e-04 - val_loss: 3.4613e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.2033e-04 - val_loss: 2.9322e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.0718e-04 - val_loss: 3.2815e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.2587e-04 - val_loss: 3.4026e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.8852e-04 - val_loss: 4.3733e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 11s 132ms/step - loss: 0.0296 - val_loss: 0.0030\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0014 - val_loss: 7.6612e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0012 - val_loss: 7.4601e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0011 - val_loss: 8.1395e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0012 - val_loss: 6.7448e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0011 - val_loss: 6.7199e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 9.9459e-04 - val_loss: 9.5631e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 9.4468e-04 - val_loss: 5.8959e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 9.8003e-04 - val_loss: 5.7466e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0011 - val_loss: 6.3687e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0010 - val_loss: 5.9966e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 8.6958e-04 - val_loss: 5.1684e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 7.6596e-04 - val_loss: 6.7753e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 7.6244e-04 - val_loss: 6.4672e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 7.3221e-04 - val_loss: 7.3353e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 6.6965e-04 - val_loss: 5.5860e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 7.1479e-04 - val_loss: 0.0012\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 7.8028e-04 - val_loss: 0.0011\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 6.7555e-04 - val_loss: 0.0010\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 7.5863e-04 - val_loss: 6.7176e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.8064e-04 - val_loss: 4.2712e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.9514e-04 - val_loss: 4.1036e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.1460e-04 - val_loss: 4.0110e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.6848e-04 - val_loss: 6.6340e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.7218e-04 - val_loss: 8.8928e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.7289e-04 - val_loss: 4.0982e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.1746e-04 - val_loss: 3.9098e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.2146e-04 - val_loss: 3.6686e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 6.2444e-04 - val_loss: 4.1620e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.6062e-04 - val_loss: 5.3641e-04\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 31ms/step - loss: 4.4475e-04 - val_loss: 4.9871e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.5591e-04 - val_loss: 3.6033e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.5714e-04 - val_loss: 8.4480e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.4222e-04 - val_loss: 3.7927e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.9748e-04 - val_loss: 3.5104e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.2267e-04 - val_loss: 3.5257e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0956e-04 - val_loss: 3.9227e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.4224e-04 - val_loss: 6.6043e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 6.3312e-04 - val_loss: 3.4090e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.4809e-04 - val_loss: 3.3635e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 6.0617e-04 - val_loss: 4.2666e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 7.1848e-04 - val_loss: 4.4743e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.1853e-04 - val_loss: 3.1669e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.8111e-04 - val_loss: 3.1833e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.6274e-04 - val_loss: 0.0012\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 6.0504e-04 - val_loss: 5.3514e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.3725e-04 - val_loss: 3.4571e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.7026e-04 - val_loss: 3.5998e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.9867e-04 - val_loss: 3.6935e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.2976e-04 - val_loss: 3.3073e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9106e-04 - val_loss: 3.6292e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.7879e-04 - val_loss: 3.1482e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6393e-04 - val_loss: 3.6770e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5198e-04 - val_loss: 7.4444e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.2686e-04 - val_loss: 0.0010\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.0939e-04 - val_loss: 4.2705e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.2153e-04 - val_loss: 3.5587e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0915e-04 - val_loss: 2.9138e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8435e-04 - val_loss: 2.9085e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1919e-04 - val_loss: 6.0230e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.7591e-04 - val_loss: 2.9699e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.8054e-04 - val_loss: 2.9013e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0246e-04 - val_loss: 4.3783e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.7217e-04 - val_loss: 4.4437e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.7318e-04 - val_loss: 2.9225e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.6790e-04 - val_loss: 3.0701e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 6.9411e-04 - val_loss: 5.0116e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.7403e-04 - val_loss: 2.9106e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0306e-04 - val_loss: 2.9341e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.5559e-04 - val_loss: 3.7560e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.2096e-04 - val_loss: 2.9356e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6270e-04 - val_loss: 3.0798e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9267e-04 - val_loss: 4.2836e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.3799e-04 - val_loss: 4.1813e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.2830e-04 - val_loss: 3.0270e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1566e-04 - val_loss: 3.0943e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0562e-04 - val_loss: 2.9115e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.9147e-04 - val_loss: 4.1384e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.7310e-04 - val_loss: 2.9843e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6568e-04 - val_loss: 3.3761e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.4898e-04 - val_loss: 3.0393e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.8516e-04 - val_loss: 2.9562e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.8855e-04 - val_loss: 2.9429e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5888e-04 - val_loss: 8.4173e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.1382e-04 - val_loss: 3.8151e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.5165e-04 - val_loss: 3.3857e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1372e-04 - val_loss: 3.3018e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6497e-04 - val_loss: 2.9565e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.5853e-04 - val_loss: 4.0452e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.5980e-04 - val_loss: 6.9150e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.1832e-04 - val_loss: 3.0373e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.6169e-04 - val_loss: 4.1165e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 3s 60ms/step - loss: 0.1006 - val_loss: 0.0134\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0393 - val_loss: 0.0051\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 5s 97ms/step - loss: 0.0609 - val_loss: 0.0307\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 9.6578e-04\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 7.4453e-04\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.0011 - val_loss: 7.1789e-04\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 9.7007e-04 - val_loss: 6.8879e-04\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 9.6034e-04 - val_loss: 7.0572e-04\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 9.3414e-04 - val_loss: 8.0986e-04\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 9.2267e-04 - val_loss: 6.3060e-04\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 8.6837e-04 - val_loss: 6.1274e-04\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 8.2435e-04 - val_loss: 5.7307e-04\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 8.2191e-04 - val_loss: 5.5547e-04\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 7.6961e-04 - val_loss: 5.6826e-04\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 7.4848e-04 - val_loss: 5.9792e-04\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 7.1765e-04 - val_loss: 5.1538e-04\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 7.0470e-04 - val_loss: 5.0758e-04\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 6.8960e-04 - val_loss: 6.0130e-04\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 6.5948e-04 - val_loss: 5.0110e-04\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 6.4939e-04 - val_loss: 4.8658e-04\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 6.4144e-04 - val_loss: 4.5701e-04\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 6.0934e-04 - val_loss: 5.2333e-04\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.8812e-04 - val_loss: 4.4301e-04\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.7789e-04 - val_loss: 4.6526e-04\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.6653e-04 - val_loss: 5.1024e-04\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.8640e-04 - val_loss: 4.3099e-04\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 6.0223e-04 - val_loss: 4.2079e-04\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.4444e-04 - val_loss: 4.4687e-04\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.2729e-04 - val_loss: 3.9140e-04\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.0907e-04 - val_loss: 5.9653e-04\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.4787e-04 - val_loss: 4.4858e-04\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.0543e-04 - val_loss: 4.4394e-04\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.8007e-04 - val_loss: 3.7210e-04\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.8924e-04 - val_loss: 3.6609e-04\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.5912e-04 - val_loss: 4.3137e-04\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.6160e-04 - val_loss: 4.2522e-04\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.5697e-04 - val_loss: 4.0323e-04\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.6025e-04 - val_loss: 4.9824e-04\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.5592e-04 - val_loss: 3.7741e-04\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.4978e-04 - val_loss: 6.3570e-04\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 5.1616e-04 - val_loss: 4.4158e-04\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.7632e-04 - val_loss: 3.7408e-04\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.2554e-04 - val_loss: 3.3577e-04\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.1925e-04 - val_loss: 3.3014e-04\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.2569e-04 - val_loss: 5.5738e-04\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.3709e-04 - val_loss: 4.0483e-04\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.2902e-04 - val_loss: 3.7212e-04\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.1097e-04 - val_loss: 3.2465e-04\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.8563e-04 - val_loss: 3.4054e-04\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.7905e-04 - val_loss: 3.2943e-04\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.8854e-04 - val_loss: 4.0934e-04\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.0897e-04 - val_loss: 4.6759e-04\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.2398e-04 - val_loss: 3.6562e-04\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.2581e-04 - val_loss: 3.6169e-04\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.0140e-04 - val_loss: 3.4805e-04\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.3437e-04 - val_loss: 3.2736e-04\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 42ms/step - loss: 3.9237e-04 - val_loss: 3.2512e-04\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.1209e-04 - val_loss: 3.0926e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.0274e-04 - val_loss: 3.3815e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.7383e-04 - val_loss: 3.0407e-04\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.9442e-04 - val_loss: 3.4989e-04\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.0703e-04 - val_loss: 3.1767e-04\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.7906e-04 - val_loss: 3.0527e-04\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.6657e-04 - val_loss: 3.0492e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.6295e-04 - val_loss: 3.0279e-04\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5327e-04 - val_loss: 3.6145e-04\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.9968e-04 - val_loss: 3.7679e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 4.1627e-04 - val_loss: 3.2343e-04\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.7794e-04 - val_loss: 3.0090e-04\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.5847e-04 - val_loss: 3.0679e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5432e-04 - val_loss: 3.9310e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.4790e-04 - val_loss: 2.9448e-04\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.9837e-04 - val_loss: 3.8573e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.8280e-04 - val_loss: 3.0669e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.8017e-04 - val_loss: 3.1904e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.5497e-04 - val_loss: 2.9649e-04\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.4120e-04 - val_loss: 3.0348e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.5072e-04 - val_loss: 2.9271e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.8645e-04 - val_loss: 3.2768e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 4.1724e-04 - val_loss: 3.0405e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 4.3774e-04 - val_loss: 3.1104e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.6241e-04 - val_loss: 3.0496e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 4.8040e-04 - val_loss: 4.7975e-04\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 4.0817e-04 - val_loss: 4.4532e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.9928e-04 - val_loss: 4.5656e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.7475e-04 - val_loss: 2.9181e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.5166e-04 - val_loss: 2.9646e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.3334e-04 - val_loss: 2.9069e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.3053e-04 - val_loss: 2.9040e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.4341e-04 - val_loss: 2.9157e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.4003e-04 - val_loss: 3.0045e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.5388e-04 - val_loss: 3.0742e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.3157e-04 - val_loss: 3.2619e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.2460e-04 - val_loss: 3.3187e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.3682e-04 - val_loss: 2.9559e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.3439e-04 - val_loss: 3.0276e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.4343e-04 - val_loss: 3.4472e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.5214e-04 - val_loss: 2.9149e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.4010e-04 - val_loss: 2.9094e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.5356e-04 - val_loss: 2.9880e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.9060e-04 - val_loss: 3.6062e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.4929e-04 - val_loss: 3.0393e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.6047e-04 - val_loss: 3.6973e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 4.0998e-04 - val_loss: 3.6539e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.7376e-04 - val_loss: 2.8849e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 4.2721e-04 - val_loss: 3.7271e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 4.2561e-04 - val_loss: 2.9152e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.5212e-04 - val_loss: 3.3880e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.5473e-04 - val_loss: 2.8747e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.6155e-04 - val_loss: 4.8176e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.5836e-04 - val_loss: 3.7120e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.3464e-04 - val_loss: 2.9117e-04\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 4.0208e-04 - val_loss: 5.1064e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 4.6533e-04 - val_loss: 4.9725e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.6691e-04 - val_loss: 3.5937e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.7553e-04 - val_loss: 3.0559e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.5197e-04 - val_loss: 2.8639e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.3218e-04 - val_loss: 3.9998e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.7332e-04 - val_loss: 2.8698e-04\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.4146e-04 - val_loss: 3.0162e-04\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.5052e-04 - val_loss: 3.5154e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.5145e-04 - val_loss: 2.8884e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.3211e-04 - val_loss: 2.8701e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.5843e-04 - val_loss: 4.3506e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.7699e-04 - val_loss: 4.0973e-04\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.9121e-04 - val_loss: 3.7524e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 4.3980e-04 - val_loss: 2.9315e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.5172e-04 - val_loss: 2.9000e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 3.4769e-04 - val_loss: 2.8798e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.6447e-04 - val_loss: 3.0827e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.6967e-04 - val_loss: 3.1432e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.2945e-04 - val_loss: 2.8692e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.3202e-04 - val_loss: 2.9476e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.3245e-04 - val_loss: 2.9496e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.2573e-04 - val_loss: 3.0203e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.3082e-04 - val_loss: 2.8885e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.6277e-04 - val_loss: 3.9471e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.3600e-04 - val_loss: 2.9178e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.3038e-04 - val_loss: 3.0870e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.3492e-04 - val_loss: 3.0332e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 3.3882e-04 - val_loss: 2.8987e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.2766e-04 - val_loss: 3.0734e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.3061e-04 - val_loss: 3.0928e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 3.7374e-04 - val_loss: 3.1409e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 4.2760e-04 - val_loss: 8.0497e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 5.0246e-04 - val_loss: 3.3070e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 3.4794e-04 - val_loss: 4.0632e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 7s 129ms/step - loss: 0.0486 - val_loss: 0.0023\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0016 - val_loss: 9.5324e-04\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0016 - val_loss: 9.5655e-04\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0014 - val_loss: 9.1346e-04\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0013 - val_loss: 9.3690e-04\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0012 - val_loss: 9.4846e-04\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0013 - val_loss: 8.5472e-04\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0015 - val_loss: 8.5489e-04\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0011 - val_loss: 7.0836e-04\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0010 - val_loss: 8.4250e-04\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0012 - val_loss: 6.5839e-04\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 9.6626e-04 - val_loss: 7.1437e-04\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 9.0879e-04 - val_loss: 6.7208e-04\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.8075e-04 - val_loss: 5.9708e-04\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.4462e-04 - val_loss: 7.4752e-04\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.6529e-04 - val_loss: 8.7232e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.3490e-04 - val_loss: 5.4126e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.7681e-04 - val_loss: 5.4444e-04\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 7.6121e-04 - val_loss: 7.4473e-04\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 57ms/step - loss: 7.5682e-04 - val_loss: 5.2223e-04\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.1720e-04 - val_loss: 9.0484e-04\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0010 - val_loss: 5.2236e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.7986e-04 - val_loss: 5.3850e-04\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 7.6133e-04 - val_loss: 5.1521e-04\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 7.8638e-04 - val_loss: 8.8907e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 7.7785e-04 - val_loss: 5.0426e-04\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.1264e-04 - val_loss: 5.3453e-04\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 6.7605e-04 - val_loss: 4.8233e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 6.4333e-04 - val_loss: 7.3827e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 6.2662e-04 - val_loss: 9.6935e-04\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 6.6395e-04 - val_loss: 6.4910e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 6.3710e-04 - val_loss: 5.9845e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 6.0350e-04 - val_loss: 6.3097e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.8552e-04 - val_loss: 5.9813e-04\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 6.4137e-04 - val_loss: 4.4353e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.9103e-04 - val_loss: 4.2944e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 6.3834e-04 - val_loss: 4.3425e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 5.9517e-04 - val_loss: 4.5696e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 5.2528e-04 - val_loss: 4.5362e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.9306e-04 - val_loss: 4.0369e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 5.2405e-04 - val_loss: 3.9362e-04\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.9460e-04 - val_loss: 4.0570e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 6.7015e-04 - val_loss: 4.1845e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 5.2351e-04 - val_loss: 5.6328e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.9330e-04 - val_loss: 3.8140e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.5413e-04 - val_loss: 4.0659e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.4029e-04 - val_loss: 3.9790e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.8960e-04 - val_loss: 3.9123e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.9983e-04 - val_loss: 3.5899e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.6165e-04 - val_loss: 3.9696e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.5160e-04 - val_loss: 3.9533e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.4246e-04 - val_loss: 5.1315e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.5798e-04 - val_loss: 3.5210e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.2327e-04 - val_loss: 4.1940e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.6878e-04 - val_loss: 3.4583e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.3357e-04 - val_loss: 4.1884e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.7660e-04 - val_loss: 8.4217e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 7.3083e-04 - val_loss: 3.4155e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 5.1971e-04 - val_loss: 3.3368e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.0172e-04 - val_loss: 3.3600e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 4.0856e-04 - val_loss: 5.3413e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 4.9680e-04 - val_loss: 3.6935e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.3142e-04 - val_loss: 4.1364e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.0759e-04 - val_loss: 3.2195e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.8771e-04 - val_loss: 3.2341e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.9397e-04 - val_loss: 4.5074e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.8012e-04 - val_loss: 3.7385e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 4.3852e-04 - val_loss: 3.1128e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.8972e-04 - val_loss: 4.5865e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.2757e-04 - val_loss: 3.8037e-04\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.9202e-04 - val_loss: 3.9133e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.7244e-04 - val_loss: 3.2210e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.0278e-04 - val_loss: 3.9575e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 5.0479e-04 - val_loss: 4.0966e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.9747e-04 - val_loss: 3.2780e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.2616e-04 - val_loss: 8.6788e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 4.7637e-04 - val_loss: 5.1649e-04\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.4096e-04 - val_loss: 5.1507e-04\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.4193e-04 - val_loss: 3.6648e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.0314e-04 - val_loss: 3.3660e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.6102e-04 - val_loss: 3.0204e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.0800e-04 - val_loss: 5.2524e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6132e-04 - val_loss: 3.1406e-04\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.6175e-04 - val_loss: 2.9582e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 4.1762e-04 - val_loss: 6.1292e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 5.6600e-04 - val_loss: 4.8579e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.2358e-04 - val_loss: 5.7471e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.2632e-04 - val_loss: 4.4583e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.9908e-04 - val_loss: 5.2598e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 3.9831e-04 - val_loss: 3.4020e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.1994e-04 - val_loss: 3.0898e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.4447e-04 - val_loss: 3.9715e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.8133e-04 - val_loss: 3.0249e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.4693e-04 - val_loss: 2.9838e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.4725e-04 - val_loss: 4.0099e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.6957e-04 - val_loss: 3.0623e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.0815e-04 - val_loss: 4.3121e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.8230e-04 - val_loss: 2.9075e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.6492e-04 - val_loss: 5.1843e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.8066e-04 - val_loss: 3.2635e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.5807e-04 - val_loss: 3.0326e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.8793e-04 - val_loss: 4.2514e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.4930e-04 - val_loss: 3.0709e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.5315e-04 - val_loss: 3.5941e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.5006e-04 - val_loss: 2.9439e-04\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.3315e-04 - val_loss: 5.9911e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 3.5981e-04 - val_loss: 2.9118e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.3988e-04 - val_loss: 2.9298e-04\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.6557e-04 - val_loss: 3.7347e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6014e-04 - val_loss: 3.0997e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6745e-04 - val_loss: 4.3000e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.8648e-04 - val_loss: 4.2887e-04\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.6178e-04 - val_loss: 3.4011e-04\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.5589e-04 - val_loss: 3.1531e-04\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 4.3219e-04 - val_loss: 2.9074e-04\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.4640e-04 - val_loss: 2.9807e-04\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.8539e-04 - val_loss: 4.0801e-04\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.6151e-04 - val_loss: 3.3940e-04\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.2777e-04 - val_loss: 3.5270e-04\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.1419e-04 - val_loss: 3.1180e-04\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.3413e-04 - val_loss: 4.2410e-04\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.6614e-04 - val_loss: 3.1154e-04\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.6230e-04 - val_loss: 4.9244e-04\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.4592e-04 - val_loss: 3.9708e-04\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.3280e-04 - val_loss: 3.0530e-04\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.7075e-04 - val_loss: 0.0011\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.1878e-04 - val_loss: 3.1143e-04\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.4777e-04 - val_loss: 3.7076e-04\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.6041e-04 - val_loss: 2.9330e-04\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 3.3150e-04 - val_loss: 2.8825e-04\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.0144e-04 - val_loss: 6.1570e-04\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.7225e-04 - val_loss: 7.9975e-04\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.3302e-04 - val_loss: 2.9308e-04\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.5632e-04 - val_loss: 2.9069e-04\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.3468e-04 - val_loss: 3.0780e-04\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.5801e-04 - val_loss: 3.4942e-04\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.5923e-04 - val_loss: 3.5398e-04\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.3861e-04 - val_loss: 4.6236e-04\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.4946e-04 - val_loss: 4.2671e-04\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 3.9033e-04 - val_loss: 2.9916e-04\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 3.5111e-04 - val_loss: 3.0445e-04\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 3.3130e-04 - val_loss: 2.9129e-04\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.3966e-04 - val_loss: 2.9178e-04\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.0623e-04 - val_loss: 3.8115e-04\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.0981e-04 - val_loss: 2.9325e-04\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.6265e-04 - val_loss: 5.9166e-04\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.9373e-04 - val_loss: 3.0930e-04\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.2548e-04 - val_loss: 2.9901e-04\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.9935e-04 - val_loss: 3.2196e-04\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.6923e-04 - val_loss: 8.0467e-04\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.8377e-04 - val_loss: 3.4087e-04\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 3.6935e-04 - val_loss: 2.9358e-04\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 4.1148e-04 - val_loss: 3.2927e-04\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 3.9772e-04 - val_loss: 3.1360e-04\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.3444e-04 - val_loss: 2.9612e-04\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 4.0809e-04 - val_loss: 3.0436e-04\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 3.4914e-04 - val_loss: 4.1661e-04\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 3.7121e-04 - val_loss: 3.4560e-04\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.0574e-04 - val_loss: 4.0712e-04\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.8291e-04 - val_loss: 3.2824e-04\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 3s 162ms/step - loss: 0.1680 - val_loss: 0.1348\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0900 - val_loss: 0.0429\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0552 - val_loss: 0.0110\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0453 - val_loss: 0.0074\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0296 - val_loss: 0.0094\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0188 - val_loss: 0.0064\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0017\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 5s 242ms/step - loss: 0.0857 - val_loss: 0.0050\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.0135 - val_loss: 0.0191\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0044 - val_loss: 0.0102\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0014 - val_loss: 9.3978e-04\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0012 - val_loss: 8.3877e-04\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.0011 - val_loss: 7.1850e-04\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.0011 - val_loss: 7.3477e-04\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.0010 - val_loss: 7.2895e-04\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.0010 - val_loss: 6.7529e-04\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 9.6311e-04 - val_loss: 6.6856e-04\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 9.4278e-04 - val_loss: 7.2015e-04\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 9.2099e-04 - val_loss: 6.3843e-04\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 9.3341e-04 - val_loss: 6.7765e-04\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.8458e-04 - val_loss: 6.1398e-04\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.7027e-04 - val_loss: 6.2002e-04\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 8.5237e-04 - val_loss: 6.5407e-04\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.7368e-04 - val_loss: 5.7895e-04\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.2023e-04 - val_loss: 5.9030e-04\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 8.0962e-04 - val_loss: 5.5765e-04\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.8853e-04 - val_loss: 5.6801e-04\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 7.7371e-04 - val_loss: 5.4900e-04\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 7.5816e-04 - val_loss: 5.8580e-04\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 7.4934e-04 - val_loss: 5.2732e-04\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 7.4503e-04 - val_loss: 5.4930e-04\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 7.4282e-04 - val_loss: 6.8949e-04\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 7.2322e-04 - val_loss: 5.2106e-04\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.1643e-04 - val_loss: 5.0168e-04\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 6.8977e-04 - val_loss: 5.1868e-04\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 6.9191e-04 - val_loss: 5.0415e-04\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 6.7502e-04 - val_loss: 5.7738e-04\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 6.7896e-04 - val_loss: 4.9126e-04\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 6.5589e-04 - val_loss: 4.7125e-04\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.3439e-04 - val_loss: 4.6528e-04\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 6.3374e-04 - val_loss: 4.7838e-04\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.1562e-04 - val_loss: 4.7332e-04\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 6.0639e-04 - val_loss: 4.5040e-04\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 5.9993e-04 - val_loss: 4.3498e-04\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 5.9682e-04 - val_loss: 4.3087e-04\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.8368e-04 - val_loss: 4.4257e-04\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.7107e-04 - val_loss: 4.6463e-04\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 5.7425e-04 - val_loss: 5.6850e-04\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.9000e-04 - val_loss: 4.5935e-04\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.6703e-04 - val_loss: 4.1473e-04\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.4104e-04 - val_loss: 4.1493e-04\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.3669e-04 - val_loss: 4.0163e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.2857e-04 - val_loss: 4.8034e-04\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.4274e-04 - val_loss: 5.2306e-04\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 5.5359e-04 - val_loss: 5.4673e-04\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 5.8560e-04 - val_loss: 5.7382e-04\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 5.9095e-04 - val_loss: 4.4871e-04\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 5.7087e-04 - val_loss: 4.0870e-04\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.2318e-04 - val_loss: 3.8410e-04\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3825e-04 - val_loss: 3.9399e-04\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1748e-04 - val_loss: 3.8081e-04\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.1234e-04 - val_loss: 4.8272e-04\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3395e-04 - val_loss: 4.2884e-04\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.2050e-04 - val_loss: 4.3674e-04\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9451e-04 - val_loss: 3.8213e-04\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 4.6892e-04 - val_loss: 4.2285e-04\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.6881e-04 - val_loss: 4.1363e-04\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6018e-04 - val_loss: 4.0980e-04\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.5908e-04 - val_loss: 3.5801e-04\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5095e-04 - val_loss: 3.6228e-04\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5832e-04 - val_loss: 3.5305e-04\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.5355e-04 - val_loss: 3.8297e-04\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.7314e-04 - val_loss: 3.6809e-04\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5418e-04 - val_loss: 3.5319e-04\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.3706e-04 - val_loss: 4.6327e-04\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.4831e-04 - val_loss: 3.5933e-04\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.3403e-04 - val_loss: 3.4357e-04\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.2308e-04 - val_loss: 3.4710e-04\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.2616e-04 - val_loss: 3.4714e-04\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.1979e-04 - val_loss: 3.4474e-04\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.2388e-04 - val_loss: 3.5407e-04\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 4.2761e-04 - val_loss: 3.4044e-04\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.4476e-04 - val_loss: 4.3386e-04\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.6023e-04 - val_loss: 4.0095e-04\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.6858e-04 - val_loss: 3.9824e-04\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.5723e-04 - val_loss: 3.4195e-04\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 4.2696e-04 - val_loss: 3.3417e-04\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.0383e-04 - val_loss: 3.2923e-04\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 4.0899e-04 - val_loss: 3.6411e-04\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 4.2238e-04 - val_loss: 4.1592e-04\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.3230e-04 - val_loss: 3.3450e-04\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 4.3155e-04 - val_loss: 3.3071e-04\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.1456e-04 - val_loss: 3.2445e-04\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.1398e-04 - val_loss: 3.3734e-04\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 4.0176e-04 - val_loss: 3.2415e-04\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.9799e-04 - val_loss: 3.2273e-04\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.9029e-04 - val_loss: 3.3416e-04\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.9085e-04 - val_loss: 3.2284e-04\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.9695e-04 - val_loss: 3.2315e-04\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.5110e-04 - val_loss: 5.2703e-04\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.4369e-04 - val_loss: 3.3248e-04\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.9883e-04 - val_loss: 3.6141e-04\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.1695e-04 - val_loss: 3.4351e-04\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.2489e-04 - val_loss: 4.4577e-04\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.2617e-04 - val_loss: 4.2866e-04\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.9972e-04 - val_loss: 3.1412e-04\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.8187e-04 - val_loss: 3.7749e-04\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.9160e-04 - val_loss: 3.1620e-04\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.7886e-04 - val_loss: 3.5282e-04\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1372e-04 - val_loss: 3.2199e-04\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.8038e-04 - val_loss: 3.1392e-04\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.7383e-04 - val_loss: 3.8646e-04\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.8319e-04 - val_loss: 3.1920e-04\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.6777e-04 - val_loss: 3.3562e-04\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.7837e-04 - val_loss: 3.8471e-04\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.9836e-04 - val_loss: 3.7231e-04\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 4.2072e-04 - val_loss: 3.6311e-04\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.8956e-04 - val_loss: 3.4350e-04\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.0664e-04 - val_loss: 3.0657e-04\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.8018e-04 - val_loss: 3.1120e-04\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.7949e-04 - val_loss: 3.2388e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.9812e-04 - val_loss: 3.7331e-04\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.1283e-04 - val_loss: 3.5112e-04\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.6062e-04 - val_loss: 3.0762e-04\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.6978e-04 - val_loss: 3.7293e-04\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.8872e-04 - val_loss: 3.0984e-04\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.6663e-04 - val_loss: 3.3818e-04\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.7010e-04 - val_loss: 3.0135e-04\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.5214e-04 - val_loss: 2.9979e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5757e-04 - val_loss: 3.4652e-04\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.6688e-04 - val_loss: 3.0280e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.8151e-04 - val_loss: 3.3363e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.8074e-04 - val_loss: 3.1994e-04\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4798e-04 - val_loss: 3.0253e-04\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4696e-04 - val_loss: 2.9775e-04\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5781e-04 - val_loss: 3.3083e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.6740e-04 - val_loss: 2.9665e-04\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5580e-04 - val_loss: 3.0166e-04\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.5896e-04 - val_loss: 2.9724e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.4396e-04 - val_loss: 3.0373e-04\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5273e-04 - val_loss: 3.6661e-04\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.6881e-04 - val_loss: 2.9611e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5499e-04 - val_loss: 3.0110e-04\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.5776e-04 - val_loss: 2.9531e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.8087e-04 - val_loss: 4.7455e-04\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.0161e-04 - val_loss: 3.7473e-04\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.8457e-04 - val_loss: 2.9343e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.5199e-04 - val_loss: 2.9752e-04\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4256e-04 - val_loss: 2.9274e-04\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.4811e-04 - val_loss: 3.1525e-04\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.5054e-04 - val_loss: 2.9988e-04\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6979e-04 - val_loss: 3.7097e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.7463e-04 - val_loss: 3.6182e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.6114e-04 - val_loss: 3.2315e-04\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.9863e-04 - val_loss: 3.1403e-04\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.6278e-04 - val_loss: 2.9609e-04\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4246e-04 - val_loss: 3.2744e-04\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.5527e-04 - val_loss: 2.9964e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.4304e-04 - val_loss: 3.0085e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4115e-04 - val_loss: 3.6474e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.8343e-04 - val_loss: 4.2982e-04\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 4.9795e-04 - val_loss: 3.6293e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 5.1010e-04 - val_loss: 7.3104e-04\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 5.8304e-04 - val_loss: 3.2836e-04\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.5146e-04 - val_loss: 4.7737e-04\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.0614e-04 - val_loss: 2.9119e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.3967e-04 - val_loss: 3.8888e-04\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.6873e-04 - val_loss: 2.9573e-04\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.7859e-04 - val_loss: 3.2738e-04\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.4482e-04 - val_loss: 2.9623e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.3884e-04 - val_loss: 3.0082e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.3823e-04 - val_loss: 2.9564e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5453e-04 - val_loss: 3.1054e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4125e-04 - val_loss: 2.9095e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4248e-04 - val_loss: 2.9168e-04\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.3791e-04 - val_loss: 2.9105e-04\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.3881e-04 - val_loss: 2.9753e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5113e-04 - val_loss: 3.6057e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5346e-04 - val_loss: 2.9082e-04\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.8846e-04 - val_loss: 3.1513e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.3899e-04 - val_loss: 3.0802e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.3408e-04 - val_loss: 2.9375e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.3916e-04 - val_loss: 3.1949e-04\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.5266e-04 - val_loss: 3.3816e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.4645e-04 - val_loss: 2.9665e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5369e-04 - val_loss: 3.2959e-04\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.3892e-04 - val_loss: 2.8949e-04\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.4076e-04 - val_loss: 3.0698e-04\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5278e-04 - val_loss: 3.1191e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.4240e-04 - val_loss: 2.9951e-04\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3712e-04 - val_loss: 3.0708e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5555e-04 - val_loss: 3.4377e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.6627e-04 - val_loss: 2.9836e-04\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.7433e-04 - val_loss: 3.5500e-04\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.7572e-04 - val_loss: 3.3984e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.3859e-04 - val_loss: 2.8886e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3711e-04 - val_loss: 3.5335e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.6663e-04 - val_loss: 3.1569e-04\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.5740e-04 - val_loss: 4.0219e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1910e-04 - val_loss: 3.4202e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.5402e-04 - val_loss: 2.8721e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.3479e-04 - val_loss: 3.2533e-04\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4540e-04 - val_loss: 3.1261e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.3992e-04 - val_loss: 2.8806e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.3142e-04 - val_loss: 3.4102e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.5617e-04 - val_loss: 3.0558e-04\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.4729e-04 - val_loss: 3.8962e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.5360e-04 - val_loss: 2.8900e-04\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.4769e-04 - val_loss: 3.6575e-04\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.8151e-04 - val_loss: 3.3177e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.6318e-04 - val_loss: 3.3568e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.4957e-04 - val_loss: 3.0983e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.5581e-04 - val_loss: 2.8552e-04\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.3720e-04 - val_loss: 3.1150e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.4282e-04 - val_loss: 3.0516e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 3.3452e-04 - val_loss: 3.4678e-04\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.4209e-04 - val_loss: 3.1644e-04\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.4455e-04 - val_loss: 3.0716e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.4320e-04 - val_loss: 3.0782e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.5054e-04 - val_loss: 2.8588e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.3662e-04 - val_loss: 2.8679e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.4794e-04 - val_loss: 3.1284e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.4673e-04 - val_loss: 3.2753e-04\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.5103e-04 - val_loss: 3.8286e-04\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.4250e-04 - val_loss: 2.9863e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3884e-04 - val_loss: 3.2341e-04\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 3.5009e-04 - val_loss: 3.0221e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 3.3286e-04 - val_loss: 3.1228e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.3268e-04 - val_loss: 3.0707e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 3.3592e-04 - val_loss: 2.8724e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 3.2394e-04 - val_loss: 3.0253e-04\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.4291e-04 - val_loss: 3.6345e-04\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.4861e-04 - val_loss: 3.4540e-04\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 3.4814e-04 - val_loss: 3.0332e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.4469e-04 - val_loss: 3.4322e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 3.4188e-04 - val_loss: 2.8781e-04\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.8271e-04 - val_loss: 3.3747e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.5692e-04 - val_loss: 2.8720e-04\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.3002e-04 - val_loss: 2.8830e-04\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 3.3157e-04 - val_loss: 2.9950e-04\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.5194e-04 - val_loss: 3.0787e-04\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.5231e-04 - val_loss: 2.9550e-04\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 3.3271e-04 - val_loss: 2.8986e-04\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 7s 303ms/step - loss: 0.0679 - val_loss: 0.0031\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0015 - val_loss: 9.3950e-04\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0015 - val_loss: 9.5699e-04\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0013 - val_loss: 8.5580e-04\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0014 - val_loss: 8.8669e-04\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0013 - val_loss: 8.6547e-04\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0013 - val_loss: 8.8936e-04\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0012 - val_loss: 7.7044e-04\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0013 - val_loss: 8.5955e-04\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0013 - val_loss: 7.3203e-04\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0013 - val_loss: 7.2780e-04\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0011 - val_loss: 7.0959e-04\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0012 - val_loss: 7.6355e-04\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0011 - val_loss: 6.7399e-04\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 9.9060e-04 - val_loss: 6.5368e-04\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0011 - val_loss: 7.9583e-04\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0011 - val_loss: 6.9827e-04\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0010 - val_loss: 9.8097e-04\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0010 - val_loss: 6.2380e-04\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 9.8210e-04 - val_loss: 6.0213e-04\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 9.8629e-04 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 9.2043e-04 - val_loss: 5.8195e-04\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 8.2154e-04 - val_loss: 5.6548e-04\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 8.1978e-04 - val_loss: 8.3311e-04\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 8.4463e-04 - val_loss: 6.4933e-04\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 8.6645e-04 - val_loss: 8.2025e-04\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 7.9949e-04 - val_loss: 5.4135e-04\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 8.4883e-04 - val_loss: 8.4801e-04\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 7.5951e-04 - val_loss: 5.6449e-04\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 7.5861e-04 - val_loss: 8.8263e-04\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 7.7897e-04 - val_loss: 5.2596e-04\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 7.2162e-04 - val_loss: 5.2126e-04\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 6.9506e-04 - val_loss: 7.2024e-04\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 6.9663e-04 - val_loss: 5.1657e-04\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 6.6839e-04 - val_loss: 6.3449e-04\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 6.6203e-04 - val_loss: 5.6627e-04\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 7.0644e-04 - val_loss: 0.0013\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 8.6849e-04 - val_loss: 0.0012\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 8.3248e-04 - val_loss: 6.9942e-04\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 6.4258e-04 - val_loss: 7.6798e-04\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 6.5458e-04 - val_loss: 4.8747e-04\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 7.3137e-04 - val_loss: 6.5515e-04\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 7.0033e-04 - val_loss: 7.0790e-04\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 6.9938e-04 - val_loss: 4.7969e-04\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 6.2438e-04 - val_loss: 7.9958e-04\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 7.1028e-04 - val_loss: 5.5614e-04\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 6.4251e-04 - val_loss: 4.7171e-04\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 6.3041e-04 - val_loss: 8.2735e-04\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 6.7792e-04 - val_loss: 7.3796e-04\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 6.5841e-04 - val_loss: 7.9161e-04\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.0119e-04 - val_loss: 5.3681e-04\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 6.5332e-04 - val_loss: 4.9105e-04\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.4434e-04 - val_loss: 4.4125e-04\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.8168e-04 - val_loss: 7.0718e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.8941e-04 - val_loss: 4.8849e-04\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.9821e-04 - val_loss: 5.3740e-04\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 6.4283e-04 - val_loss: 0.0010\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.0119e-04 - val_loss: 4.9017e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 5.5549e-04 - val_loss: 6.0284e-04\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.4516e-04 - val_loss: 4.2956e-04\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.1608e-04 - val_loss: 5.0189e-04\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.0081e-04 - val_loss: 4.1941e-04\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.8958e-04 - val_loss: 4.5781e-04\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 5.6460e-04 - val_loss: 4.3228e-04\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.2175e-04 - val_loss: 5.4249e-04\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.6812e-04 - val_loss: 5.0701e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.8869e-04 - val_loss: 4.6000e-04\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.2680e-04 - val_loss: 4.6937e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.9292e-04 - val_loss: 8.2210e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.7948e-04 - val_loss: 4.0823e-04\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.3456e-04 - val_loss: 4.1473e-04\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 4.9592e-04 - val_loss: 4.6674e-04\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.6402e-04 - val_loss: 4.3449e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 5.2536e-04 - val_loss: 3.8676e-04\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.7141e-04 - val_loss: 4.2478e-04\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.9448e-04 - val_loss: 5.1318e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 5.1562e-04 - val_loss: 3.8576e-04\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.6050e-04 - val_loss: 5.1623e-04\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 4.9000e-04 - val_loss: 4.1470e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 4.3746e-04 - val_loss: 3.7797e-04\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.2762e-04 - val_loss: 4.1093e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.3192e-04 - val_loss: 4.1187e-04\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.4503e-04 - val_loss: 3.6843e-04\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.4165e-04 - val_loss: 4.4146e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.4789e-04 - val_loss: 4.0883e-04\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.4039e-04 - val_loss: 5.3441e-04\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 5.3129e-04 - val_loss: 3.7721e-04\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 6.7872e-04 - val_loss: 8.2646e-04\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 6.2080e-04 - val_loss: 6.2930e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 5.7126e-04 - val_loss: 3.6680e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.6427e-04 - val_loss: 3.6264e-04\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 5.3635e-04 - val_loss: 3.9632e-04\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 5.6971e-04 - val_loss: 3.5269e-04\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.1405e-04 - val_loss: 5.5410e-04\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.0871e-04 - val_loss: 4.0428e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 5.4987e-04 - val_loss: 5.2390e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.6967e-04 - val_loss: 3.4818e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.2422e-04 - val_loss: 3.5942e-04\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.0914e-04 - val_loss: 4.4988e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.3626e-04 - val_loss: 3.6119e-04\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.2111e-04 - val_loss: 6.3643e-04\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.7503e-04 - val_loss: 3.6327e-04\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.2878e-04 - val_loss: 5.1106e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.7532e-04 - val_loss: 5.4035e-04\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.7325e-04 - val_loss: 4.4016e-04\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.2487e-04 - val_loss: 4.0542e-04\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 4.9059e-04 - val_loss: 4.9758e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.7614e-04 - val_loss: 3.4851e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 3.8621e-04 - val_loss: 3.6478e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.2149e-04 - val_loss: 3.4093e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 3.9871e-04 - val_loss: 3.4029e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 3.8960e-04 - val_loss: 6.8764e-04\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.8062e-04 - val_loss: 6.2254e-04\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.4744e-04 - val_loss: 4.4375e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.1001e-04 - val_loss: 3.3658e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.1264e-04 - val_loss: 4.3389e-04\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.3584e-04 - val_loss: 3.3479e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.3250e-04 - val_loss: 3.2591e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 3.7581e-04 - val_loss: 3.5834e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 3.7415e-04 - val_loss: 3.2899e-04\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 3.6654e-04 - val_loss: 4.3974e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 4.0934e-04 - val_loss: 4.5355e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.1714e-04 - val_loss: 3.1860e-04\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 3.7991e-04 - val_loss: 3.1719e-04\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.7540e-04 - val_loss: 3.4422e-04\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.7769e-04 - val_loss: 3.8720e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 3.8665e-04 - val_loss: 6.8755e-04\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 4.8938e-04 - val_loss: 5.7581e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 3.8395e-04 - val_loss: 3.2898e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 3.7197e-04 - val_loss: 3.1595e-04\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 3.5611e-04 - val_loss: 3.1287e-04\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 3.7133e-04 - val_loss: 3.7660e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 3.6682e-04 - val_loss: 3.5301e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 3.7454e-04 - val_loss: 4.0334e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.0974e-04 - val_loss: 3.0941e-04\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 3.9327e-04 - val_loss: 3.8161e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 4.5901e-04 - val_loss: 8.4721e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 5.1827e-04 - val_loss: 3.0980e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.6369e-04 - val_loss: 3.2447e-04\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 3.9817e-04 - val_loss: 4.6891e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.4367e-04 - val_loss: 3.8533e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 3.9532e-04 - val_loss: 4.4980e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.3280e-04 - val_loss: 3.0479e-04\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.7999e-04 - val_loss: 3.0979e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 3.9385e-04 - val_loss: 3.5100e-04\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.8515e-04 - val_loss: 3.3252e-04\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.4346e-04 - val_loss: 3.2179e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.2371e-04 - val_loss: 2.9930e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 3.7214e-04 - val_loss: 3.9922e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.1031e-04 - val_loss: 3.3515e-04\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.5668e-04 - val_loss: 3.1921e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 3.4575e-04 - val_loss: 3.1205e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.6994e-04 - val_loss: 3.0459e-04\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.4716e-04 - val_loss: 3.6955e-04\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 3.8056e-04 - val_loss: 3.5917e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 3.6076e-04 - val_loss: 3.3442e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 3.5530e-04 - val_loss: 3.0521e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 3.6159e-04 - val_loss: 3.0668e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 3.6102e-04 - val_loss: 3.9705e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 3.5804e-04 - val_loss: 3.4647e-04\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 3.7739e-04 - val_loss: 5.4236e-04\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 5.5483e-04 - val_loss: 3.0723e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 3.8871e-04 - val_loss: 3.1895e-04\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 3.7338e-04 - val_loss: 3.5318e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.4485e-04 - val_loss: 3.1548e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 3.4990e-04 - val_loss: 3.6456e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 4.6265e-04 - val_loss: 5.0168e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 4.3422e-04 - val_loss: 3.5089e-04\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.8263e-04 - val_loss: 4.7265e-04\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 4.6908e-04 - val_loss: 6.2021e-04\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 4.0153e-04 - val_loss: 4.7443e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.8732e-04 - val_loss: 3.7289e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 3.5865e-04 - val_loss: 3.2432e-04\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 3.6429e-04 - val_loss: 3.1552e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 3.6492e-04 - val_loss: 3.1300e-04\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.5451e-04 - val_loss: 3.3647e-04\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.5602e-04 - val_loss: 3.5165e-04\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 3.6407e-04 - val_loss: 3.5474e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 3s 19ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 9.7891e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 9.2435e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 8.9167e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 7.8482e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 7.7754e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 8.6247e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 7.8629e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 8.2822e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 8.2775e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 8.0326e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 7.8564e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 7.0647e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 7.4315e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 6.8744e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 7.1427e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 6.7570e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.6278e-04 - val_loss: 6.5001e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.2881e-04 - val_loss: 6.2406e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.1033e-04 - val_loss: 6.5194e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.0954e-04 - val_loss: 7.4057e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.0758e-04 - val_loss: 8.5579e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.6285e-04 - val_loss: 6.4923e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.7040e-04 - val_loss: 6.0984e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.7288e-04 - val_loss: 7.3513e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.5379e-04 - val_loss: 6.3133e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 9.2978e-04 - val_loss: 6.1219e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.6521e-04 - val_loss: 7.9930e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.2451e-04 - val_loss: 5.9053e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.0153e-04 - val_loss: 7.1090e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.4753e-04 - val_loss: 5.9205e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.9869e-04 - val_loss: 8.2435e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.9776e-04 - val_loss: 5.4111e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.8880e-04 - val_loss: 5.7093e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.7131e-04 - val_loss: 5.6626e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.8434e-04 - val_loss: 5.3906e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.5672e-04 - val_loss: 6.1322e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.1664e-04 - val_loss: 5.7317e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.3494e-04 - val_loss: 5.4491e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.6925e-04 - val_loss: 5.9266e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 8.3742e-04 - val_loss: 6.6404e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.4402e-04 - val_loss: 5.6664e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.7754e-04 - val_loss: 5.4749e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 7.1955e-04 - val_loss: 5.2133e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.5913e-04 - val_loss: 5.0205e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.4446e-04 - val_loss: 5.3893e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.8130e-04 - val_loss: 5.5854e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.6386e-04 - val_loss: 5.8554e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.4571e-04 - val_loss: 5.7121e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.3153e-04 - val_loss: 6.8540e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.1562e-04 - val_loss: 4.7153e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 6.0684e-04 - val_loss: 5.7010e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.6442e-04 - val_loss: 4.8873e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.1105e-04 - val_loss: 5.1286e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.0387e-04 - val_loss: 4.7356e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 6.3490e-04 - val_loss: 4.8149e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.8480e-04 - val_loss: 4.8433e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.9252e-04 - val_loss: 5.3605e-04\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.5635e-04 - val_loss: 6.4295e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.6032e-04 - val_loss: 4.6846e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.2741e-04 - val_loss: 5.7055e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.1369e-04 - val_loss: 4.5943e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.0847e-04 - val_loss: 4.6443e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.0421e-04 - val_loss: 5.9307e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.0890e-04 - val_loss: 4.6868e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.1974e-04 - val_loss: 4.5047e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.1520e-04 - val_loss: 4.9269e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.8095e-04 - val_loss: 4.9060e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.4221e-04 - val_loss: 6.7047e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.6172e-04 - val_loss: 5.2218e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.3507e-04 - val_loss: 4.7217e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.8708e-04 - val_loss: 4.2470e-04\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.6612e-04 - val_loss: 4.2479e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.9238e-04 - val_loss: 4.5633e-04\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.2179e-04 - val_loss: 6.4837e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.8273e-04 - val_loss: 4.8162e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5412e-04 - val_loss: 4.2370e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5220e-04 - val_loss: 4.0429e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.3937e-04 - val_loss: 4.5053e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5845e-04 - val_loss: 4.1877e-04\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5731e-04 - val_loss: 4.0007e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.3792e-04 - val_loss: 4.6400e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.4166e-04 - val_loss: 6.2273e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.6674e-04 - val_loss: 4.0226e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.7037e-04 - val_loss: 4.9203e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5585e-04 - val_loss: 4.2140e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.6488e-04 - val_loss: 4.4379e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5914e-04 - val_loss: 4.5020e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.5273e-04 - val_loss: 3.9157e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.1530e-04 - val_loss: 3.7472e-04\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.3194e-04 - val_loss: 5.1907e-04\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.4988e-04 - val_loss: 4.9112e-04\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 4.4579e-04 - val_loss: 4.2253e-04\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.2442e-04 - val_loss: 3.9244e-04\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 4.2252e-04 - val_loss: 4.1418e-04\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.9927e-04 - val_loss: 3.8230e-04\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 4.2919e-04 - val_loss: 3.6572e-04\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 4.0017e-04 - val_loss: 3.6268e-04\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.9204e-04 - val_loss: 3.6603e-04\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.9515e-04 - val_loss: 3.4819e-04\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.9480e-04 - val_loss: 4.4694e-04\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 4.0933e-04 - val_loss: 3.6269e-04\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9520e-04 - val_loss: 4.6588e-04\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9213e-04 - val_loss: 3.8069e-04\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.8907e-04 - val_loss: 3.6790e-04\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7565e-04 - val_loss: 3.4681e-04\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7740e-04 - val_loss: 3.5001e-04\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 4.1440e-04 - val_loss: 3.4929e-04\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8211e-04 - val_loss: 3.5530e-04\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6520e-04 - val_loss: 3.9245e-04\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9796e-04 - val_loss: 3.4973e-04\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8542e-04 - val_loss: 3.4029e-04\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7669e-04 - val_loss: 3.7621e-04\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8400e-04 - val_loss: 3.9802e-04\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8942e-04 - val_loss: 3.2465e-04\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8400e-04 - val_loss: 4.3946e-04\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9350e-04 - val_loss: 3.3120e-04\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6334e-04 - val_loss: 3.2664e-04\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6076e-04 - val_loss: 3.4689e-04\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6843e-04 - val_loss: 5.4049e-04\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6771e-04 - val_loss: 3.5446e-04\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6018e-04 - val_loss: 3.6190e-04\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7022e-04 - val_loss: 4.2665e-04\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8557e-04 - val_loss: 3.3093e-04\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6279e-04 - val_loss: 3.3629e-04\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8776e-04 - val_loss: 4.2644e-04\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7410e-04 - val_loss: 4.6743e-04\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8015e-04 - val_loss: 3.2151e-04\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9009e-04 - val_loss: 3.2768e-04\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5811e-04 - val_loss: 3.5807e-04\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6520e-04 - val_loss: 3.8944e-04\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6795e-04 - val_loss: 3.3621e-04\n",
      "Epoch 161/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5067e-04 - val_loss: 3.3921e-04\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4530e-04 - val_loss: 3.2873e-04\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5812e-04 - val_loss: 3.3678e-04\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5727e-04 - val_loss: 3.8545e-04\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6262e-04 - val_loss: 4.5710e-04\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6686e-04 - val_loss: 4.5270e-04\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.8640e-04 - val_loss: 3.7052e-04\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4840e-04 - val_loss: 3.3695e-04\n",
      "Epoch 169/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6070e-04 - val_loss: 3.1715e-04\n",
      "Epoch 170/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6136e-04 - val_loss: 3.1273e-04\n",
      "Epoch 171/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6366e-04 - val_loss: 3.4822e-04\n",
      "Epoch 172/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5140e-04 - val_loss: 3.8579e-04\n",
      "Epoch 173/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3895e-04 - val_loss: 3.4693e-04\n",
      "Epoch 174/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6895e-04 - val_loss: 3.0993e-04\n",
      "Epoch 175/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4988e-04 - val_loss: 3.2421e-04\n",
      "Epoch 176/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4457e-04 - val_loss: 3.0417e-04\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5632e-04 - val_loss: 3.6356e-04\n",
      "Epoch 178/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5713e-04 - val_loss: 3.2415e-04\n",
      "Epoch 179/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4138e-04 - val_loss: 3.3230e-04\n",
      "Epoch 180/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5895e-04 - val_loss: 3.4877e-04\n",
      "Epoch 181/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7211e-04 - val_loss: 3.8130e-04\n",
      "Epoch 182/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3215e-04 - val_loss: 3.3758e-04\n",
      "Epoch 183/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3612e-04 - val_loss: 3.1865e-04\n",
      "Epoch 184/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7113e-04 - val_loss: 3.1192e-04\n",
      "Epoch 185/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4586e-04 - val_loss: 3.3002e-04\n",
      "Epoch 186/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4780e-04 - val_loss: 3.2807e-04\n",
      "Epoch 187/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4056e-04 - val_loss: 3.0971e-04\n",
      "Epoch 188/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5038e-04 - val_loss: 3.3333e-04\n",
      "Epoch 189/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3726e-04 - val_loss: 3.0032e-04\n",
      "Epoch 190/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5662e-04 - val_loss: 3.2597e-04\n",
      "Epoch 191/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4535e-04 - val_loss: 3.0835e-04\n",
      "Epoch 192/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4812e-04 - val_loss: 3.0416e-04\n",
      "Epoch 193/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.2477e-04 - val_loss: 3.6105e-04\n",
      "Epoch 194/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5594e-04 - val_loss: 3.1590e-04\n",
      "Epoch 195/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4924e-04 - val_loss: 3.0352e-04\n",
      "Epoch 196/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5599e-04 - val_loss: 4.2158e-04\n",
      "Epoch 197/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.7647e-04 - val_loss: 3.5515e-04\n",
      "Epoch 198/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.2923e-04 - val_loss: 3.3969e-04\n",
      "Epoch 199/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4196e-04 - val_loss: 3.0820e-04\n",
      "Epoch 200/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3632e-04 - val_loss: 3.3339e-04\n",
      "Epoch 201/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3163e-04 - val_loss: 3.8571e-04\n",
      "Epoch 202/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3989e-04 - val_loss: 5.0410e-04\n",
      "Epoch 203/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.6952e-04 - val_loss: 4.4303e-04\n",
      "Epoch 204/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4087e-04 - val_loss: 3.0501e-04\n",
      "Epoch 205/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3002e-04 - val_loss: 3.0419e-04\n",
      "Epoch 206/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.4569e-04 - val_loss: 3.1174e-04\n",
      "Epoch 207/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.9551e-04 - val_loss: 3.0038e-04\n",
      "Epoch 208/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.3586e-04 - val_loss: 3.2560e-04\n",
      "Epoch 209/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.5512e-04 - val_loss: 3.7392e-04\n",
      "Epoch 210/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.5166e-04 - val_loss: 3.1910e-04\n",
      "Epoch 211/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.3088e-04 - val_loss: 3.6193e-04\n",
      "Epoch 212/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4143e-04 - val_loss: 2.9646e-04\n",
      "Epoch 213/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4533e-04 - val_loss: 4.1402e-04\n",
      "Epoch 214/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4221e-04 - val_loss: 3.2075e-04\n",
      "Epoch 215/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3434e-04 - val_loss: 3.2965e-04\n",
      "Epoch 216/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.3213e-04 - val_loss: 3.1975e-04\n",
      "Epoch 217/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3221e-04 - val_loss: 3.3244e-04\n",
      "Epoch 218/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3587e-04 - val_loss: 3.8834e-04\n",
      "Epoch 219/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4612e-04 - val_loss: 3.5589e-04\n",
      "Epoch 220/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4399e-04 - val_loss: 3.5139e-04\n",
      "Epoch 221/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5851e-04 - val_loss: 3.0233e-04\n",
      "Epoch 222/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3373e-04 - val_loss: 3.6006e-04\n",
      "Epoch 223/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4678e-04 - val_loss: 3.0686e-04\n",
      "Epoch 224/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.2379e-04 - val_loss: 3.1444e-04\n",
      "Epoch 225/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4916e-04 - val_loss: 4.4596e-04\n",
      "Epoch 226/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4665e-04 - val_loss: 2.9575e-04\n",
      "Epoch 227/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3326e-04 - val_loss: 3.5039e-04\n",
      "Epoch 228/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3499e-04 - val_loss: 3.0464e-04\n",
      "Epoch 229/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3944e-04 - val_loss: 3.9127e-04\n",
      "Epoch 230/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5409e-04 - val_loss: 3.0590e-04\n",
      "Epoch 231/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3939e-04 - val_loss: 3.5384e-04\n",
      "Epoch 232/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3542e-04 - val_loss: 3.0054e-04\n",
      "Epoch 233/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3265e-04 - val_loss: 3.2197e-04\n",
      "Epoch 234/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4536e-04 - val_loss: 3.6629e-04\n",
      "Epoch 235/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4996e-04 - val_loss: 3.1097e-04\n",
      "Epoch 236/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3354e-04 - val_loss: 2.9704e-04\n",
      "Epoch 237/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3751e-04 - val_loss: 3.0439e-04\n",
      "Epoch 238/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2925e-04 - val_loss: 3.5462e-04\n",
      "Epoch 239/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3387e-04 - val_loss: 2.9547e-04\n",
      "Epoch 240/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5014e-04 - val_loss: 3.0950e-04\n",
      "Epoch 241/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5764e-04 - val_loss: 2.9504e-04\n",
      "Epoch 242/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3560e-04 - val_loss: 2.9804e-04\n",
      "Epoch 243/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4767e-04 - val_loss: 3.1013e-04\n",
      "Epoch 244/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3802e-04 - val_loss: 3.0651e-04\n",
      "Epoch 245/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3397e-04 - val_loss: 3.0940e-04\n",
      "Epoch 246/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3380e-04 - val_loss: 3.0581e-04\n",
      "Epoch 247/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3860e-04 - val_loss: 3.3761e-04\n",
      "Epoch 248/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4653e-04 - val_loss: 4.8067e-04\n",
      "Epoch 249/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4989e-04 - val_loss: 3.3652e-04\n",
      "Epoch 250/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3196e-04 - val_loss: 3.0366e-04\n",
      "Epoch 251/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2944e-04 - val_loss: 4.1833e-04\n",
      "Epoch 252/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5860e-04 - val_loss: 3.1005e-04\n",
      "Epoch 253/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4657e-04 - val_loss: 3.0333e-04\n",
      "Epoch 254/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3400e-04 - val_loss: 3.5086e-04\n",
      "Epoch 255/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4118e-04 - val_loss: 2.9958e-04\n",
      "Epoch 256/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3523e-04 - val_loss: 3.1123e-04\n",
      "Epoch 257/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2472e-04 - val_loss: 3.0841e-04\n",
      "Epoch 258/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3140e-04 - val_loss: 3.7472e-04\n",
      "Epoch 259/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2943e-04 - val_loss: 3.0653e-04\n",
      "Epoch 260/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3246e-04 - val_loss: 3.8915e-04\n",
      "Epoch 261/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5403e-04 - val_loss: 2.9718e-04\n",
      "Epoch 262/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2243e-04 - val_loss: 2.9976e-04\n",
      "Epoch 263/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3393e-04 - val_loss: 3.0970e-04\n",
      "Epoch 264/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5654e-04 - val_loss: 2.9330e-04\n",
      "Epoch 265/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3321e-04 - val_loss: 2.9952e-04\n",
      "Epoch 266/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3393e-04 - val_loss: 3.5546e-04\n",
      "Epoch 267/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4003e-04 - val_loss: 3.0347e-04\n",
      "Epoch 268/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.7321e-04 - val_loss: 2.9713e-04\n",
      "Epoch 269/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2573e-04 - val_loss: 3.2678e-04\n",
      "Epoch 270/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2940e-04 - val_loss: 3.2107e-04\n",
      "Epoch 271/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3366e-04 - val_loss: 3.5030e-04\n",
      "Epoch 272/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4397e-04 - val_loss: 3.4286e-04\n",
      "Epoch 273/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3575e-04 - val_loss: 2.9936e-04\n",
      "Epoch 274/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5586e-04 - val_loss: 2.9712e-04\n",
      "Epoch 275/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3406e-04 - val_loss: 3.8259e-04\n",
      "Epoch 276/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6570e-04 - val_loss: 3.3835e-04\n",
      "Epoch 277/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3307e-04 - val_loss: 3.2179e-04\n",
      "Epoch 278/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.2873e-04 - val_loss: 2.9534e-04\n",
      "Epoch 279/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.3791e-04 - val_loss: 3.0160e-04\n",
      "Epoch 280/1000\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 3.2677e-04 - val_loss: 3.0050e-04\n",
      "Epoch 281/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.8053e-04 - val_loss: 3.1057e-04\n",
      "Epoch 282/1000\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 3.2611e-04 - val_loss: 3.1188e-04\n",
      "Epoch 283/1000\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 3.4034e-04 - val_loss: 2.9493e-04\n",
      "Epoch 284/1000\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 3.2410e-04 - val_loss: 3.3016e-04\n",
      "Epoch 285/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.3279e-04 - val_loss: 2.9760e-04\n",
      "Epoch 286/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4943e-04 - val_loss: 5.1298e-04\n",
      "Epoch 287/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5412e-04 - val_loss: 2.9821e-04\n",
      "Epoch 288/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6031e-04 - val_loss: 3.0484e-04\n",
      "Epoch 289/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3904e-04 - val_loss: 3.2754e-04\n",
      "Epoch 290/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2898e-04 - val_loss: 3.8551e-04\n",
      "Epoch 291/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.4023e-04 - val_loss: 3.0377e-04\n",
      "Epoch 292/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.2509e-04 - val_loss: 3.3337e-04\n",
      "Epoch 293/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3926e-04 - val_loss: 3.3205e-04\n",
      "Epoch 294/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4059e-04 - val_loss: 3.4349e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 6s 36ms/step - loss: 0.0129 - val_loss: 0.0020\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 7.5868e-04\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 9.7756e-04 - val_loss: 6.8564e-04\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 9.8181e-04 - val_loss: 6.8631e-04\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 9.0265e-04 - val_loss: 5.8253e-04\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 8.1854e-04 - val_loss: 6.2632e-04\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 7.9026e-04 - val_loss: 5.3629e-04\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 7.4070e-04 - val_loss: 5.2550e-04\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 7.3243e-04 - val_loss: 5.4125e-04\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.9811e-04 - val_loss: 4.7660e-04\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.8103e-04 - val_loss: 5.0612e-04\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.4361e-04 - val_loss: 4.5738e-04\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.1066e-04 - val_loss: 5.0445e-04\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.1781e-04 - val_loss: 4.3901e-04\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.0255e-04 - val_loss: 4.1667e-04\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.7797e-04 - val_loss: 4.4515e-04\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.7085e-04 - val_loss: 3.9737e-04\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2772e-04 - val_loss: 5.7941e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.3554e-04 - val_loss: 4.7141e-04\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2444e-04 - val_loss: 3.8453e-04\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.7502e-04 - val_loss: 4.3824e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.9359e-04 - val_loss: 3.6292e-04\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.5908e-04 - val_loss: 3.7072e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.6348e-04 - val_loss: 4.4202e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2729e-04 - val_loss: 3.3493e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.1852e-04 - val_loss: 3.5603e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.4595e-04 - val_loss: 3.4332e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.4313e-04 - val_loss: 5.8058e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.4659e-04 - val_loss: 3.4438e-04\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 21ms/step - loss: 5.1163e-04 - val_loss: 4.0387e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.9018e-04 - val_loss: 3.1369e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.8498e-04 - val_loss: 3.1178e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.9609e-04 - val_loss: 5.4635e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.7529e-04 - val_loss: 3.9181e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.1760e-04 - val_loss: 3.1827e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 3.9572e-04 - val_loss: 3.2271e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 4.1495e-04 - val_loss: 3.3861e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.1462e-04 - val_loss: 6.0400e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 4.3462e-04 - val_loss: 3.6071e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.3586e-04 - val_loss: 2.9701e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 4.1837e-04 - val_loss: 2.9553e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 4.5450e-04 - val_loss: 3.1382e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 4.1080e-04 - val_loss: 3.0551e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 3.9720e-04 - val_loss: 5.2048e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 4.6637e-04 - val_loss: 2.9727e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 3.6359e-04 - val_loss: 3.2471e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 4.0877e-04 - val_loss: 3.0432e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 3.9725e-04 - val_loss: 4.1945e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 3.8078e-04 - val_loss: 3.5744e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 4.0836e-04 - val_loss: 3.0368e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.6009e-04 - val_loss: 3.4893e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.7639e-04 - val_loss: 3.5265e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 4.0066e-04 - val_loss: 3.5249e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.8821e-04 - val_loss: 6.7498e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 4.3725e-04 - val_loss: 3.3176e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.7037e-04 - val_loss: 3.0419e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 5.6923e-04 - val_loss: 2.8678e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.4711e-04 - val_loss: 3.1949e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.8527e-04 - val_loss: 4.9054e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.2550e-04 - val_loss: 4.8625e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9518e-04 - val_loss: 3.2556e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9668e-04 - val_loss: 3.0237e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9774e-04 - val_loss: 3.6140e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.4057e-04 - val_loss: 2.8996e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.3903e-04 - val_loss: 3.1079e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.9533e-04 - val_loss: 5.3793e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.4839e-04 - val_loss: 5.2707e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.9695e-04 - val_loss: 4.6677e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9323e-04 - val_loss: 4.5868e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.7347e-04 - val_loss: 3.0234e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9591e-04 - val_loss: 3.0303e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.8845e-04 - val_loss: 3.4040e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.6324e-04 - val_loss: 5.4861e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.9346e-04 - val_loss: 4.6319e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.7470e-04 - val_loss: 4.7234e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.1718e-04 - val_loss: 6.4335e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.8566e-04 - val_loss: 2.9761e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.9793e-04 - val_loss: 3.6334e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 3.7759e-04 - val_loss: 3.1661e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.1145e-04 - val_loss: 6.6406e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.6956e-04 - val_loss: 3.7253e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.9765e-04 - val_loss: 7.6247e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.0209e-04 - val_loss: 4.0415e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.9358e-04 - val_loss: 2.8663e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.5988e-04 - val_loss: 2.8970e-04\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.8123e-04 - val_loss: 2.9291e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.6724e-04 - val_loss: 2.8466e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.5672e-04 - val_loss: 3.1786e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.9742e-04 - val_loss: 3.0524e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.6946e-04 - val_loss: 3.0679e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9267e-04 - val_loss: 2.8529e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5734e-04 - val_loss: 2.9361e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5031e-04 - val_loss: 3.6192e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5785e-04 - val_loss: 3.2182e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.0916e-04 - val_loss: 3.3756e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.9936e-04 - val_loss: 2.9002e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.6423e-04 - val_loss: 2.8511e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3834e-04 - val_loss: 2.9453e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3899e-04 - val_loss: 3.3241e-04\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.5056e-04 - val_loss: 3.6897e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0024e-04 - val_loss: 6.4029e-04\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.4368e-04 - val_loss: 3.0382e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.4911e-04 - val_loss: 3.9104e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3545e-04 - val_loss: 3.0771e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.3486e-04 - val_loss: 2.8990e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.3636e-04 - val_loss: 2.9569e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.6060e-04 - val_loss: 3.0975e-04\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.4106e-04 - val_loss: 5.0819e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.6675e-04 - val_loss: 3.0999e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.8722e-04 - val_loss: 2.8658e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.4636e-04 - val_loss: 3.7440e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.5555e-04 - val_loss: 3.1302e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.5257e-04 - val_loss: 3.0459e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.5755e-04 - val_loss: 2.9879e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.4586e-04 - val_loss: 3.0358e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.3188e-04 - val_loss: 3.8759e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.2205e-04 - val_loss: 2.9216e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 8s 60ms/step - loss: 0.0183 - val_loss: 0.0021\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0015 - val_loss: 9.6909e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0015 - val_loss: 8.4544e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0014 - val_loss: 9.7354e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0016 - val_loss: 8.2469e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0014 - val_loss: 7.8452e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0013 - val_loss: 8.6917e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0012 - val_loss: 7.6508e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0013 - val_loss: 8.3857e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.0011 - val_loss: 9.3319e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0010 - val_loss: 6.6502e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.0011 - val_loss: 7.8774e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 9.9259e-04 - val_loss: 5.8402e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 9.9506e-04 - val_loss: 6.2246e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 9.2086e-04 - val_loss: 0.0027\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0011 - val_loss: 5.9605e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 8.9317e-04 - val_loss: 5.5685e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 7.9474e-04 - val_loss: 5.0616e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 7.9844e-04 - val_loss: 9.0732e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 7.1499e-04 - val_loss: 5.2749e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 9.0181e-04 - val_loss: 0.0021\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 7.7979e-04 - val_loss: 6.7553e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 6.5032e-04 - val_loss: 4.8165e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 6.1405e-04 - val_loss: 4.7719e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 6.3238e-04 - val_loss: 4.5413e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 7.0890e-04 - val_loss: 4.4300e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 6.2186e-04 - val_loss: 5.3669e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 5.7769e-04 - val_loss: 0.0011\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 9.1709e-04 - val_loss: 7.0526e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 5.6843e-04 - val_loss: 6.0146e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 5.6503e-04 - val_loss: 5.6937e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 5.4734e-04 - val_loss: 3.9796e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 5.4719e-04 - val_loss: 8.7559e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.8939e-04 - val_loss: 3.7097e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 5.0651e-04 - val_loss: 3.5990e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.8408e-04 - val_loss: 3.7169e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.7482e-04 - val_loss: 7.5728e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 5.7505e-04 - val_loss: 4.3169e-04\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 31ms/step - loss: 4.5294e-04 - val_loss: 4.5392e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.6007e-04 - val_loss: 3.5446e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 5.9307e-04 - val_loss: 3.8522e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.4409e-04 - val_loss: 3.6930e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 5.5692e-04 - val_loss: 3.5177e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 5.4689e-04 - val_loss: 4.5985e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 5.9128e-04 - val_loss: 3.3329e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.9640e-04 - val_loss: 3.6554e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.5871e-04 - val_loss: 3.1595e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 4.0471e-04 - val_loss: 3.6694e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 4.6202e-04 - val_loss: 0.0010\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 6.3447e-04 - val_loss: 5.8520e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.6674e-04 - val_loss: 3.2709e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.7372e-04 - val_loss: 3.1255e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.4857e-04 - val_loss: 3.1862e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.3531e-04 - val_loss: 4.4155e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.7214e-04 - val_loss: 3.0574e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.1123e-04 - val_loss: 3.4234e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.5265e-04 - val_loss: 3.4554e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 5.0062e-04 - val_loss: 3.7429e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.0906e-04 - val_loss: 3.5018e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.8494e-04 - val_loss: 3.5046e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.9900e-04 - val_loss: 0.0018\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.4087e-04 - val_loss: 5.0646e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.5779e-04 - val_loss: 3.6472e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 5.8649e-04 - val_loss: 2.9348e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.9248e-04 - val_loss: 5.9386e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 5.1969e-04 - val_loss: 3.4654e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.8511e-04 - val_loss: 2.9004e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.1006e-04 - val_loss: 2.9808e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.6005e-04 - val_loss: 6.4585e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.7194e-04 - val_loss: 2.9833e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.2450e-04 - val_loss: 4.1692e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.6989e-04 - val_loss: 3.5642e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.9874e-04 - val_loss: 3.0865e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.9397e-04 - val_loss: 6.1154e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 4.3437e-04 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.2353e-04 - val_loss: 3.3760e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 4.0513e-04 - val_loss: 0.0011\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 4.0227e-04 - val_loss: 3.2750e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 3.9372e-04 - val_loss: 2.8692e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 3.6070e-04 - val_loss: 3.1838e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 3.9141e-04 - val_loss: 4.0822e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.9628e-04 - val_loss: 3.3316e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.5948e-04 - val_loss: 3.5628e-04\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 3.5433e-04 - val_loss: 2.8739e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.2724e-04 - val_loss: 3.7505e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3899e-04 - val_loss: 2.9076e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.4892e-04 - val_loss: 2.8873e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.6546e-04 - val_loss: 2.9796e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.0256e-04 - val_loss: 3.5254e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 3.9348e-04 - val_loss: 3.9264e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.9252e-04 - val_loss: 3.0858e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 3.6080e-04 - val_loss: 3.4548e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.1112e-04 - val_loss: 2.9498e-04\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.1207e-04 - val_loss: 0.0012\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 4.6840e-04 - val_loss: 3.7371e-04\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.8466e-04 - val_loss: 3.0388e-04\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 4.2994e-04 - val_loss: 2.8734e-04\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.5405e-04 - val_loss: 2.9383e-04\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 3.5754e-04 - val_loss: 3.5988e-04\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.2806e-04 - val_loss: 4.2233e-04\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 3.9130e-04 - val_loss: 2.9754e-04\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.4043e-04 - val_loss: 2.8908e-04\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.0935e-04 - val_loss: 3.7709e-04\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 3.9661e-04 - val_loss: 4.6135e-04\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 4.1465e-04 - val_loss: 3.0525e-04\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.1003e-04 - val_loss: 5.1825e-04\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 3.4476e-04 - val_loss: 4.2340e-04\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.5405e-04 - val_loss: 2.8974e-04\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.8147e-04 - val_loss: 6.2564e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 3s 34ms/step - loss: 0.0736 - val_loss: 0.0134\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0037\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 9.7006e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 7.7748e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 7.5659e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 8.2883e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 7.8208e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 8.6332e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 8.5172e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 7.2113e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 8.8045e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 8.3272e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 9.8657e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.4881e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.9976e-04 - val_loss: 7.1950e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.4591e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.8741e-04 - val_loss: 8.4745e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.5903e-04 - val_loss: 6.3424e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.2595e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.7267e-04 - val_loss: 7.8528e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.9103e-04 - val_loss: 6.6694e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.6850e-04 - val_loss: 6.5712e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 8.2360e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.6342e-04 - val_loss: 5.9820e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.2006e-04 - val_loss: 5.9828e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.9886e-04 - val_loss: 6.0382e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.0885e-04 - val_loss: 7.5688e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.4710e-04 - val_loss: 5.8252e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.9891e-04 - val_loss: 5.8991e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.8679e-04 - val_loss: 5.9717e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.3604e-04 - val_loss: 5.6553e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6752e-04 - val_loss: 6.9566e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.5552e-04 - val_loss: 7.1172e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.0384e-04 - val_loss: 6.5017e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6694e-04 - val_loss: 5.5148e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.4995e-04 - val_loss: 5.4766e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.6227e-04 - val_loss: 5.5655e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3154e-04 - val_loss: 5.5957e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2672e-04 - val_loss: 5.3473e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.8908e-04 - val_loss: 5.4861e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0607e-04 - val_loss: 5.4136e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0917e-04 - val_loss: 5.2905e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.9743e-04 - val_loss: 5.2638e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.9198e-04 - val_loss: 5.1875e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.8745e-04 - val_loss: 5.2171e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0859e-04 - val_loss: 6.3048e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.8098e-04 - val_loss: 5.2691e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.7449e-04 - val_loss: 5.1180e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.6794e-04 - val_loss: 5.2424e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.7243e-04 - val_loss: 6.2427e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.8458e-04 - val_loss: 5.1590e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0221e-04 - val_loss: 5.0215e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.2424e-04 - val_loss: 5.2452e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.1501e-04 - val_loss: 5.1129e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.1274e-04 - val_loss: 5.3231e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.2336e-04 - val_loss: 4.7659e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.4253e-04 - val_loss: 5.3094e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.9540e-04 - val_loss: 4.9859e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.8575e-04 - val_loss: 4.8535e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.9435e-04 - val_loss: 4.8987e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3338e-04 - val_loss: 5.4772e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.0106e-04 - val_loss: 4.9316e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.7372e-04 - val_loss: 6.0870e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.0190e-04 - val_loss: 4.9119e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.0000e-04 - val_loss: 5.3428e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.5586e-04 - val_loss: 4.7592e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.5217e-04 - val_loss: 5.1168e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2159e-04 - val_loss: 4.4377e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2787e-04 - val_loss: 4.4743e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3890e-04 - val_loss: 4.5345e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.5299e-04 - val_loss: 4.4817e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1708e-04 - val_loss: 4.6283e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0892e-04 - val_loss: 4.6741e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1635e-04 - val_loss: 5.0875e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2439e-04 - val_loss: 4.3515e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1511e-04 - val_loss: 4.3576e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8960e-04 - val_loss: 4.4676e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0747e-04 - val_loss: 5.5991e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.7577e-04 - val_loss: 4.3177e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8932e-04 - val_loss: 5.2169e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3621e-04 - val_loss: 8.1529e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.7935e-04 - val_loss: 4.4508e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.5208e-04 - val_loss: 4.1898e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8089e-04 - val_loss: 4.5811e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8593e-04 - val_loss: 4.3188e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.9043e-04 - val_loss: 4.0654e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3367e-04 - val_loss: 4.1659e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3372e-04 - val_loss: 4.5824e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.4566e-04 - val_loss: 4.1385e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.4613e-04 - val_loss: 4.2622e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1992e-04 - val_loss: 4.0296e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1704e-04 - val_loss: 4.0423e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.2394e-04 - val_loss: 4.0896e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1352e-04 - val_loss: 5.2146e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.2412e-04 - val_loss: 4.0029e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3246e-04 - val_loss: 4.2244e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9787e-04 - val_loss: 4.4364e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0742e-04 - val_loss: 4.1820e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9971e-04 - val_loss: 5.0205e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9985e-04 - val_loss: 3.9036e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8731e-04 - val_loss: 3.8567e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9860e-04 - val_loss: 3.9790e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9074e-04 - val_loss: 4.3754e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9746e-04 - val_loss: 5.1516e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1312e-04 - val_loss: 3.8805e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9109e-04 - val_loss: 4.1261e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8219e-04 - val_loss: 4.2370e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7958e-04 - val_loss: 3.8382e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6469e-04 - val_loss: 4.3424e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8221e-04 - val_loss: 4.1227e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.7253e-04 - val_loss: 3.8745e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.9136e-04 - val_loss: 3.9470e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5333e-04 - val_loss: 3.8123e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4856e-04 - val_loss: 3.8578e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6348e-04 - val_loss: 3.7121e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4816e-04 - val_loss: 3.8263e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5832e-04 - val_loss: 4.2258e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6314e-04 - val_loss: 4.0556e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5188e-04 - val_loss: 3.6206e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8967e-04 - val_loss: 4.1653e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4045e-04 - val_loss: 4.2953e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5227e-04 - val_loss: 3.6760e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3332e-04 - val_loss: 3.6412e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3609e-04 - val_loss: 3.6803e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2558e-04 - val_loss: 3.7927e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3227e-04 - val_loss: 3.7380e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3868e-04 - val_loss: 3.9948e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7742e-04 - val_loss: 3.6802e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3415e-04 - val_loss: 3.8018e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1732e-04 - val_loss: 3.8696e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1699e-04 - val_loss: 3.5462e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3171e-04 - val_loss: 3.9167e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1808e-04 - val_loss: 3.6307e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4360e-04 - val_loss: 4.3377e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.4312e-04 - val_loss: 3.5514e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5773e-04 - val_loss: 3.9054e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3638e-04 - val_loss: 3.5634e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1863e-04 - val_loss: 3.6160e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5670e-04 - val_loss: 5.4542e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2998e-04 - val_loss: 3.8562e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0960e-04 - val_loss: 3.8282e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1998e-04 - val_loss: 4.2290e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1440e-04 - val_loss: 3.5973e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0154e-04 - val_loss: 3.7023e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1578e-04 - val_loss: 3.5951e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2290e-04 - val_loss: 3.5450e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1182e-04 - val_loss: 3.4553e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0905e-04 - val_loss: 3.4863e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1560e-04 - val_loss: 3.6889e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0969e-04 - val_loss: 3.7939e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5600e-04 - val_loss: 4.9376e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2183e-04 - val_loss: 3.5038e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0811e-04 - val_loss: 3.7698e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2429e-04 - val_loss: 4.0508e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9665e-04 - val_loss: 3.5221e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1228e-04 - val_loss: 4.3127e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1023e-04 - val_loss: 4.6161e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5323e-04 - val_loss: 3.5802e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8041e-04 - val_loss: 3.6016e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7952e-04 - val_loss: 3.6498e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1150e-04 - val_loss: 3.3328e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9764e-04 - val_loss: 3.4118e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7970e-04 - val_loss: 3.4358e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7361e-04 - val_loss: 3.3829e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7806e-04 - val_loss: 3.6341e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8843e-04 - val_loss: 3.6294e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8879e-04 - val_loss: 3.3477e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6982e-04 - val_loss: 3.5699e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8049e-04 - val_loss: 4.0880e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0908e-04 - val_loss: 4.3434e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9212e-04 - val_loss: 3.4997e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7535e-04 - val_loss: 3.3463e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6786e-04 - val_loss: 3.7011e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8587e-04 - val_loss: 3.4004e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6882e-04 - val_loss: 3.9339e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9362e-04 - val_loss: 3.3324e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8740e-04 - val_loss: 4.1255e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8917e-04 - val_loss: 3.9396e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7574e-04 - val_loss: 3.2321e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1608e-04 - val_loss: 3.6179e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7759e-04 - val_loss: 3.1762e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9253e-04 - val_loss: 3.3214e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8388e-04 - val_loss: 3.5533e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0575e-04 - val_loss: 3.7859e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9585e-04 - val_loss: 3.2783e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8572e-04 - val_loss: 3.3792e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7385e-04 - val_loss: 3.3598e-04\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5849e-04 - val_loss: 3.3800e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0017e-04 - val_loss: 5.9692e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8104e-04 - val_loss: 3.4160e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6139e-04 - val_loss: 3.4234e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6234e-04 - val_loss: 3.2500e-04\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7675e-04 - val_loss: 3.8922e-04\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9174e-04 - val_loss: 3.4056e-04\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8244e-04 - val_loss: 4.1436e-04\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7149e-04 - val_loss: 3.5278e-04\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9176e-04 - val_loss: 3.8393e-04\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1658e-04 - val_loss: 4.1079e-04\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9080e-04 - val_loss: 3.7395e-04\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8343e-04 - val_loss: 3.2811e-04\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7002e-04 - val_loss: 3.1417e-04\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7787e-04 - val_loss: 3.5743e-04\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5934e-04 - val_loss: 3.2189e-04\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8199e-04 - val_loss: 3.9660e-04\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6162e-04 - val_loss: 3.2435e-04\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5390e-04 - val_loss: 3.2812e-04\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5836e-04 - val_loss: 4.2001e-04\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7973e-04 - val_loss: 3.2385e-04\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6861e-04 - val_loss: 4.5205e-04\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1020e-04 - val_loss: 3.1786e-04\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5699e-04 - val_loss: 3.4654e-04\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7166e-04 - val_loss: 3.7065e-04\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0524e-04 - val_loss: 6.1281e-04\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0381e-04 - val_loss: 3.5764e-04\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4763e-04 - val_loss: 3.8305e-04\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7822e-04 - val_loss: 3.3287e-04\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5955e-04 - val_loss: 3.1080e-04\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5755e-04 - val_loss: 3.2526e-04\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5444e-04 - val_loss: 3.2599e-04\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8657e-04 - val_loss: 3.9354e-04\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5436e-04 - val_loss: 3.3104e-04\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5886e-04 - val_loss: 3.4051e-04\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5602e-04 - val_loss: 3.2326e-04\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7748e-04 - val_loss: 5.3896e-04\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8273e-04 - val_loss: 4.0038e-04\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5354e-04 - val_loss: 3.1620e-04\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4833e-04 - val_loss: 3.2754e-04\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3951e-04 - val_loss: 3.0918e-04\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4007e-04 - val_loss: 3.4984e-04\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5009e-04 - val_loss: 3.3633e-04\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5464e-04 - val_loss: 3.2229e-04\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6115e-04 - val_loss: 3.2987e-04\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5009e-04 - val_loss: 4.1170e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6385e-04 - val_loss: 3.3410e-04\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6561e-04 - val_loss: 3.0951e-04\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4100e-04 - val_loss: 3.5586e-04\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3541e-04 - val_loss: 3.1386e-04\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4814e-04 - val_loss: 3.1344e-04\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4245e-04 - val_loss: 3.5556e-04\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6882e-04 - val_loss: 3.0886e-04\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5574e-04 - val_loss: 3.3629e-04\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4296e-04 - val_loss: 3.2036e-04\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4514e-04 - val_loss: 3.3446e-04\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4355e-04 - val_loss: 3.1262e-04\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4821e-04 - val_loss: 3.5999e-04\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5621e-04 - val_loss: 3.1454e-04\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7887e-04 - val_loss: 3.7723e-04\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4454e-04 - val_loss: 4.2199e-04\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5570e-04 - val_loss: 3.2114e-04\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6900e-04 - val_loss: 4.0908e-04\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5568e-04 - val_loss: 3.0581e-04\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5714e-04 - val_loss: 3.2134e-04\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3287e-04 - val_loss: 3.0752e-04\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3170e-04 - val_loss: 3.0350e-04\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4529e-04 - val_loss: 3.0128e-04\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4103e-04 - val_loss: 3.0906e-04\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4088e-04 - val_loss: 3.2763e-04\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4402e-04 - val_loss: 3.0736e-04\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5627e-04 - val_loss: 3.0120e-04\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4510e-04 - val_loss: 3.1850e-04\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3937e-04 - val_loss: 3.5085e-04\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4510e-04 - val_loss: 3.4690e-04\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4063e-04 - val_loss: 3.0646e-04\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5245e-04 - val_loss: 3.0609e-04\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5431e-04 - val_loss: 3.2676e-04\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6363e-04 - val_loss: 3.1388e-04\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3695e-04 - val_loss: 3.1575e-04\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4528e-04 - val_loss: 3.0834e-04\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4772e-04 - val_loss: 3.1476e-04\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6978e-04 - val_loss: 3.4368e-04\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5329e-04 - val_loss: 3.1850e-04\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5672e-04 - val_loss: 3.7424e-04\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4459e-04 - val_loss: 3.0452e-04\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4715e-04 - val_loss: 3.1454e-04\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4138e-04 - val_loss: 2.9665e-04\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5405e-04 - val_loss: 4.0221e-04\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5317e-04 - val_loss: 4.0340e-04\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3244e-04 - val_loss: 3.7342e-04\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8331e-04 - val_loss: 3.3519e-04\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4135e-04 - val_loss: 3.1829e-04\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4143e-04 - val_loss: 3.0015e-04\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3882e-04 - val_loss: 3.4369e-04\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3255e-04 - val_loss: 3.0193e-04\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3723e-04 - val_loss: 3.0968e-04\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4437e-04 - val_loss: 3.0817e-04\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3803e-04 - val_loss: 3.1747e-04\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3152e-04 - val_loss: 3.1776e-04\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3470e-04 - val_loss: 3.1001e-04\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3303e-04 - val_loss: 2.9692e-04\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5832e-04 - val_loss: 3.0117e-04\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9955e-04 - val_loss: 3.2333e-04\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1257e-04 - val_loss: 3.1647e-04\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3946e-04 - val_loss: 3.0890e-04\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8586e-04 - val_loss: 3.0817e-04\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4949e-04 - val_loss: 2.9923e-04\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2517e-04 - val_loss: 3.0113e-04\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2365e-04 - val_loss: 3.0190e-04\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2359e-04 - val_loss: 3.0256e-04\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3755e-04 - val_loss: 3.1598e-04\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6371e-04 - val_loss: 2.9875e-04\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2836e-04 - val_loss: 2.9871e-04\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3312e-04 - val_loss: 3.0130e-04\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5529e-04 - val_loss: 3.0341e-04\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2866e-04 - val_loss: 3.4940e-04\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3926e-04 - val_loss: 3.1049e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 5s 57ms/step - loss: 0.0205 - val_loss: 0.0018\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0028 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 9.3091e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0012 - val_loss: 7.7244e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0011 - val_loss: 7.3485e-04\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0010 - val_loss: 7.0979e-04\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0010 - val_loss: 6.8133e-04\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 9.6715e-04 - val_loss: 7.2008e-04\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.3975e-04 - val_loss: 6.7374e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.1162e-04 - val_loss: 6.6026e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.8171e-04 - val_loss: 7.4129e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 8.5620e-04 - val_loss: 6.3993e-04\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.3773e-04 - val_loss: 6.0894e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.6066e-04 - val_loss: 6.6468e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.1216e-04 - val_loss: 5.9323e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 7.6767e-04 - val_loss: 7.4585e-04\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.0136e-04 - val_loss: 5.3849e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 7.8132e-04 - val_loss: 5.3919e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.3047e-04 - val_loss: 5.4942e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 7.0595e-04 - val_loss: 5.8202e-04\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.9951e-04 - val_loss: 4.9869e-04\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 6.7754e-04 - val_loss: 5.0843e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 6.5602e-04 - val_loss: 4.7827e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.5141e-04 - val_loss: 5.1315e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.2213e-04 - val_loss: 5.2931e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 6.1486e-04 - val_loss: 4.8683e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.9546e-04 - val_loss: 4.8305e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 6.1609e-04 - val_loss: 4.5225e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.8057e-04 - val_loss: 4.3329e-04\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 5.6922e-04 - val_loss: 4.2274e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 6.0723e-04 - val_loss: 4.1672e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.4771e-04 - val_loss: 4.2520e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.3291e-04 - val_loss: 4.6740e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.4761e-04 - val_loss: 5.9062e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.6036e-04 - val_loss: 4.6677e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.4043e-04 - val_loss: 3.8764e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.1455e-04 - val_loss: 3.8285e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.9156e-04 - val_loss: 4.1680e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.8499e-04 - val_loss: 3.9263e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.8860e-04 - val_loss: 3.7522e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.9343e-04 - val_loss: 6.3367e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.3306e-04 - val_loss: 6.2516e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.7850e-04 - val_loss: 3.5501e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.5950e-04 - val_loss: 3.5372e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.5619e-04 - val_loss: 6.0078e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.3839e-04 - val_loss: 4.0453e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.6650e-04 - val_loss: 3.4175e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.5585e-04 - val_loss: 4.1115e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.7514e-04 - val_loss: 3.4912e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.2079e-04 - val_loss: 3.4836e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.5460e-04 - val_loss: 3.3916e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.0874e-04 - val_loss: 3.5214e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.9500e-04 - val_loss: 3.8308e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1263e-04 - val_loss: 3.9466e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.1703e-04 - val_loss: 3.9607e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.2526e-04 - val_loss: 5.4289e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.4668e-04 - val_loss: 3.2174e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.7857e-04 - val_loss: 3.6711e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.8595e-04 - val_loss: 3.1417e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.7381e-04 - val_loss: 3.2708e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.0655e-04 - val_loss: 3.2277e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9852e-04 - val_loss: 3.2331e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.0377e-04 - val_loss: 3.4055e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.4410e-04 - val_loss: 3.9981e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.2351e-04 - val_loss: 3.9782e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.1247e-04 - val_loss: 3.1859e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.1208e-04 - val_loss: 3.1246e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.1643e-04 - val_loss: 3.5863e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.3125e-04 - val_loss: 3.1588e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.7606e-04 - val_loss: 3.0401e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.6267e-04 - val_loss: 3.2894e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.7312e-04 - val_loss: 3.1795e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.5915e-04 - val_loss: 3.9565e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.9665e-04 - val_loss: 3.7185e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.0960e-04 - val_loss: 2.9978e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.5977e-04 - val_loss: 3.0992e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6653e-04 - val_loss: 2.9945e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.7151e-04 - val_loss: 2.9378e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.4527e-04 - val_loss: 2.9611e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.7657e-04 - val_loss: 4.0268e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.6623e-04 - val_loss: 3.1813e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8768e-04 - val_loss: 3.0367e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.9817e-04 - val_loss: 3.3636e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5774e-04 - val_loss: 2.8944e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.5004e-04 - val_loss: 2.8958e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5869e-04 - val_loss: 2.9044e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5161e-04 - val_loss: 2.9069e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.6549e-04 - val_loss: 2.9405e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.6746e-04 - val_loss: 3.7451e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 3.4413e-04 - val_loss: 3.3011e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.7659e-04 - val_loss: 4.2470e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.6821e-04 - val_loss: 3.1446e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.5550e-04 - val_loss: 4.1786e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4830e-04 - val_loss: 2.9075e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5565e-04 - val_loss: 3.0682e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.6269e-04 - val_loss: 2.9808e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.7592e-04 - val_loss: 4.8145e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.7164e-04 - val_loss: 3.8877e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.6859e-04 - val_loss: 3.5506e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.9173e-04 - val_loss: 4.1023e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.9464e-04 - val_loss: 2.9993e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.4218e-04 - val_loss: 3.3007e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.2818e-04 - val_loss: 7.0429e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.3262e-04 - val_loss: 2.9823e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.2929e-04 - val_loss: 2.8480e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4858e-04 - val_loss: 2.9111e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.3632e-04 - val_loss: 3.1665e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.3953e-04 - val_loss: 2.9795e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.6382e-04 - val_loss: 2.9073e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8093e-04 - val_loss: 5.1220e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6927e-04 - val_loss: 3.1727e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8016e-04 - val_loss: 3.1005e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4253e-04 - val_loss: 2.9817e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.5735e-04 - val_loss: 3.2765e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0012e-04 - val_loss: 4.0387e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.1482e-04 - val_loss: 3.4250e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.6216e-04 - val_loss: 2.8803e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.5648e-04 - val_loss: 3.4525e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.5457e-04 - val_loss: 2.9478e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.6077e-04 - val_loss: 2.9246e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.6540e-04 - val_loss: 3.9787e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.8154e-04 - val_loss: 5.8577e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.1295e-04 - val_loss: 3.1457e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5646e-04 - val_loss: 3.0459e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8068e-04 - val_loss: 4.6719e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.8883e-04 - val_loss: 3.2632e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.2932e-04 - val_loss: 2.9093e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.6189e-04 - val_loss: 5.2427e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.6366e-04 - val_loss: 3.1790e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6405e-04 - val_loss: 3.0762e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.3459e-04 - val_loss: 2.8854e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4357e-04 - val_loss: 3.3033e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.5403e-04 - val_loss: 3.3749e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.3838e-04 - val_loss: 3.3547e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.5241e-04 - val_loss: 3.2874e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 7s 81ms/step - loss: 0.0304 - val_loss: 0.0105\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0018 - val_loss: 9.7220e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0018 - val_loss: 9.4796e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 9.0476e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 9.6437e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 8.3610e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0013 - val_loss: 9.7993e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0014 - val_loss: 7.9419e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0013 - val_loss: 9.6358e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0012 - val_loss: 9.6729e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0013 - val_loss: 7.9650e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0012 - val_loss: 7.7914e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0012 - val_loss: 7.8553e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0012 - val_loss: 7.4169e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0012 - val_loss: 7.1134e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0013 - val_loss: 7.6349e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 6.9570e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0012 - val_loss: 6.6290e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0010 - val_loss: 7.1293e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0010 - val_loss: 8.1356e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 6.3827e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 6.1837e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 8.3899e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0011 - val_loss: 6.6030e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 9.7255e-04 - val_loss: 6.5667e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 9.1952e-04 - val_loss: 7.8437e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 9.3795e-04 - val_loss: 0.0012\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 8.9025e-04 - val_loss: 6.9536e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.9364e-04 - val_loss: 5.8037e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.1774e-04 - val_loss: 7.2150e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.0263e-04 - val_loss: 6.2710e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 7.7888e-04 - val_loss: 5.4839e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.6659e-04 - val_loss: 5.2810e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 8.5512e-04 - val_loss: 6.3845e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 7.4452e-04 - val_loss: 6.9089e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 7.0912e-04 - val_loss: 5.1831e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 7.8919e-04 - val_loss: 7.4102e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.7762e-04 - val_loss: 5.8530e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.7762e-04 - val_loss: 4.9531e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 8.1279e-04 - val_loss: 4.9191e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.6151e-04 - val_loss: 6.1963e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 6.7726e-04 - val_loss: 5.0610e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 7.9432e-04 - val_loss: 7.7992e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 6.6121e-04 - val_loss: 4.7379e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 6.7167e-04 - val_loss: 0.0011\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 6.4930e-04 - val_loss: 4.7333e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 7.0267e-04 - val_loss: 6.1491e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 6.6442e-04 - val_loss: 9.4135e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 6.4288e-04 - val_loss: 6.8463e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 7.1494e-04 - val_loss: 4.4926e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 6.8851e-04 - val_loss: 4.7733e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.7699e-04 - val_loss: 5.6958e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 6.3450e-04 - val_loss: 4.2837e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.3508e-04 - val_loss: 5.0579e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.5117e-04 - val_loss: 8.9762e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.6544e-04 - val_loss: 4.1525e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.3037e-04 - val_loss: 5.0749e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 6.4860e-04 - val_loss: 5.6489e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.9295e-04 - val_loss: 5.0162e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.3040e-04 - val_loss: 4.5632e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.3448e-04 - val_loss: 6.8246e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.9691e-04 - val_loss: 4.3722e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.2852e-04 - val_loss: 6.9465e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.5637e-04 - val_loss: 4.2412e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.7591e-04 - val_loss: 4.0875e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 5.7486e-04 - val_loss: 4.0405e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.9020e-04 - val_loss: 3.9375e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.9176e-04 - val_loss: 4.5937e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.9904e-04 - val_loss: 3.8335e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.8190e-04 - val_loss: 9.6956e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 5.6337e-04 - val_loss: 3.6365e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.6656e-04 - val_loss: 3.9641e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.3329e-04 - val_loss: 3.7131e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.5687e-04 - val_loss: 4.3023e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.4878e-04 - val_loss: 3.7504e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.1652e-04 - val_loss: 3.5211e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.6534e-04 - val_loss: 7.4836e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 5.3179e-04 - val_loss: 4.4443e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.4359e-04 - val_loss: 6.2780e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.3024e-04 - val_loss: 3.4929e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.5034e-04 - val_loss: 5.1375e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.4200e-04 - val_loss: 5.7391e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.1311e-04 - val_loss: 3.4123e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 4.0358e-04 - val_loss: 3.5273e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.0589e-04 - val_loss: 5.1339e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.1995e-04 - val_loss: 3.2029e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.7610e-04 - val_loss: 8.1862e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4223e-04 - val_loss: 4.3833e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.4181e-04 - val_loss: 3.6709e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.0254e-04 - val_loss: 3.3478e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.9809e-04 - val_loss: 3.8172e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.3281e-04 - val_loss: 3.1130e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.0199e-04 - val_loss: 3.1341e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.2781e-04 - val_loss: 3.4409e-04\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.8894e-04 - val_loss: 3.8334e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.8227e-04 - val_loss: 3.1708e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.0945e-04 - val_loss: 3.5642e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.3595e-04 - val_loss: 3.0506e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.6729e-04 - val_loss: 3.2799e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.1255e-04 - val_loss: 3.4290e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.7079e-04 - val_loss: 3.3547e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.7236e-04 - val_loss: 5.5965e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.3659e-04 - val_loss: 3.1055e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 4.5592e-04 - val_loss: 3.8776e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 5.3913e-04 - val_loss: 7.8886e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.7393e-04 - val_loss: 5.6372e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.1445e-04 - val_loss: 3.2700e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.6508e-04 - val_loss: 3.0236e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.6214e-04 - val_loss: 3.0197e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.9657e-04 - val_loss: 3.2573e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.5610e-04 - val_loss: 3.0842e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.4525e-04 - val_loss: 3.0420e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.0134e-04 - val_loss: 3.2721e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8825e-04 - val_loss: 3.1731e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8799e-04 - val_loss: 3.1660e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.5538e-04 - val_loss: 4.9267e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.0174e-04 - val_loss: 6.5964e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.3231e-04 - val_loss: 5.0682e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.0385e-04 - val_loss: 3.0792e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.1014e-04 - val_loss: 7.2764e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8098e-04 - val_loss: 3.0243e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.5787e-04 - val_loss: 3.8665e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.6494e-04 - val_loss: 3.0098e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.6029e-04 - val_loss: 3.2227e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.5027e-04 - val_loss: 3.1652e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.9185e-04 - val_loss: 3.9825e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.8585e-04 - val_loss: 4.1596e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.7532e-04 - val_loss: 2.9704e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.5916e-04 - val_loss: 3.1562e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.3682e-04 - val_loss: 3.4840e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.6778e-04 - val_loss: 3.0626e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.5764e-04 - val_loss: 2.9976e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.6190e-04 - val_loss: 3.3286e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.7683e-04 - val_loss: 4.0752e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.8008e-04 - val_loss: 3.1111e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.9218e-04 - val_loss: 3.5351e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.0223e-04 - val_loss: 3.2266e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4082e-04 - val_loss: 2.9171e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4732e-04 - val_loss: 3.3963e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4922e-04 - val_loss: 3.4708e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.4553e-04 - val_loss: 2.9970e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.3920e-04 - val_loss: 3.0151e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.5605e-04 - val_loss: 4.9281e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8813e-04 - val_loss: 4.3597e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9412e-04 - val_loss: 3.7977e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.4927e-04 - val_loss: 5.1427e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.9141e-04 - val_loss: 3.2577e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.3036e-04 - val_loss: 3.0993e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.8201e-04 - val_loss: 2.9365e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.7119e-04 - val_loss: 3.0820e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5608e-04 - val_loss: 2.9204e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.4524e-04 - val_loss: 3.1118e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5875e-04 - val_loss: 7.7716e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.3256e-04 - val_loss: 3.2559e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.4591e-04 - val_loss: 3.0242e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8792e-04 - val_loss: 3.5275e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8084e-04 - val_loss: 5.9086e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.8126e-04 - val_loss: 3.6690e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.8358e-04 - val_loss: 3.5455e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.5376e-04 - val_loss: 3.3425e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5845e-04 - val_loss: 3.0447e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.5036e-04 - val_loss: 3.0804e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.7448e-04 - val_loss: 2.9800e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 3.8117e-04 - val_loss: 2.9043e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.4385e-04 - val_loss: 3.0920e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.6292e-04 - val_loss: 3.5087e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 3.5520e-04 - val_loss: 3.0367e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4655e-04 - val_loss: 3.2119e-04\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.4782e-04 - val_loss: 3.3196e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.3178e-04 - val_loss: 2.9097e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.7963e-04 - val_loss: 4.0657e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 5.5407e-04 - val_loss: 5.0397e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.0279e-04 - val_loss: 2.9613e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.5467e-04 - val_loss: 3.1164e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.5471e-04 - val_loss: 3.3831e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 3.6383e-04 - val_loss: 3.2278e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.4218e-04 - val_loss: 2.9185e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.6627e-04 - val_loss: 4.2029e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.7292e-04 - val_loss: 3.0389e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.5775e-04 - val_loss: 3.3538e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.6440e-04 - val_loss: 3.0581e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.4996e-04 - val_loss: 2.9840e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.0714e-04 - val_loss: 3.3824e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.7816e-04 - val_loss: 4.4514e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.6347e-04 - val_loss: 3.0359e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8830e-04 - val_loss: 7.1870e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 5.1492e-04 - val_loss: 4.8198e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.1918e-04 - val_loss: 2.9601e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.4811e-04 - val_loss: 2.9693e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.3362e-04 - val_loss: 3.1713e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.4109e-04 - val_loss: 2.9304e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.4881e-04 - val_loss: 2.9571e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.6781e-04 - val_loss: 3.6532e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.5119e-04 - val_loss: 4.3683e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 3s 65ms/step - loss: 0.1695 - val_loss: 0.0808\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0040\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0021\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 5s 112ms/step - loss: 0.0334 - val_loss: 0.0212\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0013 - val_loss: 8.9054e-04\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0012 - val_loss: 8.8463e-04\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 8.1936e-04\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0011 - val_loss: 7.8978e-04\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0010 - val_loss: 7.3218e-04\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0010 - val_loss: 7.1790e-04\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 9.7549e-04 - val_loss: 7.1030e-04\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 9.6520e-04 - val_loss: 7.3206e-04\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 9.5616e-04 - val_loss: 6.6145e-04\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 9.1380e-04 - val_loss: 6.4969e-04\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 8.9810e-04 - val_loss: 6.5808e-04\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 9.1714e-04 - val_loss: 6.6240e-04\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 8.8764e-04 - val_loss: 6.5608e-04\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 8.8417e-04 - val_loss: 6.3083e-04\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 8.5842e-04 - val_loss: 6.0839e-04\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 8.3857e-04 - val_loss: 6.1030e-04\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 8.3620e-04 - val_loss: 6.3458e-04\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 8.2130e-04 - val_loss: 6.0390e-04\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 8.0514e-04 - val_loss: 5.8586e-04\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.9216e-04 - val_loss: 5.6917e-04\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 7.7987e-04 - val_loss: 5.6950e-04\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 7.7152e-04 - val_loss: 5.5786e-04\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 7.6280e-04 - val_loss: 5.5077e-04\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.5368e-04 - val_loss: 5.4908e-04\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 7.4648e-04 - val_loss: 5.8527e-04\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.4011e-04 - val_loss: 5.4425e-04\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.3177e-04 - val_loss: 5.4631e-04\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 7.1392e-04 - val_loss: 5.2030e-04\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.0974e-04 - val_loss: 6.0163e-04\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.2679e-04 - val_loss: 5.8541e-04\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.1194e-04 - val_loss: 5.2157e-04\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 6.9109e-04 - val_loss: 5.1644e-04\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 6.8132e-04 - val_loss: 5.1089e-04\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 6.6607e-04 - val_loss: 4.9574e-04\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.7076e-04 - val_loss: 5.0617e-04\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.6723e-04 - val_loss: 4.8669e-04\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.5201e-04 - val_loss: 5.3067e-04\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.5297e-04 - val_loss: 5.3127e-04\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 6.4660e-04 - val_loss: 5.1840e-04\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 6.4311e-04 - val_loss: 4.9555e-04\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.2773e-04 - val_loss: 4.6457e-04\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.3714e-04 - val_loss: 4.5959e-04\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.1529e-04 - val_loss: 4.6057e-04\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.0769e-04 - val_loss: 4.6093e-04\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.9945e-04 - val_loss: 4.5008e-04\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.9301e-04 - val_loss: 4.4578e-04\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.8747e-04 - val_loss: 4.4480e-04\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.8094e-04 - val_loss: 4.3943e-04\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 5.7619e-04 - val_loss: 4.4630e-04\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.8620e-04 - val_loss: 4.7109e-04\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.8309e-04 - val_loss: 4.8173e-04\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.8956e-04 - val_loss: 5.4907e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.5950e-04 - val_loss: 4.3557e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.5128e-04 - val_loss: 4.1984e-04\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.4577e-04 - val_loss: 4.1765e-04\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.5113e-04 - val_loss: 4.1783e-04\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.5148e-04 - val_loss: 4.1528e-04\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.4693e-04 - val_loss: 4.0838e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2599e-04 - val_loss: 4.1345e-04\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.2927e-04 - val_loss: 4.4142e-04\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2493e-04 - val_loss: 4.2507e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.3702e-04 - val_loss: 4.4291e-04\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2407e-04 - val_loss: 4.0353e-04\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2248e-04 - val_loss: 3.9479e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.0272e-04 - val_loss: 3.9180e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.9894e-04 - val_loss: 3.9045e-04\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.9231e-04 - val_loss: 3.8974e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 4.9045e-04 - val_loss: 3.8506e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.9007e-04 - val_loss: 3.9715e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.9579e-04 - val_loss: 3.8044e-04\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.8906e-04 - val_loss: 3.9501e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.8699e-04 - val_loss: 3.8885e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.7428e-04 - val_loss: 3.9794e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.7112e-04 - val_loss: 3.7778e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.6657e-04 - val_loss: 4.4323e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.7713e-04 - val_loss: 4.3729e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.8132e-04 - val_loss: 3.6913e-04\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.5991e-04 - val_loss: 3.7009e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.6908e-04 - val_loss: 3.7227e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 4.4914e-04 - val_loss: 3.5932e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.4825e-04 - val_loss: 3.5976e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.5613e-04 - val_loss: 3.5665e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.4337e-04 - val_loss: 3.5755e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.3808e-04 - val_loss: 3.5598e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.3633e-04 - val_loss: 3.5984e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.4337e-04 - val_loss: 3.5193e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.2780e-04 - val_loss: 3.4737e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.2748e-04 - val_loss: 3.5302e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.4253e-04 - val_loss: 3.4378e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.2474e-04 - val_loss: 3.9532e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.3306e-04 - val_loss: 3.5500e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.2124e-04 - val_loss: 3.3979e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.2317e-04 - val_loss: 3.4681e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.1756e-04 - val_loss: 3.3773e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.1170e-04 - val_loss: 3.3576e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.2615e-04 - val_loss: 3.6861e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.0757e-04 - val_loss: 3.3579e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9972e-04 - val_loss: 3.3358e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.1744e-04 - val_loss: 3.6810e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.2420e-04 - val_loss: 3.3961e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9765e-04 - val_loss: 3.3068e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.1243e-04 - val_loss: 3.4143e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.0287e-04 - val_loss: 3.5583e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9816e-04 - val_loss: 3.3549e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.1268e-04 - val_loss: 3.7597e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9966e-04 - val_loss: 3.7107e-04\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9234e-04 - val_loss: 3.2895e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9694e-04 - val_loss: 3.6460e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.8875e-04 - val_loss: 3.9100e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9429e-04 - val_loss: 3.2231e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.9410e-04 - val_loss: 3.1820e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.8495e-04 - val_loss: 3.2432e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.7505e-04 - val_loss: 3.2631e-04\n",
      "Epoch 120/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 44ms/step - loss: 3.9184e-04 - val_loss: 3.2442e-04\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.0140e-04 - val_loss: 3.2055e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.8801e-04 - val_loss: 3.1656e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9794e-04 - val_loss: 3.3166e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.7359e-04 - val_loss: 3.2233e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.6908e-04 - val_loss: 3.3143e-04\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.6223e-04 - val_loss: 3.5333e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.7998e-04 - val_loss: 3.1528e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.9155e-04 - val_loss: 3.5203e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.5732e-04 - val_loss: 3.2834e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.7597e-04 - val_loss: 3.2271e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.7248e-04 - val_loss: 3.4186e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.7103e-04 - val_loss: 3.0947e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.7628e-04 - val_loss: 3.0720e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.5999e-04 - val_loss: 3.1104e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.5936e-04 - val_loss: 3.0850e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.6001e-04 - val_loss: 3.1682e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.6983e-04 - val_loss: 3.4363e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.6486e-04 - val_loss: 3.5249e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.6929e-04 - val_loss: 3.2936e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5534e-04 - val_loss: 3.1141e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5113e-04 - val_loss: 3.2217e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.7791e-04 - val_loss: 3.3832e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.8408e-04 - val_loss: 3.0217e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.7968e-04 - val_loss: 3.0256e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.0490e-04 - val_loss: 3.0425e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.6790e-04 - val_loss: 3.1950e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.5663e-04 - val_loss: 3.2600e-04\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5934e-04 - val_loss: 3.1362e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.8326e-04 - val_loss: 2.9827e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5470e-04 - val_loss: 3.1222e-04\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.5140e-04 - val_loss: 3.0513e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.7641e-04 - val_loss: 3.4459e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 4.0131e-04 - val_loss: 3.4342e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.5588e-04 - val_loss: 3.1939e-04\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.8628e-04 - val_loss: 4.4769e-04\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.9990e-04 - val_loss: 3.5970e-04\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.5907e-04 - val_loss: 3.0202e-04\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.4233e-04 - val_loss: 3.2893e-04\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.4534e-04 - val_loss: 3.0085e-04\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.7828e-04 - val_loss: 2.9698e-04\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.4521e-04 - val_loss: 3.0633e-04\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.5168e-04 - val_loss: 2.9603e-04\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.7626e-04 - val_loss: 3.0678e-04\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.4593e-04 - val_loss: 3.1283e-04\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.6100e-04 - val_loss: 3.1653e-04\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.5893e-04 - val_loss: 3.0382e-04\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.3791e-04 - val_loss: 3.0091e-04\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.7902e-04 - val_loss: 3.0174e-04\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.6710e-04 - val_loss: 3.1838e-04\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.5262e-04 - val_loss: 4.5233e-04\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.6152e-04 - val_loss: 3.1604e-04\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.3820e-04 - val_loss: 2.9660e-04\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.3403e-04 - val_loss: 3.0281e-04\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.5022e-04 - val_loss: 2.9334e-04\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.5286e-04 - val_loss: 3.6032e-04\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.6513e-04 - val_loss: 3.0376e-04\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.9929e-04 - val_loss: 3.0404e-04\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.8793e-04 - val_loss: 3.0874e-04\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 3.4700e-04 - val_loss: 4.1283e-04\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.8378e-04 - val_loss: 3.1968e-04\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 3.4311e-04 - val_loss: 3.0095e-04\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.9352e-04 - val_loss: 3.1192e-04\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.6916e-04 - val_loss: 3.0190e-04\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.6191e-04 - val_loss: 2.9082e-04\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.4583e-04 - val_loss: 3.3869e-04\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.4762e-04 - val_loss: 3.0502e-04\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 3.4303e-04 - val_loss: 3.0717e-04\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 3.6760e-04 - val_loss: 3.1629e-04\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.7488e-04 - val_loss: 3.5163e-04\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.7931e-04 - val_loss: 3.0671e-04\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.3728e-04 - val_loss: 3.0278e-04\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.3483e-04 - val_loss: 2.9516e-04\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.4217e-04 - val_loss: 2.9126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.3366e-04 - val_loss: 2.8903e-04\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.3075e-04 - val_loss: 2.8987e-04\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.3059e-04 - val_loss: 4.1621e-04\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.8893e-04 - val_loss: 6.1614e-04\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.4833e-04 - val_loss: 3.9896e-04\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.9908e-04 - val_loss: 3.1148e-04\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.3220e-04 - val_loss: 2.9378e-04\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.9078e-04 - val_loss: 3.0252e-04\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.6991e-04 - val_loss: 2.8890e-04\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.8910e-04 - val_loss: 3.3021e-04\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.5453e-04 - val_loss: 2.9952e-04\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.3998e-04 - val_loss: 2.9420e-04\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.3153e-04 - val_loss: 3.5136e-04\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.7014e-04 - val_loss: 3.9968e-04\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.4920e-04 - val_loss: 5.7911e-04\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.9531e-04 - val_loss: 3.2715e-04\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.5704e-04 - val_loss: 3.6690e-04\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.3697e-04 - val_loss: 2.9053e-04\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.3147e-04 - val_loss: 2.8939e-04\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.2288e-04 - val_loss: 2.9049e-04\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.2661e-04 - val_loss: 3.6341e-04\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.4391e-04 - val_loss: 3.0360e-04\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 3.2324e-04 - val_loss: 3.0735e-04\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.5357e-04 - val_loss: 3.6509e-04\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.4473e-04 - val_loss: 2.9097e-04\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.2658e-04 - val_loss: 3.1955e-04\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.3829e-04 - val_loss: 2.9224e-04\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 3.4375e-04 - val_loss: 2.9458e-04\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.6152e-04 - val_loss: 2.9780e-04\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.3536e-04 - val_loss: 3.3268e-04\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.3729e-04 - val_loss: 3.4735e-04\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.3946e-04 - val_loss: 2.9261e-04\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.4775e-04 - val_loss: 3.0205e-04\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.5383e-04 - val_loss: 3.3671e-04\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.7053e-04 - val_loss: 3.3322e-04\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.3476e-04 - val_loss: 2.9333e-04\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.1984e-04 - val_loss: 2.9565e-04\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 3.3452e-04 - val_loss: 2.8968e-04\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.2582e-04 - val_loss: 2.9616e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 7s 152ms/step - loss: 0.0406 - val_loss: 0.0068\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0064 - val_loss: 0.0021\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0019 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0015 - val_loss: 9.5973e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0015 - val_loss: 9.2802e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0015 - val_loss: 9.5529e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0017 - val_loss: 8.8558e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0014 - val_loss: 9.4297e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0014 - val_loss: 8.9143e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0014 - val_loss: 8.8433e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0013 - val_loss: 8.2704e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0013 - val_loss: 9.9511e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0014 - val_loss: 9.6653e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0012 - val_loss: 7.9085e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0013 - val_loss: 7.6632e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0012 - val_loss: 9.5370e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 7.8460e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 9.0895e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 8.1026e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.0012 - val_loss: 7.0256e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 7.2251e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 6.9059e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0011 - val_loss: 7.3352e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0011 - val_loss: 6.8063e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0011 - val_loss: 7.0144e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 9.0780e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0011 - val_loss: 7.4025e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0011 - val_loss: 6.7008e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 7.1856e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0011 - val_loss: 7.0497e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 8.8840e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 7.3413e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.0013 - val_loss: 8.3715e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 8.1576e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 9.8634e-04 - val_loss: 9.9499e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 9.8671e-04 - val_loss: 0.0015\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 6.8678e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 9.9305e-04 - val_loss: 6.2863e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 9.6122e-04 - val_loss: 6.4073e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0010 - val_loss: 6.0914e-04\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 8.8249e-04 - val_loss: 6.8235e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 9.0553e-04 - val_loss: 5.8365e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0010 - val_loss: 7.0053e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 9.2333e-04 - val_loss: 6.8145e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 8.5251e-04 - val_loss: 9.6274e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 9.1556e-04 - val_loss: 0.0013\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 9.3726e-04 - val_loss: 5.7078e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 8.6942e-04 - val_loss: 5.4620e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 8.3995e-04 - val_loss: 5.4583e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 8.0633e-04 - val_loss: 5.9082e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 8.2122e-04 - val_loss: 6.0975e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 8.8579e-04 - val_loss: 5.6410e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 7.9827e-04 - val_loss: 8.4566e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 8.9215e-04 - val_loss: 5.4348e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 8.4132e-04 - val_loss: 5.6873e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.4895e-04 - val_loss: 7.6374e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 8.1238e-04 - val_loss: 7.5214e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 8.1835e-04 - val_loss: 5.8097e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.9105e-04 - val_loss: 5.0995e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.3337e-04 - val_loss: 5.5472e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 7.7513e-04 - val_loss: 5.8318e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 7.2135e-04 - val_loss: 4.9300e-04\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 7.6331e-04 - val_loss: 5.4718e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 8.1945e-04 - val_loss: 5.5239e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 7.3331e-04 - val_loss: 5.5266e-04\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 7.1447e-04 - val_loss: 6.4188e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 7.6906e-04 - val_loss: 6.4012e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 9.4795e-04 - val_loss: 7.9603e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 9.3101e-04 - val_loss: 0.0024\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.0012 - val_loss: 5.1115e-04\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 7.6485e-04 - val_loss: 4.9471e-04\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 7.1286e-04 - val_loss: 8.5691e-04\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 7.0742e-04 - val_loss: 7.6582e-04\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 7.0900e-04 - val_loss: 4.9696e-04\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 6.7226e-04 - val_loss: 5.8816e-04\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 6.3271e-04 - val_loss: 5.9804e-04\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 6.3548e-04 - val_loss: 4.9592e-04\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 6.3641e-04 - val_loss: 4.6691e-04\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 6.5333e-04 - val_loss: 4.5297e-04\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 6.6127e-04 - val_loss: 4.4898e-04\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 6.6847e-04 - val_loss: 5.2651e-04\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 7.3140e-04 - val_loss: 4.7901e-04\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 5.9921e-04 - val_loss: 4.6640e-04\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 5.8023e-04 - val_loss: 4.4739e-04\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 6.2741e-04 - val_loss: 7.7462e-04\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 7.4508e-04 - val_loss: 0.0016\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 8.2176e-04 - val_loss: 0.0012\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 6.8437e-04 - val_loss: 6.8100e-04\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 5.5695e-04 - val_loss: 4.3300e-04\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 5.7935e-04 - val_loss: 4.8936e-04\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 5.8322e-04 - val_loss: 4.9703e-04\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 6.0087e-04 - val_loss: 5.2122e-04\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.4192e-04 - val_loss: 5.8069e-04\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 5.3016e-04 - val_loss: 5.5821e-04\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 6.0493e-04 - val_loss: 7.7830e-04\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.5367e-04 - val_loss: 4.3404e-04\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 5.3029e-04 - val_loss: 5.5524e-04\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 5.4144e-04 - val_loss: 4.0295e-04\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.0519e-04 - val_loss: 4.3463e-04\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.3624e-04 - val_loss: 4.0796e-04\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.1087e-04 - val_loss: 3.9513e-04\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 4.9736e-04 - val_loss: 3.9920e-04\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 5.4115e-04 - val_loss: 4.7127e-04\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 5.1983e-04 - val_loss: 4.3100e-04\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 5.0237e-04 - val_loss: 5.7749e-04\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 5.8027e-04 - val_loss: 4.9854e-04\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.7510e-04 - val_loss: 5.6608e-04\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.8189e-04 - val_loss: 3.7770e-04\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 5.5609e-04 - val_loss: 5.6949e-04\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.6056e-04 - val_loss: 3.8794e-04\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.5147e-04 - val_loss: 3.9273e-04\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.5914e-04 - val_loss: 3.7476e-04\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 4.5174e-04 - val_loss: 4.0383e-04\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.7288e-04 - val_loss: 4.5880e-04\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.7396e-04 - val_loss: 4.5822e-04\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.3086e-04 - val_loss: 5.9669e-04\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 5.9117e-04 - val_loss: 4.3222e-04\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 4.5118e-04 - val_loss: 3.6981e-04\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 4.9319e-04 - val_loss: 3.7469e-04\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 4.3199e-04 - val_loss: 3.8815e-04\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 4.1988e-04 - val_loss: 3.6236e-04\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 4.5837e-04 - val_loss: 3.6884e-04\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 4.2000e-04 - val_loss: 3.7896e-04\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.5726e-04 - val_loss: 4.9193e-04\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.5307e-04 - val_loss: 3.5328e-04\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.9754e-04 - val_loss: 3.4884e-04\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 5.8337e-04 - val_loss: 9.9365e-04\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 5.6617e-04 - val_loss: 3.8679e-04\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.6807e-04 - val_loss: 4.7294e-04\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 5.0568e-04 - val_loss: 4.7732e-04\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.3330e-04 - val_loss: 3.5708e-04\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.1890e-04 - val_loss: 3.7950e-04\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 3.9459e-04 - val_loss: 5.2818e-04\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.4571e-04 - val_loss: 3.4370e-04\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.6737e-04 - val_loss: 3.9837e-04\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.4108e-04 - val_loss: 3.4438e-04\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.0852e-04 - val_loss: 5.8673e-04\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.8033e-04 - val_loss: 4.9454e-04\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.4019e-04 - val_loss: 5.8919e-04\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 5.3319e-04 - val_loss: 4.4936e-04\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 5.2168e-04 - val_loss: 9.8786e-04\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 5.1718e-04 - val_loss: 4.4649e-04\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.6270e-04 - val_loss: 5.1356e-04\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.3720e-04 - val_loss: 3.7275e-04\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 3.9731e-04 - val_loss: 3.5362e-04\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.2708e-04 - val_loss: 3.8156e-04\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 3.8465e-04 - val_loss: 3.2624e-04\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 3.6993e-04 - val_loss: 3.5672e-04\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.4005e-04 - val_loss: 7.8812e-04\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 4.6208e-04 - val_loss: 3.3077e-04\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 3.7642e-04 - val_loss: 3.4590e-04\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 5.0704e-04 - val_loss: 3.1555e-04\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 5.4436e-04 - val_loss: 3.1668e-04\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 3.8973e-04 - val_loss: 3.3229e-04\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 4.3023e-04 - val_loss: 4.0852e-04\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 3.9608e-04 - val_loss: 3.5023e-04\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 3.8594e-04 - val_loss: 3.4307e-04\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 3.9575e-04 - val_loss: 3.2361e-04\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 3.9008e-04 - val_loss: 3.8557e-04\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 4.0447e-04 - val_loss: 3.4582e-04\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 4.8197e-04 - val_loss: 6.0166e-04\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 6.3521e-04 - val_loss: 7.5019e-04\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 6.1495e-04 - val_loss: 4.2799e-04\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 3.7179e-04 - val_loss: 3.7781e-04\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 3.5795e-04 - val_loss: 3.2471e-04\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.3737e-04 - val_loss: 3.1097e-04\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 4.0027e-04 - val_loss: 3.7455e-04\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 3.8255e-04 - val_loss: 3.1373e-04\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.4960e-04 - val_loss: 3.0753e-04\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.0788e-04 - val_loss: 3.2520e-04\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.3628e-04 - val_loss: 5.4156e-04\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.8071e-04 - val_loss: 5.8963e-04\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.9689e-04 - val_loss: 5.2798e-04\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.9456e-04 - val_loss: 4.8398e-04\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.3157e-04 - val_loss: 3.8956e-04\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.4907e-04 - val_loss: 3.1726e-04\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.5897e-04 - val_loss: 3.0755e-04\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.5758e-04 - val_loss: 3.4648e-04\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.8364e-04 - val_loss: 3.3856e-04\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.6710e-04 - val_loss: 3.0587e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.4878e-04 - val_loss: 3.7370e-04\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.8964e-04 - val_loss: 3.2856e-04\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.6772e-04 - val_loss: 3.0338e-04\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.5140e-04 - val_loss: 3.2062e-04\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.0353e-04 - val_loss: 3.0342e-04\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.6160e-04 - val_loss: 3.0037e-04\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.8406e-04 - val_loss: 3.0530e-04\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.5152e-04 - val_loss: 8.2205e-04\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 4.1224e-04 - val_loss: 3.0036e-04\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.6326e-04 - val_loss: 2.9550e-04\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.6190e-04 - val_loss: 3.0539e-04\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.9233e-04 - val_loss: 3.9358e-04\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.8441e-04 - val_loss: 4.3636e-04\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.9707e-04 - val_loss: 3.3168e-04\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.6505e-04 - val_loss: 3.1459e-04\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 3.5707e-04 - val_loss: 3.2243e-04\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.4464e-04 - val_loss: 3.1051e-04\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.3675e-04 - val_loss: 3.1592e-04\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 4.5497e-04 - val_loss: 3.1123e-04\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.8783e-04 - val_loss: 3.6465e-04\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 3.4179e-04 - val_loss: 3.5184e-04\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.7056e-04 - val_loss: 3.0540e-04\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 3.3882e-04 - val_loss: 5.0779e-04\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.9535e-04 - val_loss: 3.5783e-04\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.7471e-04 - val_loss: 4.3044e-04\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.5921e-04 - val_loss: 3.6836e-04\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.9526e-04 - val_loss: 3.0845e-04\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.5396e-04 - val_loss: 3.0054e-04\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.9292e-04 - val_loss: 3.2968e-04\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 3.6915e-04 - val_loss: 3.8723e-04\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.8046e-04 - val_loss: 3.1921e-04\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.6264e-04 - val_loss: 4.4982e-04\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 4.7641e-04 - val_loss: 2.9948e-04\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 3.4180e-04 - val_loss: 3.0668e-04\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.5218e-04 - val_loss: 2.9961e-04\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.5711e-04 - val_loss: 4.2024e-04\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 4.1579e-04 - val_loss: 2.9658e-04\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.5461e-04 - val_loss: 5.6162e-04\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.7276e-04 - val_loss: 7.4467e-04\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 5.0846e-04 - val_loss: 4.1979e-04\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 3s 114ms/step - loss: 0.0598 - val_loss: 0.0201\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0286 - val_loss: 0.0053\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0027\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0068\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 5s 249ms/step - loss: 0.0784 - val_loss: 0.0081\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.0192 - val_loss: 0.0119\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0013 - val_loss: 9.7986e-04\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0013 - val_loss: 9.1158e-04\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0013 - val_loss: 9.2635e-04\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.0012 - val_loss: 8.9592e-04\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0012 - val_loss: 8.3345e-04\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0012 - val_loss: 8.2625e-04\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.0012 - val_loss: 8.3156e-04\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0011 - val_loss: 7.8197e-04\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0011 - val_loss: 7.9724e-04\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0011 - val_loss: 7.5157e-04\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.0011 - val_loss: 7.4497e-04\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0011 - val_loss: 7.4793e-04\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0011 - val_loss: 7.2682e-04\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0010 - val_loss: 7.2026e-04\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0010 - val_loss: 7.1215e-04\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0010 - val_loss: 7.0604e-04\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 9.9820e-04 - val_loss: 6.9615e-04\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 9.8346e-04 - val_loss: 6.9699e-04\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 9.7987e-04 - val_loss: 6.9882e-04\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 9.7137e-04 - val_loss: 6.7866e-04\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 9.5962e-04 - val_loss: 6.8925e-04\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 9.4724e-04 - val_loss: 6.7460e-04\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 9.3710e-04 - val_loss: 6.7607e-04\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 9.2848e-04 - val_loss: 6.7669e-04\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 9.2143e-04 - val_loss: 6.7321e-04\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 9.1397e-04 - val_loss: 6.6307e-04\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 9.0766e-04 - val_loss: 6.6941e-04\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 8.9861e-04 - val_loss: 6.5412e-04\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 8.9271e-04 - val_loss: 6.5711e-04\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 8.8762e-04 - val_loss: 6.5236e-04\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 8.8225e-04 - val_loss: 6.6745e-04\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 8.7142e-04 - val_loss: 6.3574e-04\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 8.6784e-04 - val_loss: 6.5859e-04\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.6038e-04 - val_loss: 6.4158e-04\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.5437e-04 - val_loss: 6.4405e-04\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.5127e-04 - val_loss: 6.4547e-04\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.4289e-04 - val_loss: 6.2066e-04\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.3764e-04 - val_loss: 6.5343e-04\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 8.3399e-04 - val_loss: 6.2666e-04\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.2588e-04 - val_loss: 6.4775e-04\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.2157e-04 - val_loss: 6.1689e-04\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.1895e-04 - val_loss: 6.4466e-04\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 8.1763e-04 - val_loss: 6.0013e-04\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 8.1088e-04 - val_loss: 6.4947e-04\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 8.0851e-04 - val_loss: 5.9677e-04\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.9395e-04 - val_loss: 6.5320e-04\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.9332e-04 - val_loss: 5.9983e-04\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.8588e-04 - val_loss: 6.2703e-04\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.8083e-04 - val_loss: 6.0515e-04\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.7472e-04 - val_loss: 5.9817e-04\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.7149e-04 - val_loss: 5.9572e-04\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.6749e-04 - val_loss: 6.1497e-04\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 7.6259e-04 - val_loss: 5.7979e-04\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.5813e-04 - val_loss: 6.0710e-04\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 7.5840e-04 - val_loss: 5.8580e-04\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 7.4880e-04 - val_loss: 5.9722e-04\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.4654e-04 - val_loss: 5.8189e-04\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.3857e-04 - val_loss: 5.6783e-04\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.3258e-04 - val_loss: 5.7993e-04\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 7.3410e-04 - val_loss: 5.6830e-04\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 7.2955e-04 - val_loss: 5.5510e-04\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 7.2389e-04 - val_loss: 5.7739e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.1540e-04 - val_loss: 5.5050e-04\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.1165e-04 - val_loss: 5.6967e-04\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.0699e-04 - val_loss: 5.4364e-04\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.0357e-04 - val_loss: 5.5170e-04\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 6.9726e-04 - val_loss: 5.6524e-04\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.9385e-04 - val_loss: 5.3873e-04\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 6.9022e-04 - val_loss: 5.4071e-04\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.8701e-04 - val_loss: 5.3517e-04\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.8207e-04 - val_loss: 5.2556e-04\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.7781e-04 - val_loss: 5.4740e-04\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.7597e-04 - val_loss: 5.2625e-04\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.7201e-04 - val_loss: 5.4216e-04\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 6.6740e-04 - val_loss: 5.3052e-04\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.6270e-04 - val_loss: 5.3613e-04\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 6.6179e-04 - val_loss: 5.0223e-04\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.5691e-04 - val_loss: 5.3067e-04\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.6056e-04 - val_loss: 5.0388e-04\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 6.5626e-04 - val_loss: 5.2647e-04\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 6.4700e-04 - val_loss: 4.9839e-04\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 6.5112e-04 - val_loss: 5.3242e-04\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 6.4200e-04 - val_loss: 5.1444e-04\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 6.3811e-04 - val_loss: 5.0958e-04\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 6.3110e-04 - val_loss: 5.0424e-04\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 6.2614e-04 - val_loss: 4.8153e-04\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 6.2824e-04 - val_loss: 5.1101e-04\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 6.2337e-04 - val_loss: 4.9255e-04\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 6.3099e-04 - val_loss: 4.8315e-04\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 6.2216e-04 - val_loss: 4.8954e-04\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 6.1115e-04 - val_loss: 4.9902e-04\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 6.1426e-04 - val_loss: 4.7298e-04\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 6.0472e-04 - val_loss: 4.6783e-04\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 6.0282e-04 - val_loss: 4.7273e-04\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 5.9692e-04 - val_loss: 4.7215e-04\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.9474e-04 - val_loss: 4.6960e-04\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.8972e-04 - val_loss: 4.7257e-04\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.8617e-04 - val_loss: 4.6546e-04\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.8320e-04 - val_loss: 4.6224e-04\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.8126e-04 - val_loss: 4.6183e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.8129e-04 - val_loss: 4.9974e-04\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.7571e-04 - val_loss: 4.4898e-04\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.7471e-04 - val_loss: 4.9969e-04\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.7414e-04 - val_loss: 4.3493e-04\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.7052e-04 - val_loss: 4.8431e-04\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 5.6949e-04 - val_loss: 4.4137e-04\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.5881e-04 - val_loss: 4.5383e-04\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.5702e-04 - val_loss: 4.4014e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.5280e-04 - val_loss: 4.4530e-04\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.4857e-04 - val_loss: 4.4782e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 5.4796e-04 - val_loss: 4.4706e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.4977e-04 - val_loss: 4.3967e-04\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.5256e-04 - val_loss: 4.2645e-04\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.4117e-04 - val_loss: 4.3300e-04\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 5.3751e-04 - val_loss: 4.2733e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.3267e-04 - val_loss: 4.2849e-04\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.3075e-04 - val_loss: 4.2948e-04\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.3191e-04 - val_loss: 4.1208e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.3189e-04 - val_loss: 4.1293e-04\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.4515e-04 - val_loss: 4.5491e-04\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 5.2298e-04 - val_loss: 4.1672e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.2241e-04 - val_loss: 4.1940e-04\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.1546e-04 - val_loss: 4.1721e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.1228e-04 - val_loss: 4.0988e-04\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 5.1134e-04 - val_loss: 4.1066e-04\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 5.0729e-04 - val_loss: 4.1397e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.0459e-04 - val_loss: 4.0313e-04\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.0231e-04 - val_loss: 4.1329e-04\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.0198e-04 - val_loss: 4.0595e-04\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 4.9844e-04 - val_loss: 3.9473e-04\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 4.9663e-04 - val_loss: 4.1322e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.9496e-04 - val_loss: 4.0088e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.9264e-04 - val_loss: 3.9579e-04\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.9379e-04 - val_loss: 4.1643e-04\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 4.8823e-04 - val_loss: 3.8417e-04\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.8470e-04 - val_loss: 4.1357e-04\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.8488e-04 - val_loss: 3.8222e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 4.8089e-04 - val_loss: 4.1723e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.8113e-04 - val_loss: 3.7993e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.7589e-04 - val_loss: 3.9982e-04\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.8132e-04 - val_loss: 3.7556e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.7709e-04 - val_loss: 3.7823e-04\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.7323e-04 - val_loss: 4.0754e-04\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.8313e-04 - val_loss: 3.7154e-04\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.7089e-04 - val_loss: 3.9171e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.6221e-04 - val_loss: 3.7181e-04\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.6624e-04 - val_loss: 3.7286e-04\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.6200e-04 - val_loss: 3.7401e-04\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 4.5703e-04 - val_loss: 3.8136e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 4.5572e-04 - val_loss: 3.6586e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.5499e-04 - val_loss: 3.8304e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 4.5403e-04 - val_loss: 3.6314e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.5169e-04 - val_loss: 3.9296e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.6042e-04 - val_loss: 3.7351e-04\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 4.4879e-04 - val_loss: 3.6290e-04\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 4.4500e-04 - val_loss: 4.0360e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.5848e-04 - val_loss: 3.5898e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 4.5426e-04 - val_loss: 3.7020e-04\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.4477e-04 - val_loss: 3.8796e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 4.4313e-04 - val_loss: 3.5587e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.4203e-04 - val_loss: 3.6399e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.3538e-04 - val_loss: 3.6298e-04\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.3375e-04 - val_loss: 3.5400e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.3481e-04 - val_loss: 3.5404e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.3270e-04 - val_loss: 3.6835e-04\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.2841e-04 - val_loss: 3.4985e-04\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.3510e-04 - val_loss: 3.6395e-04\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.3524e-04 - val_loss: 4.0451e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.3830e-04 - val_loss: 3.4778e-04\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.2864e-04 - val_loss: 3.5300e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.2338e-04 - val_loss: 3.4645e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.2206e-04 - val_loss: 3.7141e-04\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.2359e-04 - val_loss: 3.6165e-04\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.2842e-04 - val_loss: 3.5128e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.2292e-04 - val_loss: 3.4689e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1745e-04 - val_loss: 3.4819e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1895e-04 - val_loss: 3.9555e-04\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.3495e-04 - val_loss: 3.5760e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 4.1863e-04 - val_loss: 3.4037e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.1191e-04 - val_loss: 3.3912e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1053e-04 - val_loss: 3.6987e-04\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 4.1133e-04 - val_loss: 3.3880e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1077e-04 - val_loss: 3.3672e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.1096e-04 - val_loss: 3.3819e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 4.0404e-04 - val_loss: 3.3607e-04\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.1312e-04 - val_loss: 3.6033e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.0680e-04 - val_loss: 3.7619e-04\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.1927e-04 - val_loss: 3.3983e-04\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.0825e-04 - val_loss: 3.3420e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.1306e-04 - val_loss: 3.5020e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.0116e-04 - val_loss: 3.3390e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.9684e-04 - val_loss: 3.4275e-04\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.9663e-04 - val_loss: 3.3473e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.0203e-04 - val_loss: 3.2990e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.9582e-04 - val_loss: 3.3754e-04\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.9210e-04 - val_loss: 3.3039e-04\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.9239e-04 - val_loss: 3.2840e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.8962e-04 - val_loss: 3.3058e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.9225e-04 - val_loss: 3.4279e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.8740e-04 - val_loss: 3.2786e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.9044e-04 - val_loss: 3.2805e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.9300e-04 - val_loss: 3.2586e-04\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.9052e-04 - val_loss: 3.3329e-04\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.8898e-04 - val_loss: 3.2564e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.8380e-04 - val_loss: 3.5053e-04\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.8438e-04 - val_loss: 3.3026e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.9735e-04 - val_loss: 3.2822e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.9796e-04 - val_loss: 3.4293e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.8474e-04 - val_loss: 3.3334e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.8071e-04 - val_loss: 3.2360e-04\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.7659e-04 - val_loss: 3.2583e-04\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.7797e-04 - val_loss: 3.2622e-04\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 83ms/step - loss: 3.9221e-04 - val_loss: 3.2154e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.1012e-04 - val_loss: 4.0404e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.9950e-04 - val_loss: 3.5273e-04\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.7493e-04 - val_loss: 3.3392e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.8772e-04 - val_loss: 3.3359e-04\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.8284e-04 - val_loss: 3.3389e-04\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7604e-04 - val_loss: 3.4851e-04\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7549e-04 - val_loss: 3.2687e-04\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7524e-04 - val_loss: 3.1787e-04\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7499e-04 - val_loss: 3.2814e-04\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.7958e-04 - val_loss: 3.2439e-04\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.8719e-04 - val_loss: 3.2104e-04\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7498e-04 - val_loss: 3.2137e-04\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.7867e-04 - val_loss: 3.2546e-04\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6970e-04 - val_loss: 3.4466e-04\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.8403e-04 - val_loss: 3.9283e-04\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.8657e-04 - val_loss: 3.7038e-04\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.9297e-04 - val_loss: 3.5450e-04\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.8678e-04 - val_loss: 3.1661e-04\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6980e-04 - val_loss: 3.1221e-04\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6752e-04 - val_loss: 3.4290e-04\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.6168e-04 - val_loss: 3.1870e-04\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6204e-04 - val_loss: 3.1220e-04\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.5954e-04 - val_loss: 3.4133e-04\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6045e-04 - val_loss: 3.1922e-04\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6571e-04 - val_loss: 3.3024e-04\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.6248e-04 - val_loss: 3.2311e-04\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6128e-04 - val_loss: 3.2599e-04\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6391e-04 - val_loss: 3.1910e-04\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.6619e-04 - val_loss: 3.1092e-04\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.6693e-04 - val_loss: 3.0987e-04\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.5838e-04 - val_loss: 3.1119e-04\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5653e-04 - val_loss: 3.1487e-04\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5939e-04 - val_loss: 3.2067e-04\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.6064e-04 - val_loss: 3.8336e-04\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.7496e-04 - val_loss: 3.2586e-04\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.6860e-04 - val_loss: 3.1607e-04\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.6299e-04 - val_loss: 3.3958e-04\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.1437e-04 - val_loss: 3.3346e-04\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.0199e-04 - val_loss: 3.1944e-04\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.7097e-04 - val_loss: 4.4538e-04\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.1529e-04 - val_loss: 3.4464e-04\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.9900e-04 - val_loss: 3.2672e-04\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.7018e-04 - val_loss: 3.1307e-04\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.5023e-04 - val_loss: 3.0424e-04\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.4786e-04 - val_loss: 3.0628e-04\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.4925e-04 - val_loss: 3.3083e-04\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.6939e-04 - val_loss: 3.5996e-04\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.8906e-04 - val_loss: 3.1021e-04\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.6526e-04 - val_loss: 3.0457e-04\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.6435e-04 - val_loss: 3.0341e-04\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.6623e-04 - val_loss: 3.0609e-04\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.4811e-04 - val_loss: 3.1646e-04\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.4640e-04 - val_loss: 3.0201e-04\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5811e-04 - val_loss: 3.0320e-04\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.6707e-04 - val_loss: 3.0333e-04\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7661e-04 - val_loss: 3.0283e-04\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.7415e-04 - val_loss: 3.2522e-04\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.6539e-04 - val_loss: 3.7656e-04\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5422e-04 - val_loss: 3.2110e-04\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.4505e-04 - val_loss: 3.0576e-04\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.4505e-04 - val_loss: 3.0871e-04\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4320e-04 - val_loss: 2.9912e-04\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.4113e-04 - val_loss: 3.0734e-04\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.3835e-04 - val_loss: 3.0257e-04\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.4201e-04 - val_loss: 3.0474e-04\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.5417e-04 - val_loss: 3.0653e-04\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.5243e-04 - val_loss: 3.1849e-04\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.6007e-04 - val_loss: 3.6618e-04\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.7134e-04 - val_loss: 3.3121e-04\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.5071e-04 - val_loss: 2.9821e-04\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.4147e-04 - val_loss: 2.9914e-04\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.3759e-04 - val_loss: 3.0690e-04\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.4710e-04 - val_loss: 3.0278e-04\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.4330e-04 - val_loss: 2.9990e-04\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5371e-04 - val_loss: 3.0604e-04\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5103e-04 - val_loss: 3.0212e-04\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5544e-04 - val_loss: 3.0805e-04\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5773e-04 - val_loss: 3.2072e-04\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.8576e-04 - val_loss: 2.9790e-04\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.5742e-04 - val_loss: 3.4996e-04\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.7557e-04 - val_loss: 4.0239e-04\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.9861e-04 - val_loss: 4.1250e-04\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.9007e-04 - val_loss: 3.3465e-04\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.5199e-04 - val_loss: 2.9695e-04\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3601e-04 - val_loss: 3.0642e-04\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 3.3287e-04 - val_loss: 2.9783e-04\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.4443e-04 - val_loss: 2.9530e-04\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3707e-04 - val_loss: 3.0979e-04\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3566e-04 - val_loss: 3.0762e-04\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3377e-04 - val_loss: 3.1379e-04\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.4019e-04 - val_loss: 2.9407e-04\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.6326e-04 - val_loss: 3.0025e-04\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4721e-04 - val_loss: 2.9469e-04\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3526e-04 - val_loss: 2.9571e-04\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4384e-04 - val_loss: 3.1064e-04\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3741e-04 - val_loss: 3.0398e-04\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4175e-04 - val_loss: 3.0264e-04\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 3.5600e-04 - val_loss: 3.1432e-04\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.5332e-04 - val_loss: 2.9486e-04\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.5793e-04 - val_loss: 2.9308e-04\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4149e-04 - val_loss: 3.0465e-04\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.4236e-04 - val_loss: 3.1304e-04\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3925e-04 - val_loss: 3.3072e-04\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.6408e-04 - val_loss: 3.4613e-04\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.7144e-04 - val_loss: 3.0011e-04\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.5175e-04 - val_loss: 2.9428e-04\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.3420e-04 - val_loss: 2.9770e-04\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.4200e-04 - val_loss: 3.1487e-04\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.4330e-04 - val_loss: 3.0552e-04\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.5322e-04 - val_loss: 3.0315e-04\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.5120e-04 - val_loss: 3.3396e-04\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.7565e-04 - val_loss: 3.4189e-04\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 3.7261e-04 - val_loss: 2.9361e-04\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.4084e-04 - val_loss: 2.9827e-04\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.3269e-04 - val_loss: 3.2832e-04\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.2886e-04 - val_loss: 3.1889e-04\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.3666e-04 - val_loss: 3.0267e-04\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.2626e-04 - val_loss: 3.2049e-04\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.3455e-04 - val_loss: 2.9353e-04\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.2371e-04 - val_loss: 2.9601e-04\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.2541e-04 - val_loss: 2.9235e-04\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.3582e-04 - val_loss: 2.9619e-04\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.2348e-04 - val_loss: 3.0273e-04\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.4583e-04 - val_loss: 3.0917e-04\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.5439e-04 - val_loss: 3.0159e-04\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.2704e-04 - val_loss: 3.0098e-04\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4068e-04 - val_loss: 2.9377e-04\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.4386e-04 - val_loss: 2.9079e-04\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.4223e-04 - val_loss: 3.1025e-04\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.3856e-04 - val_loss: 2.9562e-04\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.2496e-04 - val_loss: 2.9320e-04\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.3688e-04 - val_loss: 3.4761e-04\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.6156e-04 - val_loss: 3.2873e-04\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3312e-04 - val_loss: 3.1191e-04\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.2454e-04 - val_loss: 2.9879e-04\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.2808e-04 - val_loss: 3.2355e-04\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5033e-04 - val_loss: 3.2378e-04\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5468e-04 - val_loss: 3.3198e-04\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.8452e-04 - val_loss: 4.4534e-04\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.7382e-04 - val_loss: 2.9522e-04\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.5713e-04 - val_loss: 3.0118e-04\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.4890e-04 - val_loss: 2.9889e-04\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.2803e-04 - val_loss: 2.8953e-04\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.4088e-04 - val_loss: 3.4660e-04\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.4120e-04 - val_loss: 3.1202e-04\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4490e-04 - val_loss: 2.9167e-04\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.2118e-04 - val_loss: 3.1215e-04\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.3858e-04 - val_loss: 3.3732e-04\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.2627e-04 - val_loss: 3.1164e-04\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4100e-04 - val_loss: 2.8932e-04\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2597e-04 - val_loss: 2.9125e-04\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.2286e-04 - val_loss: 2.9927e-04\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3037e-04 - val_loss: 2.9073e-04\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.2024e-04 - val_loss: 2.8976e-04\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.1753e-04 - val_loss: 2.9195e-04\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2005e-04 - val_loss: 3.3465e-04\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2996e-04 - val_loss: 3.9667e-04\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5377e-04 - val_loss: 2.8997e-04\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.2979e-04 - val_loss: 3.0998e-04\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2617e-04 - val_loss: 2.9767e-04\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5058e-04 - val_loss: 2.9163e-04\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.1833e-04 - val_loss: 3.4059e-04\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5811e-04 - val_loss: 2.9136e-04\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.3227e-04 - val_loss: 3.7503e-04\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5413e-04 - val_loss: 2.9141e-04\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 3.2733e-04 - val_loss: 3.1834e-04\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 3.3254e-04 - val_loss: 3.2650e-04\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 3.3062e-04 - val_loss: 2.8992e-04\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 3.1953e-04 - val_loss: 2.9119e-04\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.2211e-04 - val_loss: 2.9256e-04\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.2556e-04 - val_loss: 2.9006e-04\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.3479e-04 - val_loss: 3.1153e-04\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.2196e-04 - val_loss: 2.9429e-04\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3515e-04 - val_loss: 3.0612e-04\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2711e-04 - val_loss: 3.2347e-04\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.2740e-04 - val_loss: 2.9158e-04\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3453e-04 - val_loss: 3.5307e-04\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.3961e-04 - val_loss: 2.9264e-04\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.2352e-04 - val_loss: 3.2008e-04\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.2960e-04 - val_loss: 3.3189e-04\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 7s 285ms/step - loss: 0.0550 - val_loss: 0.0043\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0021 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0015 - val_loss: 9.8491e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0016 - val_loss: 9.7422e-04\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0016 - val_loss: 9.6657e-04\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0016 - val_loss: 9.9704e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0015 - val_loss: 9.3437e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0015 - val_loss: 9.2560e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0015 - val_loss: 9.1747e-04\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0016 - val_loss: 9.4167e-04\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0015 - val_loss: 9.3868e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0014 - val_loss: 9.2498e-04\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0014 - val_loss: 8.9750e-04\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0014 - val_loss: 8.9123e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0014 - val_loss: 9.4582e-04\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0014 - val_loss: 9.3271e-04\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0014 - val_loss: 8.8158e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0013 - val_loss: 8.5807e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0013 - val_loss: 8.6331e-04\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0013 - val_loss: 9.3988e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0013 - val_loss: 8.5665e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0013 - val_loss: 8.1633e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0013 - val_loss: 8.0061e-04\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0014 - val_loss: 8.5187e-04\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0013 - val_loss: 9.1302e-04\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0012 - val_loss: 9.1598e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0013 - val_loss: 7.8000e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0013 - val_loss: 9.0165e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0012 - val_loss: 8.4986e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0013 - val_loss: 7.9347e-04\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0012 - val_loss: 7.6639e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 0.0013 - val_loss: 8.0287e-04\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0014 - val_loss: 7.5031e-04\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0012 - val_loss: 7.7872e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 8.2282e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 7.9933e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 7.3900e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0012 - val_loss: 8.1170e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 9.0327e-04\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0011 - val_loss: 9.3816e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0011 - val_loss: 6.9815e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0011 - val_loss: 6.9675e-04\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0012 - val_loss: 6.8892e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0011 - val_loss: 6.8711e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 7.5356e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0011 - val_loss: 9.3814e-04\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 0.0010 - val_loss: 6.8064e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0011 - val_loss: 6.9441e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0011 - val_loss: 6.7246e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0010 - val_loss: 7.6763e-04\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0010 - val_loss: 8.7984e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0010 - val_loss: 9.2339e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0010 - val_loss: 8.4699e-04\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0010 - val_loss: 6.8404e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0010 - val_loss: 6.7593e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 9.7189e-04 - val_loss: 6.3046e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0010 - val_loss: 9.4202e-04\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 9.5431e-04 - val_loss: 6.2725e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0010 - val_loss: 8.7302e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 9.4879e-04 - val_loss: 8.9052e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 9.3263e-04 - val_loss: 9.4787e-04\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0010 - val_loss: 8.8520e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 9.9345e-04 - val_loss: 6.1189e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0010 - val_loss: 7.3958e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 9.6691e-04 - val_loss: 0.0011\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 9.8375e-04 - val_loss: 6.0078e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0011 - val_loss: 6.0082e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 9.7249e-04 - val_loss: 8.6329e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 9.2396e-04 - val_loss: 6.2046e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 9.4333e-04 - val_loss: 7.4496e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 9.2049e-04 - val_loss: 0.0012\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0011 - val_loss: 6.2913e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0010 - val_loss: 5.8820e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0011 - val_loss: 5.7870e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 9.0814e-04 - val_loss: 6.3864e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.4984e-04 - val_loss: 7.4591e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 8.6347e-04 - val_loss: 5.7208e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 8.8254e-04 - val_loss: 6.6528e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 8.3373e-04 - val_loss: 0.0010\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 8.5829e-04 - val_loss: 7.2858e-04\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.3490e-04 - val_loss: 8.6820e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 8.7306e-04 - val_loss: 9.4430e-04\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 8.4267e-04 - val_loss: 5.5430e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.9495e-04 - val_loss: 5.6200e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 8.5934e-04 - val_loss: 8.5578e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.7534e-04 - val_loss: 6.3389e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 8.0508e-04 - val_loss: 6.4737e-04\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 8.0974e-04 - val_loss: 0.0012\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 8.5113e-04 - val_loss: 6.8011e-04\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 7.8900e-04 - val_loss: 5.6487e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 7.7170e-04 - val_loss: 5.7671e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 7.6731e-04 - val_loss: 7.6206e-04\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 7.9370e-04 - val_loss: 5.7340e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 8.1659e-04 - val_loss: 9.8989e-04\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 9.0558e-04 - val_loss: 7.6625e-04\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 9.7307e-04 - val_loss: 8.0729e-04\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0010 - val_loss: 7.5570e-04\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 8.0354e-04 - val_loss: 0.0016\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 9.8305e-04 - val_loss: 7.9656e-04\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 8.2301e-04 - val_loss: 5.3223e-04\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 7.9308e-04 - val_loss: 8.2249e-04\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 7.3431e-04 - val_loss: 7.5141e-04\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 7.3691e-04 - val_loss: 6.2570e-04\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 7.1148e-04 - val_loss: 6.0293e-04\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 7.3108e-04 - val_loss: 6.8235e-04\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 7.4015e-04 - val_loss: 5.1992e-04\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 7.8172e-04 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 8.2568e-04 - val_loss: 5.1840e-04\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 7.1117e-04 - val_loss: 8.1021e-04\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 7.5883e-04 - val_loss: 5.1746e-04\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 8.0786e-04 - val_loss: 7.1863e-04\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.8711e-04 - val_loss: 5.6008e-04\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 7.4628e-04 - val_loss: 5.8462e-04\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 7.8076e-04 - val_loss: 0.0012\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 7.7106e-04 - val_loss: 5.0222e-04\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.9111e-04 - val_loss: 6.2048e-04\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 7.1030e-04 - val_loss: 6.2462e-04\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.7910e-04 - val_loss: 4.8893e-04\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.9580e-04 - val_loss: 5.0831e-04\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 6.7407e-04 - val_loss: 6.2051e-04\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.4926e-04 - val_loss: 4.8792e-04\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 6.5863e-04 - val_loss: 0.0011\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 7.7536e-04 - val_loss: 4.9023e-04\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.4819e-04 - val_loss: 5.4531e-04\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.4541e-04 - val_loss: 5.2804e-04\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.3327e-04 - val_loss: 8.3128e-04\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.7047e-04 - val_loss: 5.5695e-04\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 7.8136e-04 - val_loss: 0.0010\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 7.7400e-04 - val_loss: 4.8976e-04\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.4780e-04 - val_loss: 5.3942e-04\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.2364e-04 - val_loss: 6.0754e-04\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.2773e-04 - val_loss: 5.8295e-04\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 5.9923e-04 - val_loss: 5.7003e-04\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.0508e-04 - val_loss: 4.8366e-04\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 6.3387e-04 - val_loss: 5.7477e-04\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 5.9002e-04 - val_loss: 5.9321e-04\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 6.0260e-04 - val_loss: 6.5423e-04\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 5.9645e-04 - val_loss: 4.7100e-04\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 6.6207e-04 - val_loss: 9.2873e-04\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 119ms/step - loss: 7.4950e-04 - val_loss: 5.0455e-04\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 7.7294e-04 - val_loss: 6.7230e-04\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 7.4258e-04 - val_loss: 7.0605e-04\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 6.0307e-04 - val_loss: 5.0663e-04\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 6.4427e-04 - val_loss: 9.7033e-04\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 6.3588e-04 - val_loss: 5.4860e-04\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 6.7133e-04 - val_loss: 4.6966e-04\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 5.6378e-04 - val_loss: 5.1285e-04\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 5.5464e-04 - val_loss: 4.7871e-04\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 5.4409e-04 - val_loss: 5.5501e-04\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 6.9737e-04 - val_loss: 4.7315e-04\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 6.6535e-04 - val_loss: 4.7411e-04\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 5.7979e-04 - val_loss: 6.6718e-04\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 5.7520e-04 - val_loss: 4.9012e-04\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 6.6754e-04 - val_loss: 0.0011\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 6.8486e-04 - val_loss: 6.3954e-04\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.8442e-04 - val_loss: 0.0011\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 6.9326e-04 - val_loss: 4.7097e-04\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 5.7946e-04 - val_loss: 4.8093e-04\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.8982e-04 - val_loss: 4.3323e-04\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.1923e-04 - val_loss: 6.6328e-04\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 5.8734e-04 - val_loss: 4.6338e-04\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 5.5747e-04 - val_loss: 5.7375e-04\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 6.4324e-04 - val_loss: 4.6713e-04\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.7471e-04 - val_loss: 8.5238e-04\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 6.4652e-04 - val_loss: 5.3660e-04\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.6159e-04 - val_loss: 8.4607e-04\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 6.1789e-04 - val_loss: 4.5103e-04\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.7992e-04 - val_loss: 4.8081e-04\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.8799e-04 - val_loss: 4.9437e-04\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.3825e-04 - val_loss: 4.2767e-04\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.2233e-04 - val_loss: 5.5746e-04\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.6165e-04 - val_loss: 4.7270e-04\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.3472e-04 - val_loss: 5.3577e-04\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.1104e-04 - val_loss: 4.4414e-04\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.6118e-04 - val_loss: 4.4269e-04\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 4.8698e-04 - val_loss: 4.6029e-04\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 5.0234e-04 - val_loss: 5.0508e-04\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.3389e-04 - val_loss: 4.2305e-04\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 6.0558e-04 - val_loss: 4.1581e-04\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.8167e-04 - val_loss: 4.1944e-04\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.0556e-04 - val_loss: 7.4481e-04\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.4692e-04 - val_loss: 4.6673e-04\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 6.0359e-04 - val_loss: 7.5252e-04\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.3369e-04 - val_loss: 4.1976e-04\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 4.7057e-04 - val_loss: 4.4834e-04\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.7558e-04 - val_loss: 4.0616e-04\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.0157e-04 - val_loss: 3.9952e-04\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.8126e-04 - val_loss: 4.5000e-04\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.2265e-04 - val_loss: 3.9848e-04\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.6581e-04 - val_loss: 4.1212e-04\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.5810e-04 - val_loss: 3.9744e-04\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.9536e-04 - val_loss: 4.6602e-04\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 6.7185e-04 - val_loss: 7.1026e-04\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 6.3909e-04 - val_loss: 7.8826e-04\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 6.1896e-04 - val_loss: 6.7181e-04\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 5.4385e-04 - val_loss: 3.8925e-04\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 4.6568e-04 - val_loss: 4.0018e-04\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.5149e-04 - val_loss: 4.2567e-04\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 4.5629e-04 - val_loss: 3.9369e-04\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.6688e-04 - val_loss: 4.0813e-04\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 4.3571e-04 - val_loss: 4.2312e-04\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.4080e-04 - val_loss: 5.1623e-04\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 4.7853e-04 - val_loss: 4.9053e-04\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.9493e-04 - val_loss: 3.8360e-04\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.7669e-04 - val_loss: 4.7867e-04\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.7316e-04 - val_loss: 3.7539e-04\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.4621e-04 - val_loss: 3.9587e-04\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.6277e-04 - val_loss: 3.8235e-04\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.4724e-04 - val_loss: 3.7851e-04\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.3673e-04 - val_loss: 3.8210e-04\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.9257e-04 - val_loss: 4.7137e-04\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 4.7222e-04 - val_loss: 5.6999e-04\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 5.1458e-04 - val_loss: 4.9181e-04\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.7127e-04 - val_loss: 4.5834e-04\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 5.2720e-04 - val_loss: 3.7199e-04\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.6899e-04 - val_loss: 3.7943e-04\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 4.3104e-04 - val_loss: 5.0480e-04\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.4576e-04 - val_loss: 3.7510e-04\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.3260e-04 - val_loss: 3.5676e-04\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.6402e-04 - val_loss: 6.9017e-04\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.8463e-04 - val_loss: 5.2645e-04\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.6150e-04 - val_loss: 3.9315e-04\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.6092e-04 - val_loss: 4.8730e-04\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.2556e-04 - val_loss: 3.6662e-04\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.3502e-04 - val_loss: 4.5201e-04\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.2447e-04 - val_loss: 3.9510e-04\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.7094e-04 - val_loss: 4.3155e-04\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.1970e-04 - val_loss: 3.8353e-04\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.8204e-04 - val_loss: 5.1778e-04\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.8990e-04 - val_loss: 6.7671e-04\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 5.7991e-04 - val_loss: 7.5851e-04\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 5.8088e-04 - val_loss: 3.4666e-04\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.9124e-04 - val_loss: 4.6309e-04\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.4377e-04 - val_loss: 4.0067e-04\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.4608e-04 - val_loss: 3.8278e-04\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.2091e-04 - val_loss: 3.4557e-04\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 3.9256e-04 - val_loss: 3.5840e-04\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.1404e-04 - val_loss: 3.8666e-04\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.1164e-04 - val_loss: 4.8327e-04\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.9083e-04 - val_loss: 5.2641e-04\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.7284e-04 - val_loss: 3.6563e-04\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.1664e-04 - val_loss: 3.7242e-04\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.1521e-04 - val_loss: 3.4223e-04\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.0759e-04 - val_loss: 3.5410e-04\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 4.5668e-04 - val_loss: 3.9937e-04\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 5.1010e-04 - val_loss: 3.7209e-04\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.7730e-04 - val_loss: 7.0098e-04\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 5.2512e-04 - val_loss: 3.5193e-04\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.1065e-04 - val_loss: 4.0989e-04\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 4.2502e-04 - val_loss: 4.7838e-04\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.8895e-04 - val_loss: 5.9356e-04\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 5.7875e-04 - val_loss: 3.7140e-04\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.8291e-04 - val_loss: 5.9162e-04\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.3510e-04 - val_loss: 3.8765e-04\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 4.1500e-04 - val_loss: 4.8640e-04\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.2611e-04 - val_loss: 3.9694e-04\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 4.3315e-04 - val_loss: 6.8400e-04\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 5.5810e-04 - val_loss: 4.2926e-04\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.0230e-04 - val_loss: 4.7270e-04\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.0653e-04 - val_loss: 4.1727e-04\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 3.9225e-04 - val_loss: 3.3466e-04\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 4.4997e-04 - val_loss: 4.8721e-04\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.1340e-04 - val_loss: 3.7802e-04\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.0855e-04 - val_loss: 3.6170e-04\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.9612e-04 - val_loss: 3.8873e-04\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.9158e-04 - val_loss: 3.3640e-04\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.8106e-04 - val_loss: 4.6246e-04\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.5475e-04 - val_loss: 3.5165e-04\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.0018e-04 - val_loss: 3.5816e-04\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.8625e-04 - val_loss: 3.8449e-04\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.7826e-04 - val_loss: 3.3191e-04\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.7101e-04 - val_loss: 3.4128e-04\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.6592e-04 - val_loss: 3.4273e-04\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 3.8653e-04 - val_loss: 5.4480e-04\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.6795e-04 - val_loss: 4.7900e-04\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 5.1120e-04 - val_loss: 5.0648e-04\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.6086e-04 - val_loss: 5.6113e-04\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 5.6349e-04 - val_loss: 5.6528e-04\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 4.6310e-04 - val_loss: 3.3396e-04\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 4.2195e-04 - val_loss: 3.3945e-04\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 3.8614e-04 - val_loss: 3.7426e-04\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.6234e-04 - val_loss: 3.9296e-04\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.4336e-04 - val_loss: 3.1542e-04\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.1823e-04 - val_loss: 3.4343e-04\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 3.8291e-04 - val_loss: 3.3016e-04\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 3.7576e-04 - val_loss: 4.0138e-04\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.6754e-04 - val_loss: 3.2808e-04\n",
      "Epoch 430/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 108ms/step - loss: 3.7745e-04 - val_loss: 4.3279e-04\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 4.8796e-04 - val_loss: 3.9315e-04\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 3.9206e-04 - val_loss: 3.2553e-04\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 4.2374e-04 - val_loss: 3.1687e-04\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 3.7393e-04 - val_loss: 3.3508e-04\n",
      "Epoch 435/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 3.9597e-04 - val_loss: 3.3012e-04\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.1293e-04 - val_loss: 3.5959e-04\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 3.7173e-04 - val_loss: 3.3331e-04\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 3.5800e-04 - val_loss: 3.3890e-04\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 3.7719e-04 - val_loss: 5.2117e-04\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 4.1568e-04 - val_loss: 3.2467e-04\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.6029e-04 - val_loss: 4.5130e-04\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 3.9517e-04 - val_loss: 3.3094e-04\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.1036e-04 - val_loss: 4.5978e-04\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.0994e-04 - val_loss: 4.2271e-04\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 5.5588e-04 - val_loss: 4.5541e-04\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 5.2234e-04 - val_loss: 6.3771e-04\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 4.7725e-04 - val_loss: 5.2174e-04\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 4.4404e-04 - val_loss: 4.2140e-04\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.0605e-04 - val_loss: 3.0929e-04\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.4014e-04 - val_loss: 3.2327e-04\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.5801e-04 - val_loss: 3.1084e-04\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 3.4879e-04 - val_loss: 3.1182e-04\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.4781e-04 - val_loss: 3.1457e-04\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.6395e-04 - val_loss: 4.0292e-04\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.6904e-04 - val_loss: 3.1343e-04\n",
      "Epoch 456/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.4764e-04 - val_loss: 3.1510e-04\n",
      "Epoch 457/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.8544e-04 - val_loss: 3.1575e-04\n",
      "Epoch 458/1000\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 4.1357e-04 - val_loss: 3.1760e-04\n",
      "Epoch 459/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.7366e-04 - val_loss: 3.1617e-04\n",
      "Epoch 460/1000\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 3.5110e-04 - val_loss: 3.1142e-04\n",
      "Epoch 461/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.8658e-04 - val_loss: 3.0889e-04\n",
      "Epoch 462/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.8970e-04 - val_loss: 3.0777e-04\n",
      "Epoch 463/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 3.7068e-04 - val_loss: 3.2359e-04\n",
      "Epoch 464/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 4.4354e-04 - val_loss: 3.0465e-04\n",
      "Epoch 465/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.8856e-04 - val_loss: 3.0831e-04\n",
      "Epoch 466/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.3808e-04 - val_loss: 3.1480e-04\n",
      "Epoch 467/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.5044e-04 - val_loss: 3.3612e-04\n",
      "Epoch 468/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 3.6159e-04 - val_loss: 3.3712e-04\n",
      "Epoch 469/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.8395e-04 - val_loss: 3.7791e-04\n",
      "Epoch 470/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 4.4950e-04 - val_loss: 4.6945e-04\n",
      "Epoch 471/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.5331e-04 - val_loss: 3.8252e-04\n",
      "Epoch 472/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.1927e-04 - val_loss: 3.3935e-04\n",
      "Epoch 473/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.2744e-04 - val_loss: 4.3999e-04\n",
      "Epoch 474/1000\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 4.0719e-04 - val_loss: 3.1503e-04\n",
      "Epoch 475/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 3.7490e-04 - val_loss: 3.1313e-04\n",
      "Epoch 476/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.9972e-04 - val_loss: 3.2341e-04\n",
      "Epoch 477/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.9040e-04 - val_loss: 3.3809e-04\n",
      "Epoch 478/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.5115e-04 - val_loss: 3.3647e-04\n",
      "Epoch 479/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.4721e-04 - val_loss: 4.1088e-04\n",
      "Epoch 480/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 3.9253e-04 - val_loss: 3.3882e-04\n",
      "Epoch 481/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 4.0673e-04 - val_loss: 3.3575e-04\n",
      "Epoch 482/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 4.1244e-04 - val_loss: 3.2038e-04\n",
      "Epoch 483/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.2138e-04 - val_loss: 3.0893e-04\n",
      "Epoch 484/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 3.7546e-04 - val_loss: 3.9211e-04\n",
      "Epoch 485/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.6364e-04 - val_loss: 5.4845e-04\n",
      "Epoch 486/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.1217e-04 - val_loss: 7.3104e-04\n",
      "Epoch 487/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.6175e-04 - val_loss: 4.4896e-04\n",
      "Epoch 488/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.5715e-04 - val_loss: 4.0111e-04\n",
      "Epoch 489/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.5273e-04 - val_loss: 4.6124e-04\n",
      "Epoch 490/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 4.0480e-04 - val_loss: 4.6584e-04\n",
      "Epoch 491/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.5297e-04 - val_loss: 3.1086e-04\n",
      "Epoch 492/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 3.4227e-04 - val_loss: 3.1403e-04\n",
      "Epoch 493/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 3.3621e-04 - val_loss: 3.3972e-04\n",
      "Epoch 494/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.5908e-04 - val_loss: 3.0638e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 4s 20ms/step - loss: 0.0551 - val_loss: 0.0025\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.1356e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.5588e-04\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.6129e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.4161e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.1928e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.8858e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.7788e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.3838e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.8785e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 9.8295e-04 - val_loss: 5.9499e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.5942e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 9.3759e-04 - val_loss: 6.6754e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.5006e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 9.2123e-04 - val_loss: 6.9867e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.6279e-04 - val_loss: 0.0014\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.7365e-04 - val_loss: 5.6696e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.3383e-04 - val_loss: 5.4599e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.1849e-04 - val_loss: 5.2039e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.6012e-04 - val_loss: 5.3754e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.8718e-04 - val_loss: 5.6402e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 8.1706e-04 - val_loss: 7.1035e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 7.6144e-04 - val_loss: 6.3863e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 7.7866e-04 - val_loss: 5.0585e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 7.4385e-04 - val_loss: 5.3520e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 7.5965e-04 - val_loss: 5.7690e-04\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 7.5232e-04 - val_loss: 5.1740e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 7.5336e-04 - val_loss: 7.6430e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 7.1557e-04 - val_loss: 4.9347e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 7.0274e-04 - val_loss: 4.7811e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 6.5716e-04 - val_loss: 5.7969e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.8439e-04 - val_loss: 4.6993e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.4260e-04 - val_loss: 5.3802e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 6.9164e-04 - val_loss: 4.5787e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.3287e-04 - val_loss: 8.9811e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.6645e-04 - val_loss: 4.6136e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.4956e-04 - val_loss: 4.5686e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.3618e-04 - val_loss: 4.5772e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.0349e-04 - val_loss: 4.4884e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.0543e-04 - val_loss: 5.2612e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.7936e-04 - val_loss: 4.4315e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 6.1033e-04 - val_loss: 4.5310e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.8236e-04 - val_loss: 5.1942e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.5411e-04 - val_loss: 5.8861e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.4525e-04 - val_loss: 5.5971e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.5990e-04 - val_loss: 4.5485e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.6118e-04 - val_loss: 4.7197e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.4712e-04 - val_loss: 4.2534e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.1349e-04 - val_loss: 5.0479e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.1539e-04 - val_loss: 4.3796e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.1958e-04 - val_loss: 4.1376e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.1524e-04 - val_loss: 5.5423e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 5.0423e-04 - val_loss: 4.2228e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.1883e-04 - val_loss: 7.6952e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.4092e-04 - val_loss: 5.2294e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.8133e-04 - val_loss: 4.5394e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.8572e-04 - val_loss: 7.1069e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.0225e-04 - val_loss: 3.8648e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 5.1522e-04 - val_loss: 3.9625e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.7463e-04 - val_loss: 3.7317e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.3381e-04 - val_loss: 4.0864e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.5493e-04 - val_loss: 6.5895e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.4145e-04 - val_loss: 3.8433e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.6379e-04 - val_loss: 3.9146e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.3657e-04 - val_loss: 4.2700e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.5942e-04 - val_loss: 3.6383e-04\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 11ms/step - loss: 4.4829e-04 - val_loss: 3.7903e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.2353e-04 - val_loss: 4.1372e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.3929e-04 - val_loss: 5.0461e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.4474e-04 - val_loss: 4.3013e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 4.1248e-04 - val_loss: 3.7390e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.1412e-04 - val_loss: 3.4003e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.0194e-04 - val_loss: 3.3206e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 4.1715e-04 - val_loss: 3.5930e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.1362e-04 - val_loss: 3.7656e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.2207e-04 - val_loss: 3.3064e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 4.3767e-04 - val_loss: 4.3721e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.9670e-04 - val_loss: 3.3200e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8990e-04 - val_loss: 3.4957e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8737e-04 - val_loss: 3.7794e-04\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8122e-04 - val_loss: 4.8084e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8813e-04 - val_loss: 3.2212e-04\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6545e-04 - val_loss: 3.8171e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6903e-04 - val_loss: 3.0290e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.7454e-04 - val_loss: 3.5318e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6515e-04 - val_loss: 3.0640e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.7409e-04 - val_loss: 4.0999e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5568e-04 - val_loss: 3.2993e-04\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5786e-04 - val_loss: 3.4609e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5754e-04 - val_loss: 3.2912e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4896e-04 - val_loss: 3.8515e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8831e-04 - val_loss: 3.6379e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5211e-04 - val_loss: 3.1238e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.7590e-04 - val_loss: 3.0169e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5667e-04 - val_loss: 3.0894e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5676e-04 - val_loss: 3.0320e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.7096e-04 - val_loss: 3.0477e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.7540e-04 - val_loss: 3.6999e-04\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.8914e-04 - val_loss: 3.8360e-04\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5817e-04 - val_loss: 3.7086e-04\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5736e-04 - val_loss: 3.1101e-04\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5572e-04 - val_loss: 3.3424e-04\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6248e-04 - val_loss: 3.3484e-04\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4963e-04 - val_loss: 2.9895e-04\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5554e-04 - val_loss: 3.1155e-04\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5354e-04 - val_loss: 3.1200e-04\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5202e-04 - val_loss: 3.0920e-04\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6199e-04 - val_loss: 3.0085e-04\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5761e-04 - val_loss: 3.4105e-04\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5248e-04 - val_loss: 5.5791e-04\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5981e-04 - val_loss: 3.0147e-04\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4569e-04 - val_loss: 3.7449e-04\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6442e-04 - val_loss: 3.5049e-04\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6200e-04 - val_loss: 3.3124e-04\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.4939e-04 - val_loss: 3.1371e-04\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5107e-04 - val_loss: 3.2247e-04\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6312e-04 - val_loss: 3.0707e-04\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4884e-04 - val_loss: 3.2482e-04\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5042e-04 - val_loss: 3.5136e-04\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6582e-04 - val_loss: 3.1451e-04\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5164e-04 - val_loss: 3.3256e-04\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5300e-04 - val_loss: 5.1646e-04\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.6025e-04 - val_loss: 2.9747e-04\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3276e-04 - val_loss: 3.1062e-04\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.3246e-04 - val_loss: 3.5675e-04\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5570e-04 - val_loss: 3.2196e-04\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4337e-04 - val_loss: 3.1051e-04\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4133e-04 - val_loss: 4.2692e-04\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5566e-04 - val_loss: 3.5294e-04\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4991e-04 - val_loss: 3.0055e-04\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4448e-04 - val_loss: 3.1045e-04\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4471e-04 - val_loss: 3.7312e-04\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4852e-04 - val_loss: 3.1552e-04\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5071e-04 - val_loss: 3.0896e-04\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4648e-04 - val_loss: 4.4627e-04\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.5917e-04 - val_loss: 2.9677e-04\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4990e-04 - val_loss: 4.9440e-04\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.6366e-04 - val_loss: 3.3266e-04\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5925e-04 - val_loss: 3.3366e-04\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4983e-04 - val_loss: 9.3470e-04\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 3.6129e-04 - val_loss: 3.7144e-04\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3645e-04 - val_loss: 4.0444e-04\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 3.4836e-04 - val_loss: 4.2316e-04\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3462e-04 - val_loss: 3.4475e-04\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3947e-04 - val_loss: 3.2212e-04\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3759e-04 - val_loss: 4.4192e-04\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4764e-04 - val_loss: 2.9961e-04\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4412e-04 - val_loss: 2.9418e-04\n",
      "Epoch 169/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4488e-04 - val_loss: 3.0564e-04\n",
      "Epoch 170/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3785e-04 - val_loss: 2.9915e-04\n",
      "Epoch 171/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3311e-04 - val_loss: 3.3151e-04\n",
      "Epoch 172/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.6374e-04 - val_loss: 3.3242e-04\n",
      "Epoch 173/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.5096e-04 - val_loss: 3.3587e-04\n",
      "Epoch 174/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4664e-04 - val_loss: 3.1860e-04\n",
      "Epoch 175/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5310e-04 - val_loss: 2.9656e-04\n",
      "Epoch 176/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4781e-04 - val_loss: 3.1038e-04\n",
      "Epoch 177/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3934e-04 - val_loss: 2.9967e-04\n",
      "Epoch 178/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4792e-04 - val_loss: 3.1132e-04\n",
      "Epoch 179/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3573e-04 - val_loss: 3.2334e-04\n",
      "Epoch 180/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.2491e-04 - val_loss: 3.2497e-04\n",
      "Epoch 181/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3926e-04 - val_loss: 4.1658e-04\n",
      "Epoch 182/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3979e-04 - val_loss: 3.5118e-04\n",
      "Epoch 183/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.5052e-04 - val_loss: 3.2223e-04\n",
      "Epoch 184/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.4826e-04 - val_loss: 3.4699e-04\n",
      "Epoch 185/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4040e-04 - val_loss: 2.9979e-04\n",
      "Epoch 186/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 3.2833e-04 - val_loss: 3.0706e-04\n",
      "Epoch 187/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.4212e-04 - val_loss: 3.0735e-04\n",
      "Epoch 188/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3793e-04 - val_loss: 3.1812e-04\n",
      "Epoch 189/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4050e-04 - val_loss: 3.1986e-04\n",
      "Epoch 190/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4766e-04 - val_loss: 2.9438e-04\n",
      "Epoch 191/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3605e-04 - val_loss: 3.1684e-04\n",
      "Epoch 192/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3686e-04 - val_loss: 3.0505e-04\n",
      "Epoch 193/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.5288e-04 - val_loss: 3.1032e-04\n",
      "Epoch 194/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3412e-04 - val_loss: 3.4479e-04\n",
      "Epoch 195/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3376e-04 - val_loss: 3.1362e-04\n",
      "Epoch 196/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.4347e-04 - val_loss: 3.0606e-04\n",
      "Epoch 197/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 3.3744e-04 - val_loss: 3.8584e-04\n",
      "Epoch 198/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 3.3907e-04 - val_loss: 3.4566e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 6s 33ms/step - loss: 0.0175 - val_loss: 0.0014\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 5.3239e-04\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 9.0139e-04 - val_loss: 6.7381e-04\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 7.6636e-04 - val_loss: 4.3369e-04\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 7.6423e-04 - val_loss: 3.8605e-04\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 9.9886e-04 - val_loss: 4.1925e-04\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 7.0345e-04 - val_loss: 4.0211e-04\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.0010 - val_loss: 3.4740e-04\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 6.4303e-04 - val_loss: 5.0576e-04\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 8.7708e-04 - val_loss: 3.3060e-04\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 5.5859e-04 - val_loss: 0.0017\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 7.7415e-04 - val_loss: 3.5606e-04\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 7.0353e-04 - val_loss: 3.2347e-04\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 7.2614e-04 - val_loss: 5.5491e-04\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 6.9142e-04 - val_loss: 3.8817e-04\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 5.7154e-04 - val_loss: 5.7013e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.3154e-04 - val_loss: 3.1650e-04\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.4910e-04 - val_loss: 4.8030e-04\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 6.3898e-04 - val_loss: 3.0369e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.1809e-04 - val_loss: 2.9563e-04\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.1071e-04 - val_loss: 4.4727e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.6987e-04 - val_loss: 3.6538e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.3913e-04 - val_loss: 2.9539e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.1626e-04 - val_loss: 2.8825e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 5.6361e-04 - val_loss: 3.0181e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 5.5785e-04 - val_loss: 7.5384e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.7418e-04 - val_loss: 5.3324e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.2135e-04 - val_loss: 0.0019\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.4187e-04 - val_loss: 2.8382e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.4720e-04 - val_loss: 4.5033e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.0652e-04 - val_loss: 5.7185e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.5752e-04 - val_loss: 8.8567e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.0174e-04 - val_loss: 2.8552e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 7.2379e-04 - val_loss: 3.4653e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.1768e-04 - val_loss: 5.7396e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.1955e-04 - val_loss: 7.6166e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.8006e-04 - val_loss: 5.3797e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.9345e-04 - val_loss: 2.9251e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.9025e-04 - val_loss: 6.9974e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 4.4058e-04 - val_loss: 2.9386e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 5.3165e-04 - val_loss: 3.0188e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 5.1024e-04 - val_loss: 4.5526e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.4287e-04 - val_loss: 0.0020\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.3973e-04 - val_loss: 3.6251e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 5.0650e-04 - val_loss: 3.0501e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 5.9806e-04 - val_loss: 9.6543e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 5.1808e-04 - val_loss: 2.8941e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.4940e-04 - val_loss: 3.8138e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.5736e-04 - val_loss: 3.3052e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.5389e-04 - val_loss: 0.0018\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.2598e-04 - val_loss: 0.0014\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.2829e-04 - val_loss: 2.8809e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.5637e-04 - val_loss: 2.9205e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.2682e-04 - val_loss: 3.9640e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.6772e-04 - val_loss: 4.1308e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0256e-04 - val_loss: 3.9585e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0570e-04 - val_loss: 3.3031e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.1032e-04 - val_loss: 4.5995e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.2363e-04 - val_loss: 9.3588e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 8s 46ms/step - loss: 0.0130 - val_loss: 0.0333\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0019 - val_loss: 9.9570e-04\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0019 - val_loss: 9.8384e-04\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0015 - val_loss: 8.7294e-04\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 5.9844e-04\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 9.5258e-04 - val_loss: 6.3732e-04\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.0011 - val_loss: 5.4538e-04\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 8.1991e-04 - val_loss: 7.3388e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 8.8596e-04 - val_loss: 7.3923e-04\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 7.1165e-04 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 7.9748e-04 - val_loss: 0.0013\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 6.3250e-04 - val_loss: 5.5453e-04\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 6.4123e-04 - val_loss: 4.7109e-04\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 6.9298e-04 - val_loss: 0.0014\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 6.9826e-04 - val_loss: 7.5056e-04\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 5.8217e-04 - val_loss: 4.3137e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 8.8493e-04 - val_loss: 6.6900e-04\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 7.0936e-04 - val_loss: 8.3471e-04\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 5.5004e-04 - val_loss: 4.3352e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 5.6794e-04 - val_loss: 3.5089e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 6.3242e-04 - val_loss: 7.5802e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 5.5498e-04 - val_loss: 8.9002e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 6.1828e-04 - val_loss: 3.2656e-04\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.6089e-04 - val_loss: 5.9306e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.5905e-04 - val_loss: 0.0013\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 7.2285e-04 - val_loss: 4.9818e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.7062e-04 - val_loss: 4.5609e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 5.8125e-04 - val_loss: 4.6118e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 6.8570e-04 - val_loss: 3.7562e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.6780e-04 - val_loss: 4.8233e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 5.2986e-04 - val_loss: 0.0015\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.7769e-04 - val_loss: 5.2199e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.6485e-04 - val_loss: 4.7976e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.8500e-04 - val_loss: 0.0015\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 4.6011e-04 - val_loss: 0.0012\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 6.1710e-04 - val_loss: 4.1269e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.6275e-04 - val_loss: 5.8566e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.4353e-04 - val_loss: 0.0011\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3658e-04 - val_loss: 5.3651e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 4.3486e-04 - val_loss: 0.0017\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 32ms/step - loss: 4.9573e-04 - val_loss: 0.0013\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 5.0418e-04 - val_loss: 9.1058e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.3528e-04 - val_loss: 5.7424e-04\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.5456e-04 - val_loss: 7.3993e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 4.5343e-04 - val_loss: 0.0018\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 4.1883e-04 - val_loss: 5.1497e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 5.3799e-04 - val_loss: 4.0852e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 3.9889e-04 - val_loss: 4.8578e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 5.7820e-04 - val_loss: 6.4533e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.7475e-04 - val_loss: 5.2353e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 5.2851e-04 - val_loss: 7.4841e-04\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 4.1872e-04 - val_loss: 0.0017\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 5.2137e-04 - val_loss: 3.3525e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 4s 35ms/step - loss: 0.0648 - val_loss: 0.0042\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 9.2978e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 8.0104e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 7.1436e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 9.8201e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.1436e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.6724e-04 - val_loss: 6.7520e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.2981e-04 - val_loss: 0.0014\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.5186e-04 - val_loss: 6.7609e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.7933e-04 - val_loss: 6.6406e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.4960e-04 - val_loss: 0.0011\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.9686e-04 - val_loss: 6.2737e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.0158e-04 - val_loss: 7.7168e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.4452e-04 - val_loss: 7.5200e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.2320e-04 - val_loss: 6.1213e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.4648e-04 - val_loss: 5.8881e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.8144e-04 - val_loss: 6.7873e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.8198e-04 - val_loss: 5.3455e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.5288e-04 - val_loss: 5.6672e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.8092e-04 - val_loss: 5.9213e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.5780e-04 - val_loss: 5.2831e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7058e-04 - val_loss: 5.3747e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3878e-04 - val_loss: 5.4422e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.6106e-04 - val_loss: 6.3170e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.5068e-04 - val_loss: 0.0012\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.4423e-04 - val_loss: 0.0010\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.3079e-04 - val_loss: 5.5951e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.5992e-04 - val_loss: 5.9238e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6803e-04 - val_loss: 9.5725e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.8287e-04 - val_loss: 7.5556e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.9671e-04 - val_loss: 6.7196e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6330e-04 - val_loss: 4.9013e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6531e-04 - val_loss: 4.9152e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.3771e-04 - val_loss: 6.2331e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6223e-04 - val_loss: 6.9819e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3714e-04 - val_loss: 5.2053e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.8151e-04 - val_loss: 5.8186e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3985e-04 - val_loss: 4.7830e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3653e-04 - val_loss: 4.9929e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0584e-04 - val_loss: 5.0840e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.9497e-04 - val_loss: 5.3525e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.9825e-04 - val_loss: 4.6852e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.7089e-04 - val_loss: 5.8575e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1454e-04 - val_loss: 4.7786e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1825e-04 - val_loss: 4.6899e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1885e-04 - val_loss: 4.6886e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8175e-04 - val_loss: 4.5868e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0104e-04 - val_loss: 4.8023e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8967e-04 - val_loss: 5.2645e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.7318e-04 - val_loss: 7.7232e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8501e-04 - val_loss: 4.4725e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8648e-04 - val_loss: 5.1054e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.5605e-04 - val_loss: 5.2419e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.8084e-04 - val_loss: 6.1917e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.4329e-04 - val_loss: 4.8544e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3601e-04 - val_loss: 4.9366e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.2676e-04 - val_loss: 7.4016e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.4885e-04 - val_loss: 4.3144e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3735e-04 - val_loss: 4.6280e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2862e-04 - val_loss: 4.4124e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3938e-04 - val_loss: 4.2447e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0487e-04 - val_loss: 5.9519e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9978e-04 - val_loss: 4.2030e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9312e-04 - val_loss: 5.6319e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.4825e-04 - val_loss: 5.4885e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3326e-04 - val_loss: 4.2023e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3529e-04 - val_loss: 4.1719e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0837e-04 - val_loss: 4.0109e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.1757e-04 - val_loss: 3.9922e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2398e-04 - val_loss: 3.9626e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.3890e-04 - val_loss: 4.9307e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0829e-04 - val_loss: 4.7379e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.7503e-04 - val_loss: 5.9224e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1837e-04 - val_loss: 4.5821e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9214e-04 - val_loss: 3.9137e-04\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1378e-04 - val_loss: 4.0871e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0186e-04 - val_loss: 3.9478e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9765e-04 - val_loss: 3.8190e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4452e-04 - val_loss: 3.8506e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8837e-04 - val_loss: 4.1557e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5365e-04 - val_loss: 3.9103e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7067e-04 - val_loss: 3.7761e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9192e-04 - val_loss: 5.4475e-04\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6180e-04 - val_loss: 5.3486e-04\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5690e-04 - val_loss: 4.7377e-04\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5387e-04 - val_loss: 3.6582e-04\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5516e-04 - val_loss: 3.6524e-04\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6075e-04 - val_loss: 3.6137e-04\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7568e-04 - val_loss: 4.3402e-04\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4062e-04 - val_loss: 3.8118e-04\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6223e-04 - val_loss: 4.9152e-04\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8349e-04 - val_loss: 3.9775e-04\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2050e-04 - val_loss: 5.7544e-04\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.4168e-04 - val_loss: 3.8631e-04\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2533e-04 - val_loss: 6.0516e-04\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.4503e-04 - val_loss: 4.4448e-04\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1649e-04 - val_loss: 4.5702e-04\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.4903e-04 - val_loss: 3.7916e-04\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2789e-04 - val_loss: 3.6173e-04\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1113e-04 - val_loss: 6.0985e-04\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3711e-04 - val_loss: 4.7002e-04\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3672e-04 - val_loss: 4.7301e-04\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0620e-04 - val_loss: 3.5277e-04\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1838e-04 - val_loss: 3.3614e-04\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1009e-04 - val_loss: 4.0666e-04\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0099e-04 - val_loss: 3.4621e-04\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9976e-04 - val_loss: 3.8425e-04\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9134e-04 - val_loss: 5.0255e-04\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0921e-04 - val_loss: 3.6319e-04\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9929e-04 - val_loss: 5.7112e-04\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9043e-04 - val_loss: 3.2743e-04\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0885e-04 - val_loss: 3.2633e-04\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8911e-04 - val_loss: 3.8125e-04\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8577e-04 - val_loss: 3.2859e-04\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8797e-04 - val_loss: 3.5790e-04\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0596e-04 - val_loss: 3.4168e-04\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9294e-04 - val_loss: 3.4109e-04\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7507e-04 - val_loss: 3.9264e-04\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7685e-04 - val_loss: 3.3942e-04\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7949e-04 - val_loss: 3.9914e-04\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.2567e-04 - val_loss: 3.3310e-04\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8400e-04 - val_loss: 3.2204e-04\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9402e-04 - val_loss: 3.1318e-04\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8131e-04 - val_loss: 3.2976e-04\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8175e-04 - val_loss: 3.2553e-04\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8023e-04 - val_loss: 3.6029e-04\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8413e-04 - val_loss: 3.2681e-04\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9333e-04 - val_loss: 3.6018e-04\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9531e-04 - val_loss: 3.3307e-04\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6145e-04 - val_loss: 4.4843e-04\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7867e-04 - val_loss: 3.0843e-04\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7661e-04 - val_loss: 3.1587e-04\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7466e-04 - val_loss: 3.3755e-04\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6401e-04 - val_loss: 4.1516e-04\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7202e-04 - val_loss: 3.8796e-04\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7817e-04 - val_loss: 3.0431e-04\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5767e-04 - val_loss: 3.1434e-04\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5981e-04 - val_loss: 3.8797e-04\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5738e-04 - val_loss: 3.0351e-04\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8668e-04 - val_loss: 3.2740e-04\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1674e-04 - val_loss: 4.4957e-04\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6558e-04 - val_loss: 6.4611e-04\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5894e-04 - val_loss: 4.5170e-04\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4757e-04 - val_loss: 3.5275e-04\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7260e-04 - val_loss: 3.0057e-04\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5094e-04 - val_loss: 3.0088e-04\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4139e-04 - val_loss: 2.9763e-04\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4194e-04 - val_loss: 2.9706e-04\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6972e-04 - val_loss: 3.2441e-04\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6999e-04 - val_loss: 2.9666e-04\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5702e-04 - val_loss: 3.5597e-04\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5809e-04 - val_loss: 3.4393e-04\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4731e-04 - val_loss: 3.0730e-04\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3966e-04 - val_loss: 3.5338e-04\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6249e-04 - val_loss: 3.1929e-04\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4651e-04 - val_loss: 3.1097e-04\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4036e-04 - val_loss: 2.9623e-04\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5304e-04 - val_loss: 3.2379e-04\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5382e-04 - val_loss: 2.9995e-04\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4959e-04 - val_loss: 3.0697e-04\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5621e-04 - val_loss: 3.2457e-04\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8556e-04 - val_loss: 3.6409e-04\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5899e-04 - val_loss: 3.2387e-04\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4961e-04 - val_loss: 3.6409e-04\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4866e-04 - val_loss: 3.5690e-04\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4091e-04 - val_loss: 2.9560e-04\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5653e-04 - val_loss: 2.9743e-04\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3673e-04 - val_loss: 2.9339e-04\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6232e-04 - val_loss: 3.1797e-04\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5928e-04 - val_loss: 3.8508e-04\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5693e-04 - val_loss: 3.0182e-04\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4633e-04 - val_loss: 3.2537e-04\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6042e-04 - val_loss: 3.6933e-04\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4557e-04 - val_loss: 2.9788e-04\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2977e-04 - val_loss: 3.1015e-04\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2988e-04 - val_loss: 2.9645e-04\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4743e-04 - val_loss: 3.1354e-04\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4653e-04 - val_loss: 3.0602e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4638e-04 - val_loss: 2.9825e-04\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6532e-04 - val_loss: 2.9771e-04\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4077e-04 - val_loss: 3.2867e-04\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4007e-04 - val_loss: 2.9731e-04\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5443e-04 - val_loss: 2.9874e-04\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3345e-04 - val_loss: 3.5336e-04\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4724e-04 - val_loss: 3.2428e-04\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2597e-04 - val_loss: 2.9667e-04\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3950e-04 - val_loss: 3.8528e-04\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4947e-04 - val_loss: 3.1245e-04\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3977e-04 - val_loss: 2.9667e-04\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6611e-04 - val_loss: 5.2496e-04\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5149e-04 - val_loss: 2.9236e-04\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5393e-04 - val_loss: 3.7566e-04\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4374e-04 - val_loss: 4.8563e-04\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4738e-04 - val_loss: 3.0589e-04\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4530e-04 - val_loss: 3.2480e-04\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5199e-04 - val_loss: 3.0281e-04\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3330e-04 - val_loss: 3.0067e-04\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4354e-04 - val_loss: 3.6363e-04\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4727e-04 - val_loss: 2.9285e-04\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3096e-04 - val_loss: 2.9171e-04\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3291e-04 - val_loss: 2.9969e-04\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3105e-04 - val_loss: 2.9335e-04\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2802e-04 - val_loss: 3.2622e-04\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3675e-04 - val_loss: 3.0576e-04\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3950e-04 - val_loss: 4.1878e-04\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3007e-04 - val_loss: 3.2631e-04\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2618e-04 - val_loss: 3.2192e-04\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3716e-04 - val_loss: 3.1553e-04\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3934e-04 - val_loss: 3.0150e-04\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3412e-04 - val_loss: 3.8132e-04\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4322e-04 - val_loss: 3.2127e-04\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2515e-04 - val_loss: 2.9351e-04\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4226e-04 - val_loss: 3.4248e-04\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3480e-04 - val_loss: 3.0332e-04\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4445e-04 - val_loss: 3.0074e-04\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4297e-04 - val_loss: 3.1905e-04\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2863e-04 - val_loss: 2.9945e-04\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3529e-04 - val_loss: 2.9438e-04\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2637e-04 - val_loss: 4.2536e-04\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5582e-04 - val_loss: 3.6114e-04\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3430e-04 - val_loss: 3.7491e-04\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3519e-04 - val_loss: 2.9484e-04\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4518e-04 - val_loss: 3.2008e-04\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3506e-04 - val_loss: 3.2809e-04\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2988e-04 - val_loss: 3.0279e-04\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4318e-04 - val_loss: 3.1145e-04\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3609e-04 - val_loss: 2.9300e-04\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3044e-04 - val_loss: 3.0581e-04\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3856e-04 - val_loss: 3.3520e-04\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4324e-04 - val_loss: 3.6737e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 6s 63ms/step - loss: 0.0126 - val_loss: 0.0049\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0023 - val_loss: 7.1158e-04\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0031 - val_loss: 9.6511e-04\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0013 - val_loss: 7.1678e-04\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0015 - val_loss: 6.5108e-04\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0010 - val_loss: 5.5313e-04\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 8.3902e-04 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0012 - val_loss: 4.4438e-04\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 9.3241e-04 - val_loss: 4.4171e-04\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.9978e-04 - val_loss: 3.8283e-04\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.7373e-04 - val_loss: 0.0039\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0016 - val_loss: 4.3246e-04\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.4432e-04 - val_loss: 3.7888e-04\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.1202e-04 - val_loss: 4.3219e-04\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.5423e-04 - val_loss: 0.0014\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.9186e-04 - val_loss: 4.9243e-04\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 8.3193e-04 - val_loss: 5.6172e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 6.8913e-04 - val_loss: 9.3950e-04\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.3288e-04 - val_loss: 7.9798e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.7028e-04 - val_loss: 8.4299e-04\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 7.2137e-04 - val_loss: 4.4117e-04\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.6092e-04 - val_loss: 3.3294e-04\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.8192e-04 - val_loss: 3.1191e-04\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.1190e-04 - val_loss: 3.1688e-04\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.5064e-04 - val_loss: 3.1101e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.3541e-04 - val_loss: 3.2477e-04\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.0771e-04 - val_loss: 0.0031\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 6.2265e-04 - val_loss: 6.5245e-04\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.0603e-04 - val_loss: 5.5360e-04\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.9984e-04 - val_loss: 3.8462e-04\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.5927e-04 - val_loss: 4.4940e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.6305e-04 - val_loss: 2.9443e-04\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 5.3675e-04 - val_loss: 2.9228e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 3.7047e-04 - val_loss: 2.8969e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 3.8946e-04 - val_loss: 3.2746e-04\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 4.4302e-04 - val_loss: 2.8755e-04\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 8.3553e-04 - val_loss: 4.4795e-04\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.4392e-04 - val_loss: 0.0016\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 5.3395e-04 - val_loss: 4.6126e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.9316e-04 - val_loss: 0.0033\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 7.6486e-04 - val_loss: 2.8888e-04\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 4.7843e-04 - val_loss: 4.7413e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.2303e-04 - val_loss: 3.0023e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.0657e-04 - val_loss: 7.7323e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 5.1501e-04 - val_loss: 3.4768e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 3.9483e-04 - val_loss: 4.6287e-04\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 9.9167e-04 - val_loss: 2.8504e-04\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 4.5395e-04 - val_loss: 3.1405e-04\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.8742e-04 - val_loss: 4.5453e-04\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 5.0695e-04 - val_loss: 4.2518e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.5153e-04 - val_loss: 3.9205e-04\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 4.9861e-04 - val_loss: 3.5848e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 3.8740e-04 - val_loss: 3.7976e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.3466e-04 - val_loss: 3.4601e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.3909e-04 - val_loss: 3.3370e-04\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 4.8996e-04 - val_loss: 3.1456e-04\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.6335e-04 - val_loss: 3.4783e-04\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 6.9568e-04 - val_loss: 7.0978e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 5.3338e-04 - val_loss: 3.8380e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 3.9498e-04 - val_loss: 3.3265e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 5.1325e-04 - val_loss: 4.4099e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.6572e-04 - val_loss: 8.5232e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 4.6612e-04 - val_loss: 2.9418e-04\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 3.7091e-04 - val_loss: 3.0005e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0381e-04 - val_loss: 4.8529e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6441e-04 - val_loss: 6.7670e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.4485e-04 - val_loss: 2.8722e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9454e-04 - val_loss: 3.1772e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 5.5497e-04 - val_loss: 3.5637e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0267e-04 - val_loss: 2.8905e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.3089e-04 - val_loss: 2.8453e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.4233e-04 - val_loss: 3.3889e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.5539e-04 - val_loss: 6.2899e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9009e-04 - val_loss: 2.9964e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.2424e-04 - val_loss: 3.2103e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 7.3694e-04 - val_loss: 9.1735e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 5.9764e-04 - val_loss: 7.0936e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.5071e-04 - val_loss: 3.2148e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.0765e-04 - val_loss: 3.1281e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6769e-04 - val_loss: 5.9186e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9257e-04 - val_loss: 3.4632e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.4420e-04 - val_loss: 4.1252e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.5457e-04 - val_loss: 3.0235e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.9457e-04 - val_loss: 3.1711e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.8534e-04 - val_loss: 3.4374e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 4.0308e-04 - val_loss: 3.1740e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.0458e-04 - val_loss: 5.6976e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.9814e-04 - val_loss: 4.9310e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.8964e-04 - val_loss: 2.8877e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.3629e-04 - val_loss: 3.6013e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.6206e-04 - val_loss: 6.3931e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 5.2190e-04 - val_loss: 3.1707e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.6960e-04 - val_loss: 5.4722e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.6992e-04 - val_loss: 3.5052e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.0428e-04 - val_loss: 9.8970e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7378e-04 - val_loss: 3.1793e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 3.7800e-04 - val_loss: 4.4109e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 4.4902e-04 - val_loss: 3.4674e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 6.1972e-04 - val_loss: 4.9269e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.1041e-04 - val_loss: 4.0133e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 4.1634e-04 - val_loss: 3.6364e-04\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 8s 83ms/step - loss: 0.0268 - val_loss: 0.0028\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0019 - val_loss: 9.9707e-04\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0016 - val_loss: 0.0071\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - val_loss: 6.6533e-04\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0012 - val_loss: 5.7342e-04\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 9.1053e-04 - val_loss: 0.0013\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0012 - val_loss: 5.2152e-04\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 7.8922e-04 - val_loss: 9.9353e-04\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 8.5468e-04 - val_loss: 5.1063e-04\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 7.1979e-04 - val_loss: 0.0022\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 9.3235e-04 - val_loss: 0.0019\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 9.1674e-04 - val_loss: 0.0010\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 4.6930e-04\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 9.8541e-04 - val_loss: 6.6421e-04\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 6.9546e-04 - val_loss: 6.4854e-04\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 6.3700e-04 - val_loss: 0.0010\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 6.7206e-04 - val_loss: 6.9494e-04\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 6.9783e-04 - val_loss: 5.8911e-04\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 6.9518e-04 - val_loss: 6.0893e-04\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 8.4205e-04 - val_loss: 7.6240e-04\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 5.7145e-04 - val_loss: 0.0011\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 7.0481e-04 - val_loss: 0.0039\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 7.1263e-04 - val_loss: 0.0022\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 7.0182e-04 - val_loss: 0.0052\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 7.9022e-04 - val_loss: 3.7595e-04\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 6.9216e-04 - val_loss: 0.0019\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 5.1805e-04 - val_loss: 4.4113e-04\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 5.8136e-04 - val_loss: 5.4232e-04\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 4.7249e-04 - val_loss: 5.1946e-04\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 6.8202e-04 - val_loss: 0.0010\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 5.7803e-04 - val_loss: 0.0031\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.6105e-04 - val_loss: 0.0025\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0013 - val_loss: 4.7838e-04\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 6.5808e-04 - val_loss: 5.2410e-04\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 5.7771e-04 - val_loss: 3.4632e-04\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.5516e-04 - val_loss: 3.4758e-04\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.3150e-04 - val_loss: 7.7423e-04\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 5.5675e-04 - val_loss: 3.8928e-04\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 43ms/step - loss: 5.5237e-04 - val_loss: 6.2092e-04\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.9821e-04 - val_loss: 9.9118e-04\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.1375e-04 - val_loss: 3.0356e-04\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 6.5281e-04 - val_loss: 5.4029e-04\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.8722e-04 - val_loss: 8.4837e-04\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.4471e-04 - val_loss: 4.0464e-04\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.3967e-04 - val_loss: 3.4118e-04\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.1882e-04 - val_loss: 7.9136e-04\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 6.1336e-04 - val_loss: 3.3503e-04\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 5.5168e-04 - val_loss: 8.9590e-04\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.6921e-04 - val_loss: 3.3943e-04\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.0913e-04 - val_loss: 8.2288e-04\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 4.5905e-04 - val_loss: 6.1014e-04\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 3.9108e-04 - val_loss: 6.4450e-04\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.1808e-04 - val_loss: 3.0118e-04\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.1427e-04 - val_loss: 3.3790e-04\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 4.6049e-04 - val_loss: 7.9856e-04\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 5.1696e-04 - val_loss: 3.3493e-04\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 5.4251e-04 - val_loss: 3.9490e-04\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.3739e-04 - val_loss: 2.9875e-04\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.6034e-04 - val_loss: 3.3509e-04\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 4.0702e-04 - val_loss: 3.8355e-04\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.8975e-04 - val_loss: 4.5630e-04\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.9803e-04 - val_loss: 3.7729e-04\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 4.1558e-04 - val_loss: 5.0266e-04\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.7218e-04 - val_loss: 4.0047e-04\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 3.7742e-04 - val_loss: 3.1212e-04\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 4.1359e-04 - val_loss: 3.0701e-04\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.6154e-04 - val_loss: 4.0705e-04\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 3.8381e-04 - val_loss: 3.0217e-04\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.5493e-04 - val_loss: 3.5242e-04\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.2795e-04 - val_loss: 3.5014e-04\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.9441e-04 - val_loss: 4.4867e-04\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 4.0705e-04 - val_loss: 6.6210e-04\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.7065e-04 - val_loss: 3.0526e-04\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 5.5011e-04 - val_loss: 9.1127e-04\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.1795e-04 - val_loss: 4.1908e-04\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.5902e-04 - val_loss: 9.5704e-04\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 7.3142e-04 - val_loss: 5.1743e-04\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.0340e-04 - val_loss: 4.5605e-04\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 6.7978e-04 - val_loss: 5.2051e-04\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 5.1327e-04 - val_loss: 0.0024\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.3973e-04 - val_loss: 5.1302e-04\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 5.4194e-04 - val_loss: 4.3696e-04\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.9836e-04 - val_loss: 3.7137e-04\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 5.4895e-04 - val_loss: 4.4624e-04\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.9673e-04 - val_loss: 6.5879e-04\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 4.6705e-04 - val_loss: 4.6026e-04\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.9359e-04 - val_loss: 3.0084e-04\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.8153e-04 - val_loss: 3.0988e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 3s 64ms/step - loss: 0.0193 - val_loss: 0.0031\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 9.9418e-04\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 9.0867e-04\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 9.1638e-04\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 8.4243e-04\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 8.0893e-04\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 6.9812e-04\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 8.4664e-04\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 6.9156e-04\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 6.6293e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 8.3299e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 8.3483e-04\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 7.1276e-04\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 9.9295e-04 - val_loss: 6.2876e-04\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.7434e-04 - val_loss: 6.4116e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.1382e-04 - val_loss: 0.0015\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.7441e-04 - val_loss: 0.0015\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.4868e-04 - val_loss: 7.9357e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.2860e-04 - val_loss: 9.8763e-04\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 6.4796e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.8683e-04 - val_loss: 9.9060e-04\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.2615e-04 - val_loss: 6.0336e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.3159e-04 - val_loss: 6.2286e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.3031e-04 - val_loss: 5.9345e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 9.4171e-04 - val_loss: 5.6769e-04\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.7954e-04 - val_loss: 7.4249e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.9940e-04 - val_loss: 6.2574e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.2071e-04 - val_loss: 5.9897e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.0125e-04 - val_loss: 7.9707e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.4436e-04 - val_loss: 5.8667e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.1594e-04 - val_loss: 5.7448e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.4141e-04 - val_loss: 5.3368e-04\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.8929e-04 - val_loss: 6.0806e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.2979e-04 - val_loss: 5.6987e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.8722e-04 - val_loss: 5.3607e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.4113e-04 - val_loss: 5.7123e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.8015e-04 - val_loss: 5.3889e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.4966e-04 - val_loss: 5.7388e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.7111e-04 - val_loss: 5.7726e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.3435e-04 - val_loss: 7.9605e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.7127e-04 - val_loss: 5.6161e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.7605e-04 - val_loss: 5.9229e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 9.6918e-04 - val_loss: 5.4754e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.0347e-04 - val_loss: 5.1876e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.2223e-04 - val_loss: 5.8986e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.0628e-04 - val_loss: 5.1610e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 8.9623e-04 - val_loss: 7.1705e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.9718e-04 - val_loss: 4.9441e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.7513e-04 - val_loss: 5.3855e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 7.0462e-04 - val_loss: 5.9228e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.2924e-04 - val_loss: 5.5086e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.5252e-04 - val_loss: 7.9435e-04\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 13ms/step - loss: 7.4189e-04 - val_loss: 5.7007e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.8933e-04 - val_loss: 5.1143e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.8088e-04 - val_loss: 4.9816e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.4398e-04 - val_loss: 5.0152e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.6273e-04 - val_loss: 5.3262e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.4119e-04 - val_loss: 4.9881e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.1577e-04 - val_loss: 5.0634e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.6046e-04 - val_loss: 6.2347e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.6389e-04 - val_loss: 4.9291e-04\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.3617e-04 - val_loss: 4.9367e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.7313e-04 - val_loss: 5.5578e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.5374e-04 - val_loss: 4.9299e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.1752e-04 - val_loss: 4.6351e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.2280e-04 - val_loss: 5.3261e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.0504e-04 - val_loss: 4.8421e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.1298e-04 - val_loss: 4.7999e-04\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.3164e-04 - val_loss: 4.4639e-04\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.8776e-04 - val_loss: 4.7458e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.9402e-04 - val_loss: 4.9132e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.5340e-04 - val_loss: 4.5835e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.1402e-04 - val_loss: 6.1312e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.7977e-04 - val_loss: 4.4936e-04\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.0285e-04 - val_loss: 9.2284e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 7.1072e-04 - val_loss: 4.5409e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.1231e-04 - val_loss: 4.7580e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.4267e-04 - val_loss: 4.8181e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.4147e-04 - val_loss: 4.8902e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.5251e-04 - val_loss: 4.8152e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.0850e-04 - val_loss: 4.5358e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.2162e-04 - val_loss: 5.7974e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.5907e-04 - val_loss: 4.7690e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.8228e-04 - val_loss: 4.4532e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.7310e-04 - val_loss: 4.3934e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.1582e-04 - val_loss: 5.9127e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.3045e-04 - val_loss: 4.5334e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.5210e-04 - val_loss: 5.5823e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.0913e-04 - val_loss: 4.9333e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.9726e-04 - val_loss: 4.6565e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.9226e-04 - val_loss: 4.3715e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.2835e-04 - val_loss: 4.3402e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.3844e-04 - val_loss: 5.3744e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.1503e-04 - val_loss: 6.5191e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.4660e-04 - val_loss: 4.5239e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.8920e-04 - val_loss: 4.3453e-04\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.2064e-04 - val_loss: 5.3997e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.5161e-04 - val_loss: 4.5368e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.1804e-04 - val_loss: 4.2517e-04\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.3078e-04 - val_loss: 5.8953e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.9910e-04 - val_loss: 4.3356e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.7062e-04 - val_loss: 4.3397e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.6859e-04 - val_loss: 4.5715e-04\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.8553e-04 - val_loss: 4.2217e-04\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.7355e-04 - val_loss: 4.5384e-04\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.9242e-04 - val_loss: 5.8928e-04\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.8164e-04 - val_loss: 4.1468e-04\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 5.7254e-04 - val_loss: 4.2647e-04\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.6587e-04 - val_loss: 4.2469e-04\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.6424e-04 - val_loss: 4.2599e-04\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.4016e-04 - val_loss: 4.2358e-04\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.5244e-04 - val_loss: 4.4069e-04\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.6341e-04 - val_loss: 4.8385e-04\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.6818e-04 - val_loss: 3.9931e-04\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.8577e-04 - val_loss: 4.3746e-04\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.9528e-04 - val_loss: 4.6773e-04\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.9655e-04 - val_loss: 4.2902e-04\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.4314e-04 - val_loss: 3.8533e-04\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.0214e-04 - val_loss: 4.2599e-04\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.2118e-04 - val_loss: 4.2887e-04\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.4376e-04 - val_loss: 4.3024e-04\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.2945e-04 - val_loss: 4.0763e-04\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.5516e-04 - val_loss: 4.5567e-04\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.4754e-04 - val_loss: 4.2031e-04\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.3456e-04 - val_loss: 3.9328e-04\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.4920e-04 - val_loss: 4.4197e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2787e-04 - val_loss: 5.9799e-04\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.4345e-04 - val_loss: 3.7185e-04\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.3985e-04 - val_loss: 4.3020e-04\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2601e-04 - val_loss: 6.8483e-04\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 5.0632e-04 - val_loss: 4.3727e-04\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.3270e-04 - val_loss: 3.9437e-04\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1475e-04 - val_loss: 4.4206e-04\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.4004e-04 - val_loss: 3.8397e-04\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 5.1105e-04 - val_loss: 9.8819e-04\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.3973e-04 - val_loss: 3.8402e-04\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.5142e-04 - val_loss: 5.0624e-04\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2664e-04 - val_loss: 3.7215e-04\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.0952e-04 - val_loss: 3.8701e-04\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2349e-04 - val_loss: 3.6480e-04\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.3944e-04 - val_loss: 5.3019e-04\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.7559e-04 - val_loss: 3.6733e-04\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.3489e-04 - val_loss: 3.6440e-04\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.9315e-04 - val_loss: 3.5760e-04\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.2043e-04 - val_loss: 3.9591e-04\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0075e-04 - val_loss: 3.8359e-04\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1892e-04 - val_loss: 3.9556e-04\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.8839e-04 - val_loss: 3.9207e-04\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.1761e-04 - val_loss: 4.2049e-04\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.6457e-04 - val_loss: 3.7297e-04\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0117e-04 - val_loss: 3.7930e-04\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.9090e-04 - val_loss: 4.6985e-04\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.6503e-04 - val_loss: 5.9026e-04\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.2481e-04 - val_loss: 3.7004e-04\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9292e-04 - val_loss: 6.2773e-04\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.7879e-04 - val_loss: 3.9368e-04\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1328e-04 - val_loss: 4.9776e-04\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.5368e-04 - val_loss: 3.6537e-04\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.8178e-04 - val_loss: 3.6032e-04\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.9161e-04 - val_loss: 4.0081e-04\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.8310e-04 - val_loss: 3.5736e-04\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0248e-04 - val_loss: 4.4453e-04\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0012e-04 - val_loss: 3.4998e-04\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.3873e-04 - val_loss: 4.5262e-04\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0766e-04 - val_loss: 3.9189e-04\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2425e-04 - val_loss: 3.5165e-04\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7382e-04 - val_loss: 3.5789e-04\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0012e-04 - val_loss: 3.3621e-04\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1792e-04 - val_loss: 5.9107e-04\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0619e-04 - val_loss: 3.4543e-04\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6374e-04 - val_loss: 3.3760e-04\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.3861e-04 - val_loss: 3.9042e-04\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.9695e-04 - val_loss: 3.9178e-04\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1541e-04 - val_loss: 3.8743e-04\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2785e-04 - val_loss: 3.3581e-04\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6766e-04 - val_loss: 3.3556e-04\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6614e-04 - val_loss: 3.3117e-04\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6463e-04 - val_loss: 3.9282e-04\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0487e-04 - val_loss: 3.5218e-04\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9965e-04 - val_loss: 3.3391e-04\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5716e-04 - val_loss: 3.3199e-04\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7879e-04 - val_loss: 3.4160e-04\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5947e-04 - val_loss: 3.3945e-04\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7447e-04 - val_loss: 3.3307e-04\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.7271e-04 - val_loss: 3.4549e-04\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5060e-04 - val_loss: 3.2351e-04\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2535e-04 - val_loss: 4.1399e-04\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6467e-04 - val_loss: 3.3971e-04\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9361e-04 - val_loss: 4.3065e-04\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.8153e-04 - val_loss: 5.8035e-04\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0598e-04 - val_loss: 3.2288e-04\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5996e-04 - val_loss: 3.1513e-04\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7260e-04 - val_loss: 3.4213e-04\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5608e-04 - val_loss: 6.3793e-04\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.1917e-04 - val_loss: 3.3071e-04\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5515e-04 - val_loss: 3.2800e-04\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5596e-04 - val_loss: 4.2445e-04\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.1518e-04 - val_loss: 3.1625e-04\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4410e-04 - val_loss: 3.2573e-04\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4376e-04 - val_loss: 3.1817e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4477e-04 - val_loss: 3.8155e-04\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9847e-04 - val_loss: 3.5943e-04\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4935e-04 - val_loss: 3.8052e-04\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7262e-04 - val_loss: 4.6277e-04\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5075e-04 - val_loss: 3.1701e-04\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7549e-04 - val_loss: 4.9554e-04\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5323e-04 - val_loss: 3.3542e-04\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4337e-04 - val_loss: 3.6522e-04\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0251e-04 - val_loss: 3.7061e-04\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.7894e-04 - val_loss: 4.5848e-04\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.8558e-04 - val_loss: 3.1642e-04\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5223e-04 - val_loss: 3.0610e-04\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0591e-04 - val_loss: 4.1567e-04\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5398e-04 - val_loss: 3.2736e-04\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.7085e-04 - val_loss: 3.0686e-04\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5517e-04 - val_loss: 3.2054e-04\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3073e-04 - val_loss: 3.0985e-04\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7854e-04 - val_loss: 3.4477e-04\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3186e-04 - val_loss: 3.1215e-04\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4283e-04 - val_loss: 3.8239e-04\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3928e-04 - val_loss: 3.4911e-04\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4545e-04 - val_loss: 3.3783e-04\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.8214e-04 - val_loss: 3.8425e-04\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4587e-04 - val_loss: 3.4689e-04\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4432e-04 - val_loss: 3.1264e-04\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4799e-04 - val_loss: 3.1303e-04\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3680e-04 - val_loss: 3.3245e-04\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3050e-04 - val_loss: 3.2099e-04\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6390e-04 - val_loss: 3.7138e-04\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7604e-04 - val_loss: 3.0077e-04\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2838e-04 - val_loss: 3.0852e-04\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2123e-04 - val_loss: 3.3495e-04\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4215e-04 - val_loss: 3.1930e-04\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3296e-04 - val_loss: 3.0525e-04\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2946e-04 - val_loss: 3.3123e-04\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5596e-04 - val_loss: 3.3348e-04\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5764e-04 - val_loss: 3.4596e-04\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5008e-04 - val_loss: 3.0109e-04\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3453e-04 - val_loss: 3.0082e-04\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5206e-04 - val_loss: 3.5470e-04\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6211e-04 - val_loss: 3.0641e-04\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6950e-04 - val_loss: 3.0668e-04\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3755e-04 - val_loss: 3.3327e-04\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6684e-04 - val_loss: 3.1780e-04\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5052e-04 - val_loss: 3.1301e-04\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3331e-04 - val_loss: 3.8147e-04\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7543e-04 - val_loss: 5.0999e-04\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7392e-04 - val_loss: 3.0007e-04\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3024e-04 - val_loss: 3.9466e-04\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3756e-04 - val_loss: 3.0310e-04\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2806e-04 - val_loss: 3.3745e-04\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3329e-04 - val_loss: 3.3400e-04\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4070e-04 - val_loss: 3.0139e-04\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2385e-04 - val_loss: 3.3282e-04\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2929e-04 - val_loss: 3.2503e-04\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2331e-04 - val_loss: 3.0467e-04\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5917e-04 - val_loss: 3.2286e-04\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6253e-04 - val_loss: 2.9640e-04\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.8881e-04 - val_loss: 4.7344e-04\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5232e-04 - val_loss: 3.7888e-04\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.1300e-04 - val_loss: 2.9609e-04\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3287e-04 - val_loss: 3.5238e-04\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3875e-04 - val_loss: 3.0060e-04\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4122e-04 - val_loss: 3.0228e-04\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7570e-04 - val_loss: 3.2619e-04\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.1845e-04 - val_loss: 3.2049e-04\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3551e-04 - val_loss: 3.6283e-04\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3933e-04 - val_loss: 3.0162e-04\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3063e-04 - val_loss: 2.9830e-04\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3211e-04 - val_loss: 3.0513e-04\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2163e-04 - val_loss: 3.8410e-04\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4406e-04 - val_loss: 3.0235e-04\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4040e-04 - val_loss: 3.1593e-04\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2733e-04 - val_loss: 3.0839e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4651e-04 - val_loss: 3.1951e-04\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2267e-04 - val_loss: 2.9974e-04\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2427e-04 - val_loss: 3.5488e-04\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2731e-04 - val_loss: 3.0438e-04\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2149e-04 - val_loss: 3.1388e-04\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.1915e-04 - val_loss: 3.0210e-04\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.2189e-04 - val_loss: 3.2747e-04\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0182e-04 - val_loss: 2.9319e-04\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4442e-04 - val_loss: 4.1619e-04\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.7467e-04 - val_loss: 3.0597e-04\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2256e-04 - val_loss: 3.0161e-04\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3178e-04 - val_loss: 3.4179e-04\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6767e-04 - val_loss: 2.9871e-04\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2210e-04 - val_loss: 3.0340e-04\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5201e-04 - val_loss: 3.0134e-04\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2297e-04 - val_loss: 3.8301e-04\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2569e-04 - val_loss: 3.5176e-04\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6240e-04 - val_loss: 3.2267e-04\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2613e-04 - val_loss: 3.0401e-04\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1845e-04 - val_loss: 3.0269e-04\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3648e-04 - val_loss: 3.0236e-04\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2799e-04 - val_loss: 3.0304e-04\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2521e-04 - val_loss: 3.3318e-04\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1795e-04 - val_loss: 3.5296e-04\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2595e-04 - val_loss: 3.0171e-04\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5202e-04 - val_loss: 3.0886e-04\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.6758e-04 - val_loss: 3.2286e-04\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2351e-04 - val_loss: 2.9639e-04\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2446e-04 - val_loss: 3.0474e-04\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4136e-04 - val_loss: 3.0742e-04\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1327e-04 - val_loss: 3.1702e-04\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2217e-04 - val_loss: 3.1831e-04\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4421e-04 - val_loss: 2.9547e-04\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2981e-04 - val_loss: 3.6701e-04\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.0014e-04 - val_loss: 2.9246e-04\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4720e-04 - val_loss: 2.9003e-04\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.5871e-04 - val_loss: 3.0207e-04\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2224e-04 - val_loss: 4.0477e-04\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4072e-04 - val_loss: 2.9343e-04\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4309e-04 - val_loss: 3.0817e-04\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2668e-04 - val_loss: 2.9860e-04\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3293e-04 - val_loss: 3.2329e-04\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2724e-04 - val_loss: 3.0999e-04\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1463e-04 - val_loss: 3.2131e-04\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.2924e-04 - val_loss: 3.0275e-04\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2084e-04 - val_loss: 3.2636e-04\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4004e-04 - val_loss: 4.0751e-04\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4161e-04 - val_loss: 3.3777e-04\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3669e-04 - val_loss: 2.9769e-04\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.3448e-04 - val_loss: 3.1585e-04\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3634e-04 - val_loss: 4.3874e-04\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.3072e-04 - val_loss: 3.1426e-04\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1999e-04 - val_loss: 3.1679e-04\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.3080e-04 - val_loss: 2.9876e-04\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2887e-04 - val_loss: 3.3037e-04\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.4265e-04 - val_loss: 3.1085e-04\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.4278e-04 - val_loss: 3.0095e-04\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.3761e-04 - val_loss: 3.5626e-04\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3404e-04 - val_loss: 3.1414e-04\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4276e-04 - val_loss: 3.0395e-04\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.2671e-04 - val_loss: 3.1572e-04\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2403e-04 - val_loss: 3.2558e-04\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.2776e-04 - val_loss: 3.1679e-04\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.1509e-04 - val_loss: 3.0233e-04\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.4449e-04 - val_loss: 3.1645e-04\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 3.3842e-04 - val_loss: 3.6324e-04\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 6s 97ms/step - loss: 0.0155 - val_loss: 0.0020\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 9.4551e-04\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0043 - val_loss: 7.5648e-04\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0011 - val_loss: 9.5518e-04\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0011 - val_loss: 6.4334e-04\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0018 - val_loss: 6.0424e-04\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 7.3853e-04 - val_loss: 5.3195e-04\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 8.2794e-04 - val_loss: 6.2223e-04\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 9.7929e-04 - val_loss: 9.7696e-04\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0013 - val_loss: 7.1787e-04\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 6.2060e-04 - val_loss: 4.3781e-04\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 8.7911e-04 - val_loss: 5.2021e-04\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0012 - val_loss: 5.8453e-04\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 6.0469e-04 - val_loss: 4.1025e-04\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 7.7825e-04 - val_loss: 4.6134e-04\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 6.1440e-04 - val_loss: 8.7165e-04\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.6839e-04 - val_loss: 3.8440e-04\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 8.8861e-04 - val_loss: 9.9951e-04\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 7.7268e-04 - val_loss: 8.7821e-04\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0014 - val_loss: 9.1278e-04\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 7.3341e-04 - val_loss: 3.6958e-04\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 6.6025e-04 - val_loss: 8.7336e-04\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0021 - val_loss: 4.6007e-04\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.7913e-04 - val_loss: 3.4242e-04\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.6293e-04 - val_loss: 4.7216e-04\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 4.7519e-04 - val_loss: 5.1525e-04\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 5.8903e-04 - val_loss: 6.4453e-04\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.5305e-04 - val_loss: 3.3373e-04\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 5.2503e-04 - val_loss: 4.1463e-04\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 6.1385e-04 - val_loss: 0.0020\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0016 - val_loss: 3.2415e-04\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.6151e-04 - val_loss: 5.9381e-04\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 4.2124e-04 - val_loss: 3.7077e-04\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9813e-04 - val_loss: 4.5438e-04\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 3.9343e-04 - val_loss: 5.3072e-04\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0011 - val_loss: 5.7690e-04\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.4202e-04 - val_loss: 3.1922e-04\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 4.4539e-04 - val_loss: 4.2014e-04\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 3.9595e-04 - val_loss: 3.3170e-04\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 5.1875e-04 - val_loss: 0.0012\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 7.8739e-04 - val_loss: 3.2551e-04\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 5.4090e-04 - val_loss: 3.9086e-04\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.0656e-04 - val_loss: 2.9821e-04\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 3.5311e-04 - val_loss: 3.7050e-04\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 4.4257e-04 - val_loss: 3.5473e-04\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 5.4850e-04 - val_loss: 0.0017\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 8.1198e-04 - val_loss: 4.2129e-04\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 5.3438e-04 - val_loss: 3.2769e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 4.0078e-04 - val_loss: 4.6524e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 7.0047e-04 - val_loss: 4.8473e-04\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 7.9482e-04 - val_loss: 3.2345e-04\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 8.7357e-04 - val_loss: 0.0015\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0010 - val_loss: 2.9617e-04\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.5644e-04 - val_loss: 3.8314e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.4145e-04 - val_loss: 2.9076e-04\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 7.3727e-04 - val_loss: 5.3264e-04\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.5240e-04 - val_loss: 2.9873e-04\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.3532e-04 - val_loss: 3.0187e-04\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 7.2796e-04 - val_loss: 0.0016\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 7.2995e-04 - val_loss: 3.1722e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.9387e-04 - val_loss: 8.2964e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 6.4506e-04 - val_loss: 0.0011\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 6.8237e-04 - val_loss: 3.2275e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 4.8307e-04 - val_loss: 2.8955e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.3892e-04 - val_loss: 3.1383e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.9504e-04 - val_loss: 4.1711e-04\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 4.9982e-04 - val_loss: 3.4822e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.6319e-04 - val_loss: 2.9976e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.6438e-04 - val_loss: 5.1136e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.1527e-04 - val_loss: 6.2093e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 6.3337e-04 - val_loss: 5.1631e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.8994e-04 - val_loss: 2.8461e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.3944e-04 - val_loss: 3.2213e-04\n",
      "Epoch 84/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 49ms/step - loss: 4.4613e-04 - val_loss: 3.0944e-04\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6026e-04 - val_loss: 3.2325e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6345e-04 - val_loss: 4.1818e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.9039e-04 - val_loss: 7.6815e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.8318e-04 - val_loss: 4.2913e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 6.1576e-04 - val_loss: 4.5243e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.9554e-04 - val_loss: 5.1406e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 6.7731e-04 - val_loss: 4.5100e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.8683e-04 - val_loss: 3.2784e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 3.8329e-04 - val_loss: 4.3766e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.6851e-04 - val_loss: 0.0022\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 8.1910e-04 - val_loss: 7.2760e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.8626e-04 - val_loss: 6.0324e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.7376e-04 - val_loss: 2.9208e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.4671e-04 - val_loss: 5.3684e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 5.7384e-04 - val_loss: 6.0858e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 4.2509e-04 - val_loss: 2.9878e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.6650e-04 - val_loss: 3.6290e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.5868e-04 - val_loss: 3.9923e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 3.2961e-04 - val_loss: 3.9501e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.8465e-04 - val_loss: 4.2705e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.9871e-04 - val_loss: 9.0461e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 3.8358e-04 - val_loss: 5.7857e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 6.3978e-04 - val_loss: 5.5420e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 4.0144e-04 - val_loss: 2.9588e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.6034e-04 - val_loss: 3.4738e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 3.4033e-04 - val_loss: 3.1519e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 3.2787e-04 - val_loss: 3.2843e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 5.6958e-04 - val_loss: 0.0015\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 7s 154ms/step - loss: 0.0381 - val_loss: 0.0095\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0030 - val_loss: 0.0089\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0015 - val_loss: 9.5808e-04\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0015 - val_loss: 9.0826e-04\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.0012 - val_loss: 7.5373e-04\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.0011 - val_loss: 8.0115e-04\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0017 - val_loss: 6.6637e-04\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.0010 - val_loss: 6.7074e-04\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.0011 - val_loss: 9.3479e-04\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 9.5031e-04 - val_loss: 6.1282e-04\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 9.1921e-04 - val_loss: 5.7358e-04\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 73ms/step - loss: 8.6527e-04 - val_loss: 0.0015\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.0015 - val_loss: 7.0030e-04\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 8.5834e-04 - val_loss: 0.0015\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 9.3891e-04 - val_loss: 7.7918e-04\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 7.7889e-04 - val_loss: 0.0016\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 9.5102e-04 - val_loss: 0.0016\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.0013 - val_loss: 5.4897e-04\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 8.2974e-04 - val_loss: 5.6073e-04\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 9.5998e-04 - val_loss: 6.1864e-04\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 74ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 8.5653e-04 - val_loss: 9.4842e-04\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 6.5985e-04 - val_loss: 5.4887e-04\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 6.7002e-04 - val_loss: 5.1511e-04\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 6.9680e-04 - val_loss: 0.0013\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 75ms/step - loss: 0.0012 - val_loss: 6.0885e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.0013 - val_loss: 9.5291e-04\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 74ms/step - loss: 6.2724e-04 - val_loss: 9.1579e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 74ms/step - loss: 7.2010e-04 - val_loss: 7.6656e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 9.2265e-04 - val_loss: 4.9896e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 7.4978e-04 - val_loss: 4.9727e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 6.8633e-04 - val_loss: 4.5166e-04\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 74ms/step - loss: 7.8479e-04 - val_loss: 0.0018\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 8.9344e-04 - val_loss: 5.3700e-04\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 5.8140e-04 - val_loss: 9.5350e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 5.8355e-04 - val_loss: 4.6829e-04\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 6.2559e-04 - val_loss: 6.1842e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 5.7025e-04 - val_loss: 4.1100e-04\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.0016 - val_loss: 8.8692e-04\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 6.0526e-04 - val_loss: 4.2132e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 6.1548e-04 - val_loss: 9.8758e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.0013 - val_loss: 5.9624e-04\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 5.0623e-04 - val_loss: 5.5521e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 4.7288e-04 - val_loss: 5.0298e-04\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 5.3845e-04 - val_loss: 3.7782e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 6.4243e-04 - val_loss: 0.0012\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 7.7472e-04 - val_loss: 7.5814e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 4.8151e-04 - val_loss: 6.3563e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 6.6867e-04 - val_loss: 0.0010\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 9.4750e-04 - val_loss: 4.0095e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 4.3660e-04 - val_loss: 5.2739e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 5.3156e-04 - val_loss: 3.6742e-04\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 5.3346e-04 - val_loss: 5.2305e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 4.7751e-04 - val_loss: 6.5841e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 8.5007e-04 - val_loss: 6.9344e-04\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 73ms/step - loss: 6.1097e-04 - val_loss: 4.2137e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 4.1839e-04 - val_loss: 0.0011\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 4.1577e-04 - val_loss: 8.0756e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 4.3206e-04 - val_loss: 3.4359e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 5.5635e-04 - val_loss: 0.0016\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 5.7282e-04 - val_loss: 4.2713e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 4.2840e-04 - val_loss: 3.2483e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 6.6014e-04 - val_loss: 0.0013\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 4.0320e-04 - val_loss: 9.4285e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 5.9159e-04 - val_loss: 3.2506e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 4.7393e-04 - val_loss: 7.2212e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 75ms/step - loss: 6.2008e-04 - val_loss: 0.0018\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 6.1234e-04 - val_loss: 0.0015\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 6.8267e-04 - val_loss: 3.7635e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 4.3020e-04 - val_loss: 3.4325e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 4.7622e-04 - val_loss: 3.1070e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 75ms/step - loss: 5.5486e-04 - val_loss: 3.2291e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 3.9839e-04 - val_loss: 3.0963e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 74ms/step - loss: 7.7072e-04 - val_loss: 0.0013\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 4.9081e-04 - val_loss: 3.9272e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 4.0879e-04 - val_loss: 5.0408e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 5.1294e-04 - val_loss: 4.2786e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 4.5501e-04 - val_loss: 0.0016\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0012 - val_loss: 3.7969e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 4.0609e-04 - val_loss: 3.9675e-04\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 3.8978e-04 - val_loss: 3.7733e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 3.9445e-04 - val_loss: 7.3383e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 4.2464e-04 - val_loss: 4.6922e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 5.1357e-04 - val_loss: 3.1177e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 4.1212e-04 - val_loss: 3.8525e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 3.9204e-04 - val_loss: 6.1689e-04\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 8.5593e-04 - val_loss: 6.1729e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 4.3762e-04 - val_loss: 4.7928e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 3.5289e-04 - val_loss: 3.3150e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 6.4393e-04 - val_loss: 8.2717e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 4.7461e-04 - val_loss: 4.9441e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 98ms/step - loss: 4.1709e-04 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 4.2035e-04 - val_loss: 3.6499e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 4.3372e-04 - val_loss: 8.0520e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 5.1737e-04 - val_loss: 0.0010\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 4.0460e-04 - val_loss: 8.6790e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 6.5801e-04 - val_loss: 3.6830e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 6.1021e-04 - val_loss: 0.0012\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 4.4607e-04 - val_loss: 3.5328e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 73ms/step - loss: 4.6272e-04 - val_loss: 3.5343e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 3.8065e-04 - val_loss: 3.8013e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 6.6230e-04 - val_loss: 3.1130e-04\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 5.9459e-04 - val_loss: 0.0010\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 7s 198ms/step - loss: 0.1672 - val_loss: 0.0928\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0553 - val_loss: 0.0157\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0254 - val_loss: 0.0048\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0129 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 6s 224ms/step - loss: 0.0653 - val_loss: 0.0062\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0120 - val_loss: 0.0014\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.0012 - val_loss: 9.0634e-04\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.0011 - val_loss: 7.7540e-04\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0035 - val_loss: 0.0256\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0088 - val_loss: 0.0012\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0013 - val_loss: 8.0428e-04\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 9.9081e-04 - val_loss: 0.0010\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0010 - val_loss: 9.4137e-04\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.0012 - val_loss: 7.3195e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 9.8480e-04 - val_loss: 0.0019\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0029 - val_loss: 6.2560e-04\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 8.7252e-04 - val_loss: 0.0014\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.0010 - val_loss: 5.9642e-04\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 9.1365e-04 - val_loss: 5.9892e-04\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 7.8096e-04 - val_loss: 6.0164e-04\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 8.6416e-04 - val_loss: 6.2165e-04\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 7.5134e-04 - val_loss: 6.1732e-04\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 8.8222e-04 - val_loss: 0.0027\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0013 - val_loss: 7.7877e-04\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 9.8118e-04 - val_loss: 5.2009e-04\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 6.9239e-04 - val_loss: 6.9812e-04\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 7.5170e-04 - val_loss: 5.0435e-04\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 6.6299e-04 - val_loss: 5.5638e-04\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 7.4243e-04 - val_loss: 5.2530e-04\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 7.0918e-04 - val_loss: 9.0034e-04\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0012 - val_loss: 8.7680e-04\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 7.8944e-04 - val_loss: 0.0013\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0015 - val_loss: 8.5080e-04\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.0021 - val_loss: 5.6347e-04\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 6.8089e-04 - val_loss: 4.9018e-04\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.9290e-04 - val_loss: 4.7055e-04\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.0552e-04 - val_loss: 5.5955e-04\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.6917e-04 - val_loss: 5.8846e-04\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 5.9436e-04 - val_loss: 5.9567e-04\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 8.1685e-04 - val_loss: 9.5587e-04\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0015 - val_loss: 4.5515e-04\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 8.1266e-04 - val_loss: 9.8564e-04\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 7.4925e-04 - val_loss: 4.6492e-04\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 6.8490e-04 - val_loss: 4.9665e-04\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 5.1869e-04 - val_loss: 4.8806e-04\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 5.6726e-04 - val_loss: 4.8296e-04\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 6.1209e-04 - val_loss: 5.3276e-04\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 5.2849e-04 - val_loss: 4.0453e-04\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 5.4900e-04 - val_loss: 6.2633e-04\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0018 - val_loss: 4.2298e-04\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 4.8794e-04 - val_loss: 4.2393e-04\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 5.6660e-04 - val_loss: 0.0010\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 6.3577e-04 - val_loss: 4.0927e-04\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.8134e-04 - val_loss: 3.7519e-04\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 5.0759e-04 - val_loss: 3.9689e-04\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 4.7800e-04 - val_loss: 3.6626e-04\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.5904e-04 - val_loss: 4.6782e-04\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 4.7181e-04 - val_loss: 4.5837e-04\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.0168e-04 - val_loss: 9.2501e-04\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0011 - val_loss: 5.2109e-04\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 6.8204e-04 - val_loss: 8.3540e-04\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 7.5687e-04 - val_loss: 9.3255e-04\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 9.4424e-04 - val_loss: 0.0019\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0011 - val_loss: 8.4985e-04\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 7.7965e-04 - val_loss: 0.0011\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 9.9116e-04 - val_loss: 4.3520e-04\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 5.3054e-04 - val_loss: 6.4045e-04\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.5857e-04 - val_loss: 3.9603e-04\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.4685e-04 - val_loss: 3.9823e-04\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.2324e-04 - val_loss: 3.8021e-04\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.8470e-04 - val_loss: 3.5784e-04\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.7518e-04 - val_loss: 4.3873e-04\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.3256e-04 - val_loss: 5.7173e-04\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.9805e-04 - val_loss: 0.0013\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0013 - val_loss: 4.4611e-04\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 4.7522e-04 - val_loss: 4.5583e-04\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 5.6743e-04 - val_loss: 4.6496e-04\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 7.0610e-04 - val_loss: 4.9305e-04\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 6.7210e-04 - val_loss: 3.6528e-04\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.1867e-04 - val_loss: 4.1534e-04\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.0667e-04 - val_loss: 3.3173e-04\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 5.6689e-04 - val_loss: 0.0013\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 9.4378e-04 - val_loss: 3.8957e-04\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.8107e-04 - val_loss: 3.3739e-04\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.5419e-04 - val_loss: 3.3574e-04\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.9319e-04 - val_loss: 3.3052e-04\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.9019e-04 - val_loss: 5.4426e-04\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 6.3028e-04 - val_loss: 4.0424e-04\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.2623e-04 - val_loss: 8.7182e-04\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 7.0174e-04 - val_loss: 3.6317e-04\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 4.8750e-04 - val_loss: 6.4582e-04\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 5.8695e-04 - val_loss: 4.0195e-04\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 6.1615e-04 - val_loss: 9.6074e-04\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 6.9742e-04 - val_loss: 7.6995e-04\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 8.8700e-04 - val_loss: 9.5296e-04\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.0011 - val_loss: 8.6872e-04\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 6.3747e-04 - val_loss: 3.2943e-04\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.1154e-04 - val_loss: 3.5491e-04\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.8651e-04 - val_loss: 3.7744e-04\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.9549e-04 - val_loss: 3.2383e-04\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.8742e-04 - val_loss: 3.2416e-04\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.0107e-04 - val_loss: 3.1598e-04\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.8830e-04 - val_loss: 4.7660e-04\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 9.4454e-04 - val_loss: 5.5397e-04\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 7.4619e-04 - val_loss: 4.5097e-04\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 4.5659e-04 - val_loss: 3.2692e-04\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.6692e-04 - val_loss: 4.0705e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 5.9206e-04 - val_loss: 4.2167e-04\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.9204e-04 - val_loss: 4.4776e-04\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.6357e-04 - val_loss: 8.1273e-04\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 9.5050e-04 - val_loss: 4.7115e-04\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 7.5255e-04 - val_loss: 4.6638e-04\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.0705e-04 - val_loss: 3.1059e-04\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.7407e-04 - val_loss: 5.6877e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 4.0224e-04 - val_loss: 6.0384e-04\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.4384e-04 - val_loss: 3.6009e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.9790e-04 - val_loss: 4.5598e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 4.6286e-04 - val_loss: 6.8575e-04\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 6.7012e-04 - val_loss: 3.7553e-04\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.5404e-04 - val_loss: 3.2678e-04\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.7179e-04 - val_loss: 3.2672e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.8151e-04 - val_loss: 0.0012\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 6.2980e-04 - val_loss: 3.9204e-04\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.3031e-04 - val_loss: 5.5119e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.8673e-04 - val_loss: 3.4828e-04\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 7.3879e-04 - val_loss: 0.0017\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 6.8571e-04 - val_loss: 4.4766e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 7.3694e-04 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 9.6701e-04 - val_loss: 5.3157e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 6.6207e-04 - val_loss: 5.8761e-04\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 6.6426e-04 - val_loss: 8.9068e-04\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 7.5326e-04 - val_loss: 3.1154e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.5048e-04 - val_loss: 3.0573e-04\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.6678e-04 - val_loss: 3.6605e-04\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.1693e-04 - val_loss: 4.5454e-04\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.0285e-04 - val_loss: 3.2708e-04\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.5100e-04 - val_loss: 3.2266e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.5390e-04 - val_loss: 3.0397e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.4300e-04 - val_loss: 3.5392e-04\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 4.8118e-04 - val_loss: 0.0014\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 8.5044e-04 - val_loss: 3.7160e-04\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.7526e-04 - val_loss: 3.0078e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.9489e-04 - val_loss: 3.9361e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.8506e-04 - val_loss: 3.0030e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.5144e-04 - val_loss: 4.6400e-04\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.8820e-04 - val_loss: 7.2865e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 9.9574e-04 - val_loss: 8.9669e-04\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 5.4395e-04 - val_loss: 3.6612e-04\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 4.4146e-04 - val_loss: 3.5105e-04\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 3.8561e-04 - val_loss: 4.4079e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.9501e-04 - val_loss: 3.6257e-04\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 3.5234e-04 - val_loss: 4.1077e-04\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.5182e-04 - val_loss: 2.9870e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.4028e-04 - val_loss: 3.0881e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.7422e-04 - val_loss: 3.8720e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 5.0006e-04 - val_loss: 6.7496e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 6.9038e-04 - val_loss: 8.1612e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 8.4290e-04 - val_loss: 4.9311e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 4.2474e-04 - val_loss: 3.3188e-04\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 6.0339e-04 - val_loss: 0.0023\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 8.1554e-04 - val_loss: 3.2442e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 3.9011e-04 - val_loss: 4.0805e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 4.8036e-04 - val_loss: 9.6790e-04\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 6.0322e-04 - val_loss: 4.1272e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 7.3168e-04 - val_loss: 5.7491e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 5.8485e-04 - val_loss: 3.1787e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.7250e-04 - val_loss: 3.2491e-04\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.7521e-04 - val_loss: 3.6035e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.8418e-04 - val_loss: 3.1635e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.3395e-04 - val_loss: 3.0334e-04\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.3950e-04 - val_loss: 2.9564e-04\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.4176e-04 - val_loss: 3.2158e-04\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.5740e-04 - val_loss: 2.9453e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.3409e-04 - val_loss: 3.4105e-04\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 3.4687e-04 - val_loss: 3.7852e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 4.3338e-04 - val_loss: 4.6711e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 3.6649e-04 - val_loss: 3.4483e-04\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4759e-04 - val_loss: 5.3796e-04\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 5.8252e-04 - val_loss: 4.4929e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 5.9244e-04 - val_loss: 5.4177e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.7455e-04 - val_loss: 2.8932e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 4.1961e-04 - val_loss: 5.0272e-04\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 7.1933e-04 - val_loss: 5.0145e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 3.9761e-04 - val_loss: 3.7974e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.4886e-04 - val_loss: 3.5859e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 3.6542e-04 - val_loss: 3.4452e-04\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.7159e-04 - val_loss: 6.2569e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 5.3070e-04 - val_loss: 3.7822e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.9054e-04 - val_loss: 3.0625e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 3.6185e-04 - val_loss: 4.9019e-04\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 4.2761e-04 - val_loss: 4.7008e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 4.5554e-04 - val_loss: 0.0015\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.0011 - val_loss: 8.1017e-04\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.5699e-04 - val_loss: 3.1327e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 4.1982e-04 - val_loss: 6.0054e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 4.1937e-04 - val_loss: 4.6243e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.2094e-04 - val_loss: 2.9552e-04\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.9872e-04 - val_loss: 6.2042e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.6764e-04 - val_loss: 4.0492e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.0714e-04 - val_loss: 4.1553e-04\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 3.2947e-04 - val_loss: 3.2188e-04\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.3097e-04 - val_loss: 3.0242e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.3029e-04 - val_loss: 2.8660e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.3382e-04 - val_loss: 2.8976e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4093e-04 - val_loss: 3.1588e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.5270e-04 - val_loss: 3.0088e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4363e-04 - val_loss: 3.2776e-04\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.0694e-04 - val_loss: 7.1449e-04\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 5.4912e-04 - val_loss: 6.0042e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 6.0384e-04 - val_loss: 4.3522e-04\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.6163e-04 - val_loss: 3.8372e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 7.6467e-04 - val_loss: 5.1365e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 5.3345e-04 - val_loss: 8.1261e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.6593e-04 - val_loss: 2.9304e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.2985e-04 - val_loss: 3.4342e-04\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 4.2010e-04 - val_loss: 3.9484e-04\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.1314e-04 - val_loss: 3.9038e-04\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 4.5025e-04 - val_loss: 3.6592e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.2490e-04 - val_loss: 3.4526e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.7288e-04 - val_loss: 3.3068e-04\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.5108e-04 - val_loss: 3.0761e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.3866e-04 - val_loss: 6.4912e-04\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 9.6071e-04 - val_loss: 0.0021\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.0012 - val_loss: 4.5379e-04\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.4705e-04 - val_loss: 3.3920e-04\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.2979e-04 - val_loss: 2.8658e-04\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.3826e-04 - val_loss: 2.9317e-04\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.5764e-04 - val_loss: 3.1533e-04\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4782e-04 - val_loss: 3.1382e-04\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.6834e-04 - val_loss: 6.5724e-04\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 6.4720e-04 - val_loss: 5.3150e-04\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.9056e-04 - val_loss: 3.1276e-04\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.2977e-04 - val_loss: 3.0378e-04\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 3.2286e-04 - val_loss: 2.8485e-04\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.3723e-04 - val_loss: 5.5647e-04\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 4.3054e-04 - val_loss: 2.9474e-04\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.4242e-04 - val_loss: 2.8570e-04\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.2612e-04 - val_loss: 3.0062e-04\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.5020e-04 - val_loss: 3.0135e-04\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.6372e-04 - val_loss: 5.7586e-04\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 5.6692e-04 - val_loss: 4.0324e-04\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.6567e-04 - val_loss: 5.7715e-04\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.7428e-04 - val_loss: 3.0443e-04\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 3.7869e-04 - val_loss: 2.9039e-04\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.2340e-04 - val_loss: 2.8698e-04\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 3.2482e-04 - val_loss: 2.8871e-04\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.3173e-04 - val_loss: 3.2983e-04\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.2240e-04 - val_loss: 2.8936e-04\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.4896e-04 - val_loss: 2.8817e-04\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 3.2954e-04 - val_loss: 5.4669e-04\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 4.1439e-04 - val_loss: 3.3748e-04\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.6098e-04 - val_loss: 0.0010\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 4.9373e-04 - val_loss: 3.2153e-04\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 4.0251e-04 - val_loss: 3.6024e-04\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 3.5236e-04 - val_loss: 2.9072e-04\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 4.0282e-04 - val_loss: 4.8577e-04\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 4.5742e-04 - val_loss: 6.1351e-04\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 4.6269e-04 - val_loss: 4.7759e-04\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.9472e-04 - val_loss: 3.1242e-04\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.4266e-04 - val_loss: 3.0421e-04\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3038e-04 - val_loss: 3.7032e-04\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 3.6095e-04 - val_loss: 3.3264e-04\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 3.3226e-04 - val_loss: 4.7800e-04\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 5.2290e-04 - val_loss: 0.0010\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 7s 274ms/step - loss: 0.0976 - val_loss: 0.0045\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0051 - val_loss: 0.0093\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0048 - val_loss: 0.0157\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0032 - val_loss: 0.0245\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 0.0034 - val_loss: 0.0068\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0035 - val_loss: 0.0097\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0039 - val_loss: 0.0095\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0029 - val_loss: 0.0080\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0023 - val_loss: 9.8631e-04\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0023 - val_loss: 8.7486e-04\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0023 - val_loss: 8.6097e-04\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 8.6991e-04\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0011 - val_loss: 7.7680e-04\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0015 - val_loss: 9.0839e-04\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0011 - val_loss: 6.6744e-04\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0021 - val_loss: 6.7227e-04\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0019 - val_loss: 9.5049e-04\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 9.7622e-04 - val_loss: 0.0016\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0024 - val_loss: 7.5080e-04\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 9.8123e-04 - val_loss: 0.0012\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 9.2269e-04 - val_loss: 9.0352e-04\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0012 - val_loss: 7.9946e-04\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 8.7057e-04 - val_loss: 0.0028\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 9.8867e-04 - val_loss: 7.4076e-04\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0010 - val_loss: 8.0155e-04\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.4025e-04 - val_loss: 0.0015\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 7.9324e-04 - val_loss: 7.1108e-04\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0011 - val_loss: 7.5970e-04\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 7.6068e-04 - val_loss: 7.5919e-04\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 7.3257e-04 - val_loss: 8.2441e-04\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 8.3572e-04 - val_loss: 7.2389e-04\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 9.2549e-04 - val_loss: 5.8497e-04\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 9.6878e-04 - val_loss: 9.4222e-04\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 6.9561e-04 - val_loss: 8.6548e-04\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.2337e-04 - val_loss: 6.6346e-04\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 8.5522e-04 - val_loss: 0.0018\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0011 - val_loss: 8.2510e-04\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 6.6222e-04 - val_loss: 6.2700e-04\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 8.3423e-04 - val_loss: 0.0020\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.3168e-04 - val_loss: 5.7642e-04\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 6.7837e-04 - val_loss: 5.1714e-04\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 8.9165e-04 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.3648e-04 - val_loss: 6.1301e-04\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.3841e-04 - val_loss: 9.1317e-04\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 6.1074e-04 - val_loss: 0.0011\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 9.1058e-04 - val_loss: 5.1635e-04\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0011 - val_loss: 5.2178e-04\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 9.5620e-04 - val_loss: 0.0019\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 7.4507e-04 - val_loss: 0.0014\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 9.2081e-04 - val_loss: 4.8729e-04\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 7.6311e-04 - val_loss: 0.0013\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 5.7086e-04 - val_loss: 6.4317e-04\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 5.4085e-04 - val_loss: 5.5834e-04\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 5.8886e-04 - val_loss: 8.5909e-04\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 5.9577e-04 - val_loss: 4.4737e-04\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 9.5100e-04 - val_loss: 0.0013\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 6.5478e-04 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 7.4913e-04 - val_loss: 6.5216e-04\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 8.6454e-04 - val_loss: 0.0024\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.0013 - val_loss: 5.2008e-04\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 9.6621e-04 - val_loss: 0.0018\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 5.7360e-04 - val_loss: 5.0205e-04\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 5.3485e-04 - val_loss: 4.7224e-04\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 5.0385e-04 - val_loss: 5.9781e-04\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 6.7534e-04 - val_loss: 0.0037\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.0015 - val_loss: 5.9465e-04\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 6.0206e-04 - val_loss: 4.3622e-04\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 7.3496e-04 - val_loss: 0.0032\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0018 - val_loss: 5.7554e-04\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 6.2985e-04 - val_loss: 6.7792e-04\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 5.9564e-04 - val_loss: 8.4222e-04\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.0567e-04 - val_loss: 7.4532e-04\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 5.2815e-04 - val_loss: 9.5036e-04\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 5.2820e-04 - val_loss: 6.1937e-04\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 5.7290e-04 - val_loss: 4.1762e-04\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 6.3397e-04 - val_loss: 0.0011\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 4.7198e-04 - val_loss: 4.9403e-04\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 8.5223e-04 - val_loss: 0.0017\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 8.6033e-04 - val_loss: 0.0013\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 8.6119e-04 - val_loss: 6.2211e-04\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.7163e-04 - val_loss: 7.0607e-04\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.3573e-04 - val_loss: 7.9493e-04\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.5515e-04 - val_loss: 6.0788e-04\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.4201e-04 - val_loss: 3.9953e-04\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.4804e-04 - val_loss: 4.0970e-04\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.5999e-04 - val_loss: 4.8005e-04\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.6971e-04 - val_loss: 9.3520e-04\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.2881e-04 - val_loss: 4.3275e-04\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 7.7325e-04 - val_loss: 4.1686e-04\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0022 - val_loss: 4.1829e-04\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.4233e-04 - val_loss: 9.4045e-04\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.3465e-04 - val_loss: 5.4682e-04\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 4.3608e-04 - val_loss: 0.0010\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 5.7267e-04 - val_loss: 3.9830e-04\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 4.4842e-04 - val_loss: 4.2689e-04\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.2124e-04 - val_loss: 3.7435e-04\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 8.0137e-04 - val_loss: 0.0014\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 4.6723e-04 - val_loss: 4.9806e-04\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 5.0596e-04 - val_loss: 9.1003e-04\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 5.2095e-04 - val_loss: 0.0012\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.8881e-04 - val_loss: 3.7035e-04\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 5.1390e-04 - val_loss: 5.7858e-04\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.0528e-04 - val_loss: 0.0011\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 4.1057e-04 - val_loss: 4.3529e-04\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 4.0156e-04 - val_loss: 7.8070e-04\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 3.9514e-04 - val_loss: 4.3528e-04\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.8083e-04 - val_loss: 3.4327e-04\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 5.8343e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 7.2718e-04 - val_loss: 5.3183e-04\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0012 - val_loss: 6.0674e-04\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.3879e-04 - val_loss: 6.6037e-04\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 3.9661e-04 - val_loss: 9.7706e-04\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 4.6688e-04 - val_loss: 3.7688e-04\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 4.0753e-04 - val_loss: 9.3432e-04\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.7571e-04 - val_loss: 7.5243e-04\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 5.0132e-04 - val_loss: 3.2892e-04\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.9694e-04 - val_loss: 3.1893e-04\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 7.4997e-04 - val_loss: 0.0061\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0023 - val_loss: 8.9620e-04\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 8.9046e-04 - val_loss: 6.4543e-04\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.8361e-04 - val_loss: 9.6412e-04\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.1042e-04 - val_loss: 7.2879e-04\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.7123e-04 - val_loss: 4.8991e-04\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.5867e-04 - val_loss: 6.6985e-04\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.3234e-04 - val_loss: 4.2145e-04\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 7.1317e-04 - val_loss: 8.3454e-04\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 4.1444e-04 - val_loss: 3.9176e-04\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 3.7451e-04 - val_loss: 6.4293e-04\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.3515e-04 - val_loss: 3.9111e-04\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 4.2678e-04 - val_loss: 3.5451e-04\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 4.5215e-04 - val_loss: 6.0886e-04\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 3.6517e-04 - val_loss: 3.2496e-04\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 3.8709e-04 - val_loss: 4.0802e-04\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 6.7572e-04 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 5.4442e-04 - val_loss: 3.7368e-04\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 7.6210e-04 - val_loss: 0.0014\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 4.5564e-04 - val_loss: 3.1735e-04\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 4.0534e-04 - val_loss: 4.6359e-04\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 4.0479e-04 - val_loss: 9.6140e-04\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 5.2862e-04 - val_loss: 5.4117e-04\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 6.1823e-04 - val_loss: 0.0016\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.9391e-04 - val_loss: 3.8435e-04\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 5.2281e-04 - val_loss: 6.9529e-04\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 4.4600e-04 - val_loss: 6.8181e-04\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.0492e-04 - val_loss: 3.4516e-04\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 4.8407e-04 - val_loss: 0.0010\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 4.7261e-04 - val_loss: 3.8937e-04\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 4.6217e-04 - val_loss: 0.0018\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 6.1704e-04 - val_loss: 3.3652e-04\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 3.5769e-04 - val_loss: 3.4721e-04\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 4.7427e-04 - val_loss: 8.7200e-04\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 4.4577e-04 - val_loss: 3.7657e-04\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 5.8517e-04 - val_loss: 0.0013\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.3334e-04 - val_loss: 6.2433e-04\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.7449e-04 - val_loss: 4.2670e-04\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 3.5851e-04 - val_loss: 4.7909e-04\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 4.0773e-04 - val_loss: 8.0660e-04\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 4.5851e-04 - val_loss: 3.5341e-04\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 5.0769e-04 - val_loss: 5.6773e-04\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 5.1236e-04 - val_loss: 0.0015\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 4.5622e-04 - val_loss: 4.2781e-04\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.3938e-04 - val_loss: 3.6943e-04\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 5.8140e-04 - val_loss: 6.3615e-04\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 3.4640e-04 - val_loss: 4.0038e-04\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.7080e-04 - val_loss: 3.4232e-04\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 3.6656e-04 - val_loss: 3.9867e-04\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 3.5765e-04 - val_loss: 9.3609e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>902.148536</td>\n",
       "      <td>0.982960</td>\n",
       "      <td>nadam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>903.274280</td>\n",
       "      <td>0.982918</td>\n",
       "      <td>nadam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>903.417030</td>\n",
       "      <td>0.982912</td>\n",
       "      <td>nadam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>903.494269</td>\n",
       "      <td>0.982909</td>\n",
       "      <td>adamax</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>903.717788</td>\n",
       "      <td>0.982901</td>\n",
       "      <td>adamax</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>903.795234</td>\n",
       "      <td>0.982898</td>\n",
       "      <td>nadam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>904.845017</td>\n",
       "      <td>0.982858</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>905.096685</td>\n",
       "      <td>0.982849</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>905.816853</td>\n",
       "      <td>0.982821</td>\n",
       "      <td>adam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>906.238094</td>\n",
       "      <td>0.982805</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>907.060445</td>\n",
       "      <td>0.982774</td>\n",
       "      <td>adamax</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>909.170834</td>\n",
       "      <td>0.982694</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>910.185901</td>\n",
       "      <td>0.982655</td>\n",
       "      <td>adamax</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>910.858784</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>adamax</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>911.977408</td>\n",
       "      <td>0.982587</td>\n",
       "      <td>nadam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>912.129902</td>\n",
       "      <td>0.982581</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>912.599501</td>\n",
       "      <td>0.982563</td>\n",
       "      <td>adamax</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>913.266630</td>\n",
       "      <td>0.982538</td>\n",
       "      <td>adam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>913.590802</td>\n",
       "      <td>0.982525</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>914.609585</td>\n",
       "      <td>0.982486</td>\n",
       "      <td>nadam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>916.239264</td>\n",
       "      <td>0.982424</td>\n",
       "      <td>adam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>917.096106</td>\n",
       "      <td>0.982391</td>\n",
       "      <td>adamax</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>918.477467</td>\n",
       "      <td>0.982338</td>\n",
       "      <td>nadam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>920.529481</td>\n",
       "      <td>0.982259</td>\n",
       "      <td>adamax</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>922.313970</td>\n",
       "      <td>0.982190</td>\n",
       "      <td>adamax</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>925.582864</td>\n",
       "      <td>0.982064</td>\n",
       "      <td>nadam</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>926.424069</td>\n",
       "      <td>0.982031</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>934.674131</td>\n",
       "      <td>0.981709</td>\n",
       "      <td>adamax</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>942.285343</td>\n",
       "      <td>0.981410</td>\n",
       "      <td>nadam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>953.957302</td>\n",
       "      <td>0.980947</td>\n",
       "      <td>nadam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>967.701734</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>nadam</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2006.984062</td>\n",
       "      <td>0.915668</td>\n",
       "      <td>nadam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2183.969068</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2232.441299</td>\n",
       "      <td>0.895656</td>\n",
       "      <td>adamax</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2331.426187</td>\n",
       "      <td>0.886198</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2434.013894</td>\n",
       "      <td>0.875963</td>\n",
       "      <td>adamax</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm         rmse        r2 optimizer  batch\n",
       "1       gru   902.148536  0.982960     nadam     16\n",
       "1       gru   903.274280  0.982918     nadam     32\n",
       "1       gru   903.417030  0.982912     nadam     64\n",
       "1       gru   903.494269  0.982909    adamax     16\n",
       "1       gru   903.717788  0.982901    adamax     32\n",
       "1       gru   903.795234  0.982898     nadam    128\n",
       "1       gru   904.845017  0.982858      adam    128\n",
       "1       gru   905.096685  0.982849      adam     32\n",
       "1       gru   905.816853  0.982821      adam     16\n",
       "1       gru   906.238094  0.982805      adam     64\n",
       "2   lstmgru   907.060445  0.982774    adamax     16\n",
       "2   lstmgru   909.170834  0.982694      adam     64\n",
       "1       gru   910.185901  0.982655    adamax     64\n",
       "1       gru   910.858784  0.982630    adamax    128\n",
       "0      lstm   911.977408  0.982587     nadam     64\n",
       "2   lstmgru   912.129902  0.982581      adam     32\n",
       "2   lstmgru   912.599501  0.982563    adamax     32\n",
       "2   lstmgru   913.266630  0.982538      adam     16\n",
       "0      lstm   913.590802  0.982525      adam     32\n",
       "0      lstm   914.609585  0.982486     nadam     32\n",
       "0      lstm   916.239264  0.982424      adam     16\n",
       "0      lstm   917.096106  0.982391    adamax     16\n",
       "0      lstm   918.477467  0.982338     nadam     16\n",
       "2   lstmgru   920.529481  0.982259    adamax     64\n",
       "0      lstm   922.313970  0.982190    adamax     32\n",
       "2   lstmgru   925.582864  0.982064     nadam     32\n",
       "2   lstmgru   926.424069  0.982031      adam    128\n",
       "2   lstmgru   934.674131  0.981709    adamax    128\n",
       "2   lstmgru   942.285343  0.981410     nadam     64\n",
       "2   lstmgru   953.957302  0.980947     nadam    128\n",
       "2   lstmgru   967.701734  0.980394     nadam     16\n",
       "0      lstm  2006.984062  0.915668     nadam    128\n",
       "0      lstm  2183.969068  0.900138      adam    128\n",
       "0      lstm  2232.441299  0.895656    adamax    128\n",
       "0      lstm  2331.426187  0.886198      adam     64\n",
       "0      lstm  2434.013894  0.875963    adamax     64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "optimizer_li = ['adam','adamax', 'nadam']\n",
    "batch_li = [16, 32, 64 ,128]\n",
    "df_li = []\n",
    "\n",
    "for opt in optimizer_li :\n",
    "    for batch in batch_li :\n",
    "\n",
    "\n",
    "        df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "        scaler=MinMaxScaler(feature_range=(0,1))\n",
    "        sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "        max_val = max(df['종가'])\n",
    "        min_val = min(df['종가'])\n",
    "\n",
    "        training_size=int(len(sdf)*0.70)\n",
    "        test_size=len(sdf)-training_size\n",
    "        train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "        def create_dataset(dataset, time_step=1):\n",
    "            dataX, dataY = [], []\n",
    "            for i in range(len(dataset)-time_step-1):\n",
    "                a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "                dataX.append(a)\n",
    "                dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "            return np.array(dataX), np.array(dataY)\n",
    "\n",
    "        time_step = 15\n",
    "        X_train, y_train = create_dataset(train_data, time_step)\n",
    "        X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model=Sequential()\n",
    "        model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "        model.add(LSTM(16, return_sequences=False))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "        stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "        model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                  epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "        train_predict=model.predict(X_train)\n",
    "        test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "        train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "        test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "        y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "        lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "        lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "        df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "        scaler=MinMaxScaler(feature_range=(0,1))\n",
    "        sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "        max_val = max(df['종가'])\n",
    "        min_val = min(df['종가'])\n",
    "\n",
    "        training_size=int(len(sdf)*0.70)\n",
    "        test_size=len(sdf)-training_size\n",
    "        train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "        def create_dataset(dataset, time_step=1):\n",
    "            dataX, dataY = [], []\n",
    "            for i in range(len(dataset)-time_step-1):\n",
    "                a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "                dataX.append(a)\n",
    "                dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "            return np.array(dataX), np.array(dataY)\n",
    "\n",
    "        time_step = 15\n",
    "        X_train, y_train = create_dataset(train_data, time_step)\n",
    "        X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model=Sequential()\n",
    "        model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "        model.add(GRU(64,return_sequences=True))\n",
    "        model.add(GRU(64))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "        model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                  epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "        train_predict=model.predict(X_train)\n",
    "        test_predict=model.predict(X_test)\n",
    "        train_predict.shape, test_predict.shape\n",
    "\n",
    "        train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "        test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "        y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "        gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "        gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "        df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "        scaler=MinMaxScaler(feature_range=(0,1))\n",
    "        sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "        max_val = max(df['종가'])\n",
    "        min_val = min(df['종가'])\n",
    "\n",
    "        training_size=int(len(sdf)*0.70)\n",
    "        test_size=len(sdf)-training_size\n",
    "        train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "        def create_dataset(dataset, time_step=1):\n",
    "            dataX, dataY = [], []\n",
    "            for i in range(len(dataset)-time_step-1):\n",
    "                a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "                dataX.append(a)\n",
    "                dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "            return np.array(dataX), np.array(dataY)\n",
    "\n",
    "        time_step = 15\n",
    "        X_train, y_train = create_dataset(train_data, time_step)\n",
    "        X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model=Sequential()\n",
    "        model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "        model.add(LSTM(64,return_sequences=True))\n",
    "        model.add(GRU(64,return_sequences=True))\n",
    "        model.add(GRU(64))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "\n",
    "        model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                  epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "        train_predict=model.predict(X_train)\n",
    "        test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "        train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "        test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "        y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "        lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "        lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "        algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "        rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "        r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "        data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "                'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "                'r2': [lstm_r2, gru_r2, lstmgru_r2],\n",
    "               'optimizer':[opt, opt, opt],\n",
    "               'batch':[batch, batch, batch]}\n",
    "\n",
    "        comparison1 = pd.DataFrame(data)\n",
    "        df_li.append(comparison1)\n",
    "merged_df = pd.concat(df_li, axis=0)\n",
    "merged_df = merged_df.sort_values(['r2'], ascending=False)\n",
    "merged_df.to_csv('./ts_hyper01.csv', encoding='cp949', index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "optimizer_li = ['adam','adamax', 'nadam']\n",
    "batch_li = [16, 32, 64 ,128]\n",
    "dropout_li = [0.1, 0.15, 0.2]\n",
    "df_li = []\n",
    "\n",
    "for opt in optimizer_li :\n",
    "    for batch in batch_li :\n",
    "        for do in dropout_li :\n",
    "\n",
    "\n",
    "            df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "            scaler=MinMaxScaler(feature_range=(0,1))\n",
    "            sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "            max_val = max(df['종가'])\n",
    "            min_val = min(df['종가'])\n",
    "\n",
    "            training_size=int(len(sdf)*0.70)\n",
    "            test_size=len(sdf)-training_size\n",
    "            train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "            def create_dataset(dataset, time_step=1):\n",
    "                dataX, dataY = [], []\n",
    "                for i in range(len(dataset)-time_step-1):\n",
    "                    a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "                    dataX.append(a)\n",
    "                    dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "                return np.array(dataX), np.array(dataY)\n",
    "\n",
    "            time_step = 15\n",
    "            X_train, y_train = create_dataset(train_data, time_step)\n",
    "            X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            model=Sequential()\n",
    "            model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "            model.add(LSTM(16, return_sequences=False))\n",
    "            model.add(Dropout(do))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "            stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "            model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                      epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "            train_predict=model.predict(X_train)\n",
    "            test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "            train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_train = y_train.reshape(-1,1)\n",
    "            y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "            test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_test = y_test.reshape(-1,1)\n",
    "            y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "            lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "            lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "            df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "            scaler=MinMaxScaler(feature_range=(0,1))\n",
    "            sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "            max_val = max(df['종가'])\n",
    "            min_val = min(df['종가'])\n",
    "\n",
    "            training_size=int(len(sdf)*0.70)\n",
    "            test_size=len(sdf)-training_size\n",
    "            train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "            def create_dataset(dataset, time_step=1):\n",
    "                dataX, dataY = [], []\n",
    "                for i in range(len(dataset)-time_step-1):\n",
    "                    a = dataset[i:(i+time_step), [0,2,6,7]]\n",
    "                    dataX.append(a)\n",
    "                    dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "                return np.array(dataX), np.array(dataY)\n",
    "\n",
    "            time_step = 15\n",
    "            X_train, y_train = create_dataset(train_data, time_step)\n",
    "            X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            model=Sequential()\n",
    "            model.add(GRU(64,return_sequences=True,input_shape=(15,4)))\n",
    "            model.add(GRU(64,return_sequences=True))\n",
    "            model.add(GRU(64))\n",
    "            model.add(Dropout(do))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "            model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                      epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "            train_predict=model.predict(X_train)\n",
    "            test_predict=model.predict(X_test)\n",
    "            train_predict.shape, test_predict.shape\n",
    "\n",
    "            train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_train = y_train.reshape(-1,1)\n",
    "            y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "            test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_test = y_test.reshape(-1,1)\n",
    "            y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "\n",
    "            gru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "            gru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "            df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "            scaler=MinMaxScaler(feature_range=(0,1))\n",
    "            sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "            max_val = max(df['종가'])\n",
    "            min_val = min(df['종가'])\n",
    "\n",
    "            training_size=int(len(sdf)*0.70)\n",
    "            test_size=len(sdf)-training_size\n",
    "            train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "            def create_dataset(dataset, time_step=1):\n",
    "                dataX, dataY = [], []\n",
    "                for i in range(len(dataset)-time_step-1):\n",
    "                    a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "                    dataX.append(a)\n",
    "                    dataY.append(dataset[i + time_step, 0])\n",
    "\n",
    "                return np.array(dataX), np.array(dataY)\n",
    "\n",
    "            time_step = 15\n",
    "            X_train, y_train = create_dataset(train_data, time_step)\n",
    "            X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            model=Sequential()\n",
    "            model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "            model.add(LSTM(64,return_sequences=True))\n",
    "            model.add(GRU(64,return_sequences=True))\n",
    "            model.add(GRU(64))\n",
    "            model.add(Dropout(do))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "\n",
    "\n",
    "            model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "                      epochs=1000,callbacks=[stop],batch_size=batch)\n",
    "\n",
    "\n",
    "            train_predict=model.predict(X_train)\n",
    "            test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "            train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_train = y_train.reshape(-1,1)\n",
    "            y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "            test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "            y_test = y_test.reshape(-1,1)\n",
    "            y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "            lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "            lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "            algo_li = ['lstm', 'gru', 'lstmgru']\n",
    "\n",
    "            rmse_li = [lstm_rmse, gru_rmse, lstmgru_rmse]\n",
    "\n",
    "            r2_li = [lstm_r2, gru_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "            data = {'algorithm':['lstm', 'gru', 'lstmgru'], \n",
    "                    'rmse': [lstm_rmse, gru_rmse, lstmgru_rmse], \n",
    "                    'r2': [lstm_r2, gru_r2, lstmgru_r2],\n",
    "                   'optimizer':[opt, opt, opt],\n",
    "                   'batch':[batch, batch, batch],\n",
    "                   'dropout':[do,do,do]}\n",
    "\n",
    "            comparison1 = pd.DataFrame(data)\n",
    "            df_li.append(comparison1)\n",
    "merged_df = pd.concat(df_li, axis=0)\n",
    "merged_df = merged_df.sort_values(['r2'], ascending=False)\n",
    "merged_df.to_csv('./ts_hyper02.csv', encoding='cp949', index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a61112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 5s 91ms/step - loss: 0.3802 - val_loss: 0.2174\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0931 - val_loss: 0.0191\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.6342e-04\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 8.8943e-04\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 9.7120e-04\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 8.5824e-04\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 8.4995e-04\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 8.7319e-04\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 8.1526e-04\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.7746e-04\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.9198e-04\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 9.8620e-04\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.4264e-04\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 8.1770e-04\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 8.1344e-04\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.2046e-04\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 8.1997e-04\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.1019e-04\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 8.2167e-04\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 7.4072e-04\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 8.7434e-04\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 6.8409e-04\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.9888e-04\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 8.5627e-04\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 6.6402e-04\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 6.6432e-04\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.1182e-04\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 8.7987e-04\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 7.0228e-04\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 9.9990e-04 - val_loss: 7.4486e-04\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 7.2084e-04\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.5878e-04\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 7.4325e-04\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.7677e-04\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 6.9852e-04\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9716e-04 - val_loss: 7.8737e-04\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9908e-04 - val_loss: 6.5861e-04\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.6228e-04\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.4830e-04\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.6037e-04\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.0273e-04\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.7585e-04 - val_loss: 6.1544e-04\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.8966e-04 - val_loss: 6.7530e-04\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 9.9065e-04 - val_loss: 6.8885e-04\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.6618e-04 - val_loss: 6.4272e-04\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.5930e-04 - val_loss: 6.8659e-04\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9410e-04 - val_loss: 8.0426e-04\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.7176e-04\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.7012e-04 - val_loss: 6.6673e-04\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.4472e-04 - val_loss: 6.4745e-04\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.8699e-04 - val_loss: 0.0012\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 9.9294e-04 - val_loss: 6.4403e-04\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.3040e-04 - val_loss: 6.6432e-04\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 6.0964e-04\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.8471e-04 - val_loss: 7.5063e-04\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.1482e-04 - val_loss: 8.0828e-04\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.9564e-04 - val_loss: 7.0796e-04\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9062e-04 - val_loss: 6.2444e-04\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.8825e-04 - val_loss: 9.0486e-04\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.6766e-04 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.9643e-04 - val_loss: 5.7917e-04\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.1613e-04 - val_loss: 9.0802e-04\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.5359e-04\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.5993e-04 - val_loss: 5.6976e-04\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.5018e-04 - val_loss: 6.0729e-04\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.2381e-04 - val_loss: 5.4792e-04\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.3048e-04 - val_loss: 6.8982e-04\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.2619e-04 - val_loss: 9.6034e-04\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 10ms/step - loss: 8.4733e-04 - val_loss: 6.1105e-04\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.3583e-04 - val_loss: 5.5544e-04\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.6503e-04 - val_loss: 6.3853e-04\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.1820e-04 - val_loss: 5.6941e-04\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.4013e-04 - val_loss: 5.2870e-04\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.1175e-04 - val_loss: 5.5264e-04\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.9895e-04 - val_loss: 5.2429e-04\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.4468e-04 - val_loss: 7.7363e-04\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.0538e-04 - val_loss: 6.3748e-04\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.4660e-04 - val_loss: 5.6404e-04\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9162e-04 - val_loss: 5.9338e-04\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.0061e-04 - val_loss: 5.4964e-04\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.9749e-04 - val_loss: 5.1442e-04\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.6570e-04 - val_loss: 6.7265e-04\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.7990e-04 - val_loss: 8.6402e-04\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.0388e-04 - val_loss: 5.3712e-04\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.6292e-04 - val_loss: 6.2710e-04\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.9790e-04 - val_loss: 5.1631e-04\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.9648e-04 - val_loss: 5.0835e-04\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.3277e-04 - val_loss: 6.7976e-04\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.8119e-04 - val_loss: 5.0755e-04\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.9411e-04 - val_loss: 6.9423e-04\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4328e-04 - val_loss: 5.3395e-04\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.3541e-04 - val_loss: 0.0010\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.4383e-04 - val_loss: 5.2175e-04\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4966e-04 - val_loss: 0.0011\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.3065e-04 - val_loss: 7.6373e-04\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.5544e-04 - val_loss: 4.9599e-04\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.0513e-04 - val_loss: 0.0020\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 5.1166e-04\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.1186e-04 - val_loss: 5.5622e-04\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.2917e-04 - val_loss: 6.4695e-04\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.1916e-04 - val_loss: 0.0010\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.5176e-04 - val_loss: 4.9017e-04\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5022e-04 - val_loss: 5.8347e-04\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.1897e-04 - val_loss: 7.6143e-04\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 7.7519e-04 - val_loss: 5.5349e-04\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.5432e-04 - val_loss: 5.2958e-04\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.8925e-04 - val_loss: 5.2069e-04\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.8669e-04 - val_loss: 5.8816e-04\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.8239e-04 - val_loss: 5.0205e-04\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 7.1907e-04 - val_loss: 7.5702e-04\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.1657e-04 - val_loss: 6.0165e-04\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.7120e-04 - val_loss: 4.6993e-04\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.8667e-04 - val_loss: 5.2395e-04\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.1913e-04 - val_loss: 5.2383e-04\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 7.3073e-04 - val_loss: 8.1066e-04\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.7644e-04 - val_loss: 4.6298e-04\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3998e-04 - val_loss: 4.8568e-04\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.5159e-04 - val_loss: 6.3505e-04\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.7508e-04 - val_loss: 5.0610e-04\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.8764e-04 - val_loss: 9.2465e-04\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.7843e-04 - val_loss: 4.6580e-04\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.8136e-04 - val_loss: 5.1375e-04\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.2861e-04 - val_loss: 5.4035e-04\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.6403e-04 - val_loss: 7.9987e-04\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.7623e-04 - val_loss: 4.7267e-04\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 8.4543e-04 - val_loss: 6.6719e-04\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.7583e-04 - val_loss: 4.7881e-04\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.9370e-04 - val_loss: 5.3206e-04\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.7014e-04 - val_loss: 5.8193e-04\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.3317e-04 - val_loss: 6.9906e-04\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.8831e-04 - val_loss: 5.4721e-04\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 7.9236e-04 - val_loss: 7.2473e-04\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.2218e-04 - val_loss: 5.4746e-04\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.3019e-04 - val_loss: 4.9818e-04\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.3326e-04 - val_loss: 4.5195e-04\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.0854e-04 - val_loss: 5.3291e-04\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.9755e-04 - val_loss: 7.5218e-04\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.7619e-04 - val_loss: 4.5394e-04\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.0219e-04 - val_loss: 4.9602e-04\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.8847e-04 - val_loss: 5.0572e-04\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.4041e-04 - val_loss: 5.5644e-04\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.8875e-04 - val_loss: 5.5720e-04\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 11ms/step - loss: 6.2110e-04 - val_loss: 6.8073e-04\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.1830e-04 - val_loss: 7.1158e-04\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.6687e-04 - val_loss: 6.7031e-04\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.2429e-04 - val_loss: 6.0431e-04\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.4107e-04 - val_loss: 4.4900e-04\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.2899e-04 - val_loss: 4.9595e-04\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.1413e-04 - val_loss: 0.0010\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.5761e-04 - val_loss: 4.3190e-04\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.7015e-04 - val_loss: 6.4422e-04\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.9386e-04 - val_loss: 4.3952e-04\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.0721e-04 - val_loss: 7.5263e-04\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.0233e-04 - val_loss: 4.3555e-04\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9592e-04 - val_loss: 5.2382e-04\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.8458e-04 - val_loss: 4.6523e-04\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9335e-04 - val_loss: 4.4016e-04\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.0730e-04 - val_loss: 5.0244e-04\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.6585e-04 - val_loss: 4.2457e-04\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.1552e-04 - val_loss: 4.7521e-04\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.6714e-04 - val_loss: 5.2539e-04\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7842e-04 - val_loss: 6.0083e-04\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.5697e-04 - val_loss: 4.1547e-04\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.6202e-04 - val_loss: 4.9990e-04\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.8202e-04 - val_loss: 7.5518e-04\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.4534e-04 - val_loss: 7.3256e-04\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.8271e-04 - val_loss: 4.2911e-04\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.8615e-04 - val_loss: 5.1558e-04\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.3268e-04 - val_loss: 4.4058e-04\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.3712e-04 - val_loss: 4.7177e-04\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 5.7082e-04 - val_loss: 4.2723e-04\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 6.8743e-04 - val_loss: 4.1361e-04\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 5.8990e-04 - val_loss: 7.1181e-04\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7964e-04 - val_loss: 5.4227e-04\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.0882e-04 - val_loss: 6.8168e-04\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.4843e-04 - val_loss: 4.0782e-04\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.3186e-04 - val_loss: 4.0672e-04\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.6763e-04 - val_loss: 5.2616e-04\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.1921e-04 - val_loss: 4.1460e-04\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.9285e-04 - val_loss: 4.1208e-04\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.6839e-04 - val_loss: 5.6443e-04\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.9279e-04 - val_loss: 6.4096e-04\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.2932e-04 - val_loss: 4.9061e-04\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 5.8938e-04 - val_loss: 4.3252e-04\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.6484e-04 - val_loss: 5.6114e-04\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.9111e-04 - val_loss: 4.8173e-04\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.3502e-04 - val_loss: 4.0810e-04\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.8467e-04 - val_loss: 4.0361e-04\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.9940e-04 - val_loss: 4.2703e-04\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.3056e-04 - val_loss: 3.9507e-04\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.0044e-04 - val_loss: 4.0298e-04\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9826e-04 - val_loss: 5.8765e-04\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7761e-04 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.0959e-04 - val_loss: 4.5321e-04\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.5536e-04 - val_loss: 4.8295e-04\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7490e-04 - val_loss: 5.6931e-04\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.2044e-04 - val_loss: 4.6421e-04\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.1631e-04 - val_loss: 3.9194e-04\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.2738e-04 - val_loss: 4.1350e-04\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.2352e-04 - val_loss: 3.9204e-04\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9447e-04 - val_loss: 4.8489e-04\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9678e-04 - val_loss: 4.0613e-04\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.0258e-04 - val_loss: 4.8748e-04\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.5589e-04 - val_loss: 3.9880e-04\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 7.1489e-04 - val_loss: 5.6523e-04\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.0872e-04 - val_loss: 4.1691e-04\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.3935e-04 - val_loss: 3.9503e-04\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.8531e-04 - val_loss: 4.0247e-04\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.8632e-04 - val_loss: 3.8675e-04\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.1921e-04 - val_loss: 3.9290e-04\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.7533e-04 - val_loss: 5.2089e-04\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.7370e-04 - val_loss: 5.0526e-04\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7761e-04 - val_loss: 3.8843e-04\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.8074e-04 - val_loss: 6.2631e-04\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.8544e-04 - val_loss: 3.8135e-04\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9388e-04 - val_loss: 3.9322e-04\n",
      "Epoch 305/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 16ms/step - loss: 4.7715e-04 - val_loss: 4.8324e-04\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.8656e-04 - val_loss: 4.0383e-04\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.8915e-04 - val_loss: 4.0507e-04\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.1739e-04 - val_loss: 4.5200e-04\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.3877e-04 - val_loss: 5.0559e-04\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.7685e-04 - val_loss: 3.8668e-04\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.6997e-04 - val_loss: 3.7918e-04\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.2467e-04 - val_loss: 3.7746e-04\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.6289e-04 - val_loss: 4.8622e-04\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9156e-04 - val_loss: 3.8871e-04\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.8440e-04 - val_loss: 5.1685e-04\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 4.4229e-04 - val_loss: 3.9899e-04\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.1422e-04 - val_loss: 3.7008e-04\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.6810e-04 - val_loss: 6.3967e-04\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.6692e-04 - val_loss: 5.6353e-04\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5693e-04 - val_loss: 3.6807e-04\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.7689e-04 - val_loss: 3.8075e-04\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 6.1151e-04 - val_loss: 4.0166e-04\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5860e-04 - val_loss: 4.4387e-04\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.2257e-04 - val_loss: 3.7798e-04\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5119e-04 - val_loss: 3.8980e-04\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.7587e-04 - val_loss: 3.6841e-04\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.5265e-04 - val_loss: 3.6968e-04\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5898e-04 - val_loss: 4.0013e-04\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.9537e-04 - val_loss: 4.6542e-04\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.1248e-04 - val_loss: 4.0605e-04\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2474e-04 - val_loss: 6.1176e-04\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.4280e-04 - val_loss: 3.6846e-04\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.6970e-04 - val_loss: 3.6323e-04\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.0530e-04 - val_loss: 3.6414e-04\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2883e-04 - val_loss: 4.9207e-04\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5532e-04 - val_loss: 3.6463e-04\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5698e-04 - val_loss: 6.9123e-04\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 6.3381e-04 - val_loss: 5.5439e-04\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9742e-04 - val_loss: 3.6077e-04\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2996e-04 - val_loss: 3.6386e-04\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.4010e-04 - val_loss: 3.5505e-04\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9365e-04 - val_loss: 8.2707e-04\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5901e-04 - val_loss: 5.6821e-04\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.1842e-04 - val_loss: 3.5792e-04\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2362e-04 - val_loss: 5.5421e-04\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.3494e-04 - val_loss: 4.3412e-04\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2401e-04 - val_loss: 3.5563e-04\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.4380e-04 - val_loss: 5.2472e-04\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.4693e-04 - val_loss: 3.4973e-04\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 5.2725e-04 - val_loss: 6.4108e-04\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.3514e-04 - val_loss: 4.0528e-04\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.2878e-04 - val_loss: 5.7155e-04\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.7406e-04 - val_loss: 3.5144e-04\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 4.9209e-04 - val_loss: 3.8252e-04\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2535e-04 - val_loss: 4.2498e-04\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1327e-04 - val_loss: 4.2356e-04\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.7611e-04 - val_loss: 4.2823e-04\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1951e-04 - val_loss: 4.2873e-04\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.4699e-04 - val_loss: 4.6683e-04\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.4670e-04 - val_loss: 3.8324e-04\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2386e-04 - val_loss: 3.5544e-04\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.7924e-04 - val_loss: 3.7882e-04\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2589e-04 - val_loss: 4.4668e-04\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0654e-04 - val_loss: 3.6995e-04\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5066e-04 - val_loss: 3.6757e-04\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2083e-04 - val_loss: 3.9838e-04\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5377e-04 - val_loss: 3.8965e-04\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.6561e-04 - val_loss: 3.9718e-04\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1556e-04 - val_loss: 3.4260e-04\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0567e-04 - val_loss: 3.8660e-04\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.1108e-04 - val_loss: 4.0633e-04\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2343e-04 - val_loss: 6.4984e-04\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.0189e-04 - val_loss: 6.9430e-04\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.9654e-04 - val_loss: 8.6863e-04\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3845e-04 - val_loss: 5.5280e-04\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2857e-04 - val_loss: 3.6666e-04\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2347e-04 - val_loss: 3.4182e-04\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1572e-04 - val_loss: 6.8008e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0255e-04 - val_loss: 3.3614e-04\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9182e-04 - val_loss: 3.5964e-04\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.6122e-04 - val_loss: 4.5356e-04\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.7283e-04 - val_loss: 0.0011\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.0289e-04 - val_loss: 4.0798e-04\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.1947e-04 - val_loss: 3.5747e-04\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8731e-04 - val_loss: 3.3472e-04\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0199e-04 - val_loss: 4.2997e-04\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0604e-04 - val_loss: 3.3561e-04\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0910e-04 - val_loss: 3.5772e-04\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2424e-04 - val_loss: 3.7740e-04\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0230e-04 - val_loss: 3.4240e-04\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.1885e-04 - val_loss: 3.3061e-04\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8449e-04 - val_loss: 3.3409e-04\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1916e-04 - val_loss: 3.3460e-04\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2255e-04 - val_loss: 3.4845e-04\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8861e-04 - val_loss: 3.3126e-04\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.0872e-04 - val_loss: 3.3042e-04\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3183e-04 - val_loss: 3.7534e-04\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.4787e-04 - val_loss: 3.4818e-04\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1988e-04 - val_loss: 3.3148e-04\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9825e-04 - val_loss: 3.3672e-04\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9057e-04 - val_loss: 3.3832e-04\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7911e-04 - val_loss: 3.8512e-04\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3885e-04 - val_loss: 3.7353e-04\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7750e-04 - val_loss: 3.7024e-04\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2978e-04 - val_loss: 3.3423e-04\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9559e-04 - val_loss: 5.0100e-04\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2822e-04 - val_loss: 3.8037e-04\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8406e-04 - val_loss: 3.2907e-04\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8619e-04 - val_loss: 3.3464e-04\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0141e-04 - val_loss: 3.4672e-04\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3577e-04 - val_loss: 3.4386e-04\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7216e-04 - val_loss: 4.4021e-04\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.8820e-04 - val_loss: 3.5457e-04\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1022e-04 - val_loss: 3.9620e-04\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9753e-04 - val_loss: 3.3589e-04\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.1208e-04 - val_loss: 3.2282e-04\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8429e-04 - val_loss: 5.1180e-04\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 4.1441e-04 - val_loss: 3.2351e-04\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3080e-04 - val_loss: 3.2200e-04\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5221e-04 - val_loss: 3.2704e-04\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8063e-04 - val_loss: 4.4009e-04\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8582e-04 - val_loss: 3.2324e-04\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.7349e-04 - val_loss: 4.8020e-04\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6431e-04 - val_loss: 3.7696e-04\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9858e-04 - val_loss: 3.2620e-04\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.9794e-04 - val_loss: 3.4097e-04\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2028e-04 - val_loss: 4.0893e-04\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2105e-04 - val_loss: 3.3144e-04\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.8516e-04 - val_loss: 3.7774e-04\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.7395e-04 - val_loss: 3.2841e-04\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7720e-04 - val_loss: 3.1967e-04\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6947e-04 - val_loss: 3.9757e-04\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3219e-04 - val_loss: 4.3799e-04\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.8675e-04 - val_loss: 3.3256e-04\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6310e-04 - val_loss: 3.3956e-04\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7489e-04 - val_loss: 3.3094e-04\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8363e-04 - val_loss: 3.3394e-04\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2804e-04 - val_loss: 4.2086e-04\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1202e-04 - val_loss: 3.1553e-04\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.2004e-04 - val_loss: 4.6967e-04\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.2716e-04 - val_loss: 4.4072e-04\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0814e-04 - val_loss: 3.3451e-04\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8613e-04 - val_loss: 3.8200e-04\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7026e-04 - val_loss: 3.2300e-04\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6826e-04 - val_loss: 3.5496e-04\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7941e-04 - val_loss: 3.3681e-04\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.4736e-04 - val_loss: 4.4474e-04\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5972e-04 - val_loss: 3.9551e-04\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5970e-04 - val_loss: 3.1317e-04\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9429e-04 - val_loss: 5.3268e-04\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7755e-04 - val_loss: 3.8328e-04\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8953e-04 - val_loss: 3.3665e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5482e-04 - val_loss: 3.6495e-04\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6981e-04 - val_loss: 5.1729e-04\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.8823e-04 - val_loss: 3.4280e-04\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1676e-04 - val_loss: 3.2203e-04\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6086e-04 - val_loss: 3.1149e-04\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0703e-04 - val_loss: 4.1226e-04\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9917e-04 - val_loss: 3.5326e-04\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6867e-04 - val_loss: 4.0133e-04\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6277e-04 - val_loss: 3.3861e-04\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4528e-04 - val_loss: 3.1328e-04\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4342e-04 - val_loss: 3.4142e-04\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8602e-04 - val_loss: 3.5802e-04\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7194e-04 - val_loss: 3.3971e-04\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6067e-04 - val_loss: 3.1010e-04\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0468e-04 - val_loss: 3.2270e-04\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5950e-04 - val_loss: 3.2539e-04\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9107e-04 - val_loss: 3.1028e-04\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6020e-04 - val_loss: 3.7231e-04\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8605e-04 - val_loss: 3.1031e-04\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7922e-04 - val_loss: 3.4564e-04\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4855e-04 - val_loss: 3.1769e-04\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.0465e-04 - val_loss: 3.1008e-04\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6007e-04 - val_loss: 3.0856e-04\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4521e-04 - val_loss: 3.8940e-04\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5446e-04 - val_loss: 3.0872e-04\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5490e-04 - val_loss: 3.1562e-04\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0421e-04 - val_loss: 3.8447e-04\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.3005e-04 - val_loss: 3.0926e-04\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.5043e-04 - val_loss: 3.1613e-04\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.7725e-04 - val_loss: 4.0398e-04\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6489e-04 - val_loss: 8.1198e-04\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.0043e-04 - val_loss: 3.0538e-04\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1680e-04 - val_loss: 4.0363e-04\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.4276e-04 - val_loss: 3.0642e-04\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9129e-04 - val_loss: 3.4344e-04\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4099e-04 - val_loss: 3.0797e-04\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9947e-04 - val_loss: 3.0647e-04\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.6566e-04 - val_loss: 3.0779e-04\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.5108e-04 - val_loss: 3.1367e-04\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.7291e-04 - val_loss: 3.2168e-04\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5655e-04 - val_loss: 3.0314e-04\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4263e-04 - val_loss: 3.0369e-04\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5752e-04 - val_loss: 3.1737e-04\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4740e-04 - val_loss: 4.2470e-04\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8460e-04 - val_loss: 3.8447e-04\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5673e-04 - val_loss: 4.6244e-04\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 4.2481e-04 - val_loss: 4.8096e-04\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.9906e-04 - val_loss: 5.7204e-04\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8904e-04 - val_loss: 3.1860e-04\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5479e-04 - val_loss: 3.5463e-04\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.1379e-04 - val_loss: 4.3166e-04\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.9294e-04 - val_loss: 3.3174e-04\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5843e-04 - val_loss: 3.0167e-04\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4893e-04 - val_loss: 3.7475e-04\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.8731e-04 - val_loss: 3.0206e-04\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.4987e-04 - val_loss: 3.2011e-04\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5949e-04 - val_loss: 3.1422e-04\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3442e-04 - val_loss: 3.6095e-04\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6153e-04 - val_loss: 3.0687e-04\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.0331e-04 - val_loss: 3.0818e-04\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4338e-04 - val_loss: 3.5396e-04\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5722e-04 - val_loss: 3.0175e-04\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3284e-04 - val_loss: 3.2241e-04\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6970e-04 - val_loss: 3.0843e-04\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9522e-04 - val_loss: 3.5623e-04\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3430e-04 - val_loss: 3.0183e-04\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.3951e-04 - val_loss: 3.4940e-04\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 3.4285e-04 - val_loss: 3.1416e-04\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.8073e-04 - val_loss: 3.5706e-04\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4092e-04 - val_loss: 3.2694e-04\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6369e-04 - val_loss: 6.2688e-04\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6736e-04 - val_loss: 3.0015e-04\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7526e-04 - val_loss: 3.8488e-04\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.8378e-04 - val_loss: 3.5660e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9512e-04 - val_loss: 3.0708e-04\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5107e-04 - val_loss: 4.2078e-04\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3687e-04 - val_loss: 3.1121e-04\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8335e-04 - val_loss: 3.1231e-04\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6334e-04 - val_loss: 3.3145e-04\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.5388e-04 - val_loss: 3.6209e-04\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5868e-04 - val_loss: 3.1126e-04\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.3940e-04 - val_loss: 3.1896e-04\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3496e-04 - val_loss: 5.1894e-04\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8004e-04 - val_loss: 3.2112e-04\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7635e-04 - val_loss: 3.0717e-04\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4776e-04 - val_loss: 3.1515e-04\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3276e-04 - val_loss: 3.1796e-04\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5478e-04 - val_loss: 3.0522e-04\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9480e-04 - val_loss: 3.5616e-04\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7759e-04 - val_loss: 3.9141e-04\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4357e-04 - val_loss: 3.0048e-04\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3144e-04 - val_loss: 2.9846e-04\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9077e-04 - val_loss: 3.1624e-04\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5976e-04 - val_loss: 3.1612e-04\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6084e-04 - val_loss: 2.9793e-04\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5624e-04 - val_loss: 3.4428e-04\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7081e-04 - val_loss: 3.1518e-04\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5934e-04 - val_loss: 2.9885e-04\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3280e-04 - val_loss: 4.0278e-04\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5190e-04 - val_loss: 3.0130e-04\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5058e-04 - val_loss: 3.2604e-04\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3911e-04 - val_loss: 2.9827e-04\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4280e-04 - val_loss: 3.1717e-04\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.5421e-04 - val_loss: 3.0800e-04\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.2766e-04 - val_loss: 3.0269e-04\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.5683e-04 - val_loss: 3.2390e-04\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.4737e-04 - val_loss: 3.4093e-04\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5688e-04 - val_loss: 3.5314e-04\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4115e-04 - val_loss: 2.9995e-04\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3930e-04 - val_loss: 2.9868e-04\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3754e-04 - val_loss: 2.9891e-04\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3483e-04 - val_loss: 3.1255e-04\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3664e-04 - val_loss: 2.9528e-04\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4823e-04 - val_loss: 2.9869e-04\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4159e-04 - val_loss: 3.0479e-04\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5271e-04 - val_loss: 3.2383e-04\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3818e-04 - val_loss: 3.0264e-04\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4482e-04 - val_loss: 3.1793e-04\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4573e-04 - val_loss: 3.3651e-04\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.5514e-04 - val_loss: 3.0358e-04\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4113e-04 - val_loss: 3.0347e-04\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6297e-04 - val_loss: 3.1191e-04\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3938e-04 - val_loss: 3.2590e-04\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5397e-04 - val_loss: 3.3451e-04\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4948e-04 - val_loss: 3.9261e-04\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3544e-04 - val_loss: 2.9436e-04\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3952e-04 - val_loss: 3.1226e-04\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3935e-04 - val_loss: 3.0350e-04\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3503e-04 - val_loss: 4.6660e-04\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0152e-04 - val_loss: 3.4863e-04\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3547e-04 - val_loss: 3.0512e-04\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5544e-04 - val_loss: 2.9328e-04\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.4122e-04 - val_loss: 3.0624e-04\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.8137e-04 - val_loss: 4.5786e-04\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9138e-04 - val_loss: 3.1068e-04\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.4311e-04 - val_loss: 3.1674e-04\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.3887e-04 - val_loss: 3.5470e-04\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.6106e-04 - val_loss: 3.2992e-04\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.3170e-04 - val_loss: 2.9950e-04\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.2754e-04 - val_loss: 3.0141e-04\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3608e-04 - val_loss: 4.1749e-04\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5045e-04 - val_loss: 3.1824e-04\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3527e-04 - val_loss: 3.0548e-04\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.6182e-04 - val_loss: 4.8796e-04\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.0208e-04 - val_loss: 2.9319e-04\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.7271e-04 - val_loss: 3.3889e-04\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4825e-04 - val_loss: 2.9906e-04\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4612e-04 - val_loss: 3.3123e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4967e-04 - val_loss: 3.4025e-04\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4909e-04 - val_loss: 2.9720e-04\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3051e-04 - val_loss: 3.8580e-04\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2695e-04 - val_loss: 3.1251e-04\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.7097e-04 - val_loss: 4.2934e-04\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3294e-04 - val_loss: 3.6294e-04\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2364e-04 - val_loss: 2.9879e-04\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2315e-04 - val_loss: 2.9583e-04\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2705e-04 - val_loss: 3.6095e-04\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.2990e-04 - val_loss: 2.9884e-04\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3720e-04 - val_loss: 3.0139e-04\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3579e-04 - val_loss: 5.1511e-04\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4936e-04 - val_loss: 2.9222e-04\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3893e-04 - val_loss: 2.9286e-04\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0934e-04 - val_loss: 2.9683e-04\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3689e-04 - val_loss: 3.0156e-04\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6365e-04 - val_loss: 3.9307e-04\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3585e-04 - val_loss: 3.0399e-04\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2089e-04 - val_loss: 2.9378e-04\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3208e-04 - val_loss: 2.9547e-04\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6938e-04 - val_loss: 4.9634e-04\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5290e-04 - val_loss: 3.3611e-04\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4039e-04 - val_loss: 3.1979e-04\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4742e-04 - val_loss: 3.1179e-04\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.4706e-04 - val_loss: 3.6091e-04\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2919e-04 - val_loss: 3.0690e-04\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6212e-04 - val_loss: 3.9961e-04\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2407e-04 - val_loss: 3.1039e-04\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4117e-04 - val_loss: 3.2983e-04\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3868e-04 - val_loss: 4.3961e-04\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.0517e-04 - val_loss: 3.0870e-04\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3877e-04 - val_loss: 3.1458e-04\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6338e-04 - val_loss: 3.6649e-04\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3061e-04 - val_loss: 3.3602e-04\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2424e-04 - val_loss: 4.1447e-04\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.3074e-04 - val_loss: 3.2241e-04\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.4278e-04 - val_loss: 4.5153e-04\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6817e-04 - val_loss: 3.0095e-04\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.5324e-04 - val_loss: 3.2534e-04\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5388e-04 - val_loss: 2.9586e-04\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.2894e-04 - val_loss: 4.8989e-04\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.9503e-04 - val_loss: 2.9252e-04\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.3705e-04 - val_loss: 3.7024e-04\n",
      "Epoch 1/1000\n",
      "52/52 [==============================] - 8s 45ms/step - loss: 0.0159 - val_loss: 0.0039\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 9.2954e-04\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 8.7482e-04\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 8.0065e-04\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 8.6245e-04\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 6.8888e-04\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 7.1155e-04\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 7.5174e-04\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 6.6593e-04\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 8.2812e-04\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.9917e-04 - val_loss: 6.7854e-04\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.2899e-04 - val_loss: 5.7810e-04\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.2957e-04 - val_loss: 9.4388e-04\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.4846e-04 - val_loss: 6.1838e-04\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.8996e-04 - val_loss: 7.4335e-04\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 9.3573e-04 - val_loss: 8.0745e-04\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.5891e-04 - val_loss: 5.2082e-04\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.1264e-04 - val_loss: 5.0541e-04\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.1477e-04 - val_loss: 4.9926e-04\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.7286e-04 - val_loss: 6.0674e-04\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.7745e-04 - val_loss: 0.0018\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.5915e-04 - val_loss: 4.8065e-04\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 7.2575e-04 - val_loss: 4.7616e-04\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.2488e-04 - val_loss: 4.4896e-04\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.5889e-04 - val_loss: 5.7354e-04\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 6.2284e-04 - val_loss: 4.8354e-04\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.1657e-04 - val_loss: 8.8136e-04\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 7.6650e-04 - val_loss: 8.0012e-04\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.8632e-04 - val_loss: 0.0010\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.5452e-04 - val_loss: 5.2304e-04\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.7779e-04 - val_loss: 4.1223e-04\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.0699e-04 - val_loss: 4.1751e-04\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2042e-04 - val_loss: 3.7773e-04\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.9665e-04 - val_loss: 3.8099e-04\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.8139e-04 - val_loss: 5.6194e-04\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2242e-04 - val_loss: 3.8523e-04\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.9526e-04 - val_loss: 0.0011\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.0024e-04 - val_loss: 8.6240e-04\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.9656e-04 - val_loss: 3.8570e-04\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.5396e-04 - val_loss: 3.9161e-04\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.7047e-04 - val_loss: 3.6116e-04\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.9739e-04 - val_loss: 5.5759e-04\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.1994e-04 - val_loss: 4.1172e-04\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.5282e-04 - val_loss: 6.0528e-04\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.7597e-04 - val_loss: 6.1583e-04\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.5300e-04 - val_loss: 4.3635e-04\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.7011e-04 - val_loss: 3.6316e-04\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.0973e-04 - val_loss: 3.7121e-04\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9144e-04 - val_loss: 3.9719e-04\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.8098e-04 - val_loss: 5.1669e-04\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.4210e-04 - val_loss: 3.0207e-04\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.0181e-04 - val_loss: 3.7245e-04\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9648e-04 - val_loss: 3.1023e-04\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 5.1556e-04 - val_loss: 3.2939e-04\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.9250e-04 - val_loss: 2.9939e-04\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.1460e-04 - val_loss: 3.1036e-04\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.0000e-04 - val_loss: 5.8608e-04\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7803e-04 - val_loss: 3.1022e-04\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.8890e-04 - val_loss: 3.2192e-04\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0594e-04 - val_loss: 2.9444e-04\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.4121e-04 - val_loss: 5.4543e-04\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.3640e-04 - val_loss: 6.6834e-04\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.0895e-04 - val_loss: 3.4389e-04\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.9350e-04 - val_loss: 4.4104e-04\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.8121e-04 - val_loss: 3.3013e-04\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.6057e-04 - val_loss: 2.9146e-04\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.3943e-04 - val_loss: 3.8576e-04\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.8827e-04 - val_loss: 3.3112e-04\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.1639e-04 - val_loss: 2.9304e-04\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.6061e-04 - val_loss: 2.9991e-04\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7329e-04 - val_loss: 2.8971e-04\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.8300e-04 - val_loss: 2.9131e-04\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.9540e-04 - val_loss: 3.7965e-04\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9858e-04 - val_loss: 3.5142e-04\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7504e-04 - val_loss: 3.5327e-04\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.6429e-04 - val_loss: 2.9260e-04\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.1941e-04 - val_loss: 5.7785e-04\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.5062e-04 - val_loss: 3.1194e-04\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.6693e-04 - val_loss: 3.3066e-04\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0416e-04 - val_loss: 7.5657e-04\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 5.6343e-04 - val_loss: 4.4695e-04\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0441e-04 - val_loss: 4.3437e-04\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.1198e-04 - val_loss: 3.7165e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 3.7476e-04 - val_loss: 2.9643e-04\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7484e-04 - val_loss: 2.9286e-04\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.0875e-04 - val_loss: 3.4777e-04\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.2714e-04 - val_loss: 2.9718e-04\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.5287e-04 - val_loss: 5.6208e-04\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 4.1281e-04 - val_loss: 3.0115e-04\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.8275e-04 - val_loss: 2.9027e-04\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.4719e-04 - val_loss: 3.2945e-04\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.6639e-04 - val_loss: 3.6440e-04\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 3.8140e-04 - val_loss: 3.7829e-04\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.3547e-04 - val_loss: 3.8246e-04\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.2963e-04 - val_loss: 3.1935e-04\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.5222e-04 - val_loss: 2.8842e-04\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.0217e-04 - val_loss: 3.2547e-04\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 3.9510e-04 - val_loss: 5.6988e-04\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 3.7195e-04 - val_loss: 2.9755e-04\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.8236e-04 - val_loss: 3.2001e-04\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 4.0699e-04 - val_loss: 3.0104e-04\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 4.1076e-04 - val_loss: 4.2364e-04\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 3.5182e-04 - val_loss: 3.0562e-04\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 3.9383e-04 - val_loss: 3.1523e-04\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 3.9704e-04 - val_loss: 4.1329e-04\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 3s 61ms/step - loss: 3.8212e-04 - val_loss: 3.0319e-04\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 3.9039e-04 - val_loss: 3.1160e-04\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 3.5854e-04 - val_loss: 3.5003e-04\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.7976e-04 - val_loss: 3.3605e-04\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 3.8135e-04 - val_loss: 2.9813e-04\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 3.8379e-04 - val_loss: 2.9353e-04\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 4.3000e-04 - val_loss: 2.9347e-04\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 3.7617e-04 - val_loss: 3.0298e-04\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.4967e-04 - val_loss: 3.5571e-04\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.8677e-04 - val_loss: 2.9470e-04\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 4.2582e-04 - val_loss: 2.9128e-04\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5864e-04 - val_loss: 3.0403e-04\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 4.1942e-04 - val_loss: 3.0493e-04\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 3.4244e-04 - val_loss: 2.9225e-04\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 3.5156e-04 - val_loss: 3.1189e-04\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 3.4152e-04 - val_loss: 2.9410e-04\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 4.4588e-04 - val_loss: 3.0579e-04\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 3s 50ms/step - loss: 4.2504e-04 - val_loss: 4.3263e-04\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 3.8174e-04 - val_loss: 3.5564e-04\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 3.5420e-04 - val_loss: 4.4867e-04\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.0793e-04 - val_loss: 8.7141e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>915.407841</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstmgru</td>\n",
       "      <td>909.434771</td>\n",
       "      <td>0.982684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm        rmse        r2\n",
       "0      lstm  915.407841  0.982456\n",
       "1   lstmgru  909.434771  0.982684"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,5,7]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(16, return_sequences=True,input_shape=(15,4), activation='tanh'))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='nadam')\n",
    "\n",
    "stop = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop], batch_size=64)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstm_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "df = pd.read_csv('./stock_v12.csv', encoding='cp949')\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "sdf=scaler.fit_transform(np.array(df))\n",
    "\n",
    "max_val = max(df['종가'])\n",
    "min_val = min(df['종가'])\n",
    "\n",
    "training_size=int(len(sdf)*0.70)\n",
    "test_size=len(sdf)-training_size\n",
    "train_data,test_data=sdf[0:training_size,:],sdf[training_size:len(sdf),:]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), [0,2,4,7,8]]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,input_shape=(15,5), activation='tanh'))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(GRU(64,return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adamax')\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,callbacks=[stop],batch_size=16)\n",
    "\n",
    "\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "\n",
    "\n",
    "train_predict = train_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = y_train*(max_val-min_val) + min_val\n",
    "\n",
    "test_predict = test_predict*(max_val-min_val) + min_val\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_test = y_test*(max_val-min_val) + min_val\n",
    "\n",
    "\n",
    "lstmgru_rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "lstmgru_r2 = r2_score(y_test,test_predict)\n",
    "\n",
    "algo_li = ['lstm', 'lstmgru']\n",
    "\n",
    "rmse_li = [lstm_rmse, lstmgru_rmse]\n",
    "\n",
    "r2_li = [lstm_r2, lstmgru_r2]\n",
    "\n",
    "\n",
    "\n",
    "data = {'algorithm':['lstm', 'lstmgru'], \n",
    "        'rmse': [lstm_rmse, lstmgru_rmse], \n",
    "        'r2': [lstm_r2, lstmgru_r2]}\n",
    "\n",
    "comparison1 = pd.DataFrame(data)\n",
    "comparison1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870f2d8",
   "metadata": {},
   "source": [
    "# 종가 vs feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ef13a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ['RF', 'KNN', 'LGBM', 'LSTM', 'GRU', 'LSTM+GRU']\n",
    "notimedf = pd.DataFrame({'model':model, \n",
    "              'RMSE_close':[1294.2452, 1066.9414, 1118.5131, 932.2, 920.6104, 926.7996],\n",
    "              'R2_close' : [0.9642, 0.9756, 0.9732, 0.9817, 0.9821, 0.9819],\n",
    "              'RMSE_fs' : [1130.7106, 1009.3184, 1118.5131, 908.9118, 905.4588, 909.3614],\n",
    "              'R2_fs' : [0.9728, 0.9783, 0.9732, 0.9827, 0.9828, 0.9826]\n",
    "             })\n",
    "\n",
    "\n",
    "csfont = {'fontname':'sans-serif'}\n",
    "\n",
    "# 모델 리스트\n",
    "models = notimedf['model']\n",
    "# 막대 그래프의 위치\n",
    "x = np.arange(len(models))\n",
    "# 그래프 폭\n",
    "width = 0.35\n",
    "\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)\n",
    "\n",
    "# 그래프 생성\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x - width/2, notimedf['RMSE_close'], width, label='RMSE_close', color='blue')\n",
    "rects2 = ax.bar(x + width/2,notimedf['RMSE_fs'], width, label='RMSE_featureselection', color='orange')\n",
    "\n",
    "# # 축, 타이틀 설정\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(models)\n",
    "# # ax.set_title('Comparison of RMSE_1 and RMSE_15 by Model')\n",
    "# ax.set_xlabel('Models', fontsize=25, **csfont)\n",
    "# ax.set_ylabel('RMSE', fontsize=25, **csfont)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.set_xlabel('Models', fontsize=25, **csfont)\n",
    "ax.set_ylabel('RMSE', fontsize=25, **csfont)\n",
    "\n",
    "ax.set_ylim([800, 1350])\n",
    "\n",
    "# 범례 표시\n",
    "ax.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4d7bb",
   "metadata": {},
   "source": [
    "# default parameter VS Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc22625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ['RF', 'KNN', 'LGBM', 'LSTM', 'GRU', 'LSTM+GRU']\n",
    "notimedf = pd.DataFrame({'model':model, \n",
    "              'RMSE_default':[1130.7106, 1009.3184, 1118.5131, 908.9118, 905.4588, 909.3614],\n",
    "              'R2_default' : [0.9728, 0.9783, 0.9732, 0.9827, 0.9828, 0.9826],\n",
    "              'RMSE_hpo' : [1060.8211, 1008.5801, 987.7137, 911.9774,901.6247, 907.0604],\n",
    "              'R2_hpo' : [0.9761, 0.9784, 0.9792, 0.9825, 0.9829, 0.9827]\n",
    "             })\n",
    "\n",
    "\n",
    "csfont = {'fontname':'sans-serif'}\n",
    "\n",
    "# 모델 리스트\n",
    "models = notimedf['model']\n",
    "# 막대 그래프의 위치\n",
    "x = np.arange(len(models))\n",
    "# 그래프 폭\n",
    "width = 0.35\n",
    "\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)\n",
    "\n",
    "# 그래프 생성\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x - width/2, notimedf['RMSE_default'], width, label='RMSE_default', color='blue')\n",
    "rects2 = ax.bar(x + width/2,notimedf['RMSE_hpo'], width, label='RMSE_hyper', color='orange')\n",
    "\n",
    "# # 축, 타이틀 설정\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(models)\n",
    "# # ax.set_title('Comparison of RMSE_1 and RMSE_15 by Model')\n",
    "# ax.set_xlabel('Models', fontsize=25, **csfont)\n",
    "# ax.set_ylabel('RMSE', fontsize=25, **csfont)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.set_xlabel('Models', fontsize=25, **csfont)\n",
    "ax.set_ylabel('RMSE', fontsize=25, **csfont)\n",
    "\n",
    "ax.set_ylim([800, 1150])\n",
    "\n",
    "# 범례 표시\n",
    "ax.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17ec0e",
   "metadata": {},
   "source": [
    "# close VS feature selection VS HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d84ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ['RF', 'KNN', 'LGBM', 'LSTM', 'GRU', 'LSTM+GRU']\n",
    "notimedf = pd.DataFrame({'model':model, \n",
    "              'RMSE_close':[1294.2452, 1066.9414, 1118.5131, 932.2, 920.6104, 926.7996],\n",
    "              'R2_close' : [0.9642, 0.9756, 0.9732, 0.9817, 0.9821, 0.9819],\n",
    "              'RMSE_fs' : [1130.7106, 1009.3184, 1118.5131, 908.9118, 905.4588, 909.3614],\n",
    "              'R2_fs' : [0.9728, 0.9783, 0.9732, 0.9827, 0.9828, 0.9826],\n",
    "                'RMSE_hpo' : [1060.8211, 1008.5801, 987.7137, 911.9774,901.6247, 907.0604],\n",
    "              'R2_hpo' : [0.9761, 0.9784, 0.9792, 0.9825, 0.9829, 0.9827]\n",
    "             })\n",
    "\n",
    "\n",
    "csfont = {'fontname':'sans-serif'}\n",
    "\n",
    "# 모델 리스트\n",
    "models = notimedf['model']\n",
    "# 막대 그래프의 위치\n",
    "x = np.arange(len(models))\n",
    "# 그래프 폭\n",
    "width = 0.2\n",
    "\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)\n",
    "\n",
    "# 그래프 생성\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x - width*1.3, notimedf['RMSE_close'], width, label='RMSE_close', color='blue')\n",
    "rects2 = ax.bar(x,notimedf['RMSE_fs'], width, label='RMSE_featureselection', color='orange')\n",
    "rects3 = ax.bar(x + width*1.3,notimedf['RMSE_hpo'], width, label='RMSE_hyper', color='red')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.set_xlabel('Models', fontsize=25, **csfont)\n",
    "ax.set_ylabel('RMSE', fontsize=25, **csfont)\n",
    "\n",
    "ax.set_ylim([800, 1350])\n",
    "\n",
    "# 범례 표시\n",
    "ax.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
